#!/usr/bin/env python3
"""
è‡ªé€‚åº”é£é™©ç®¡ç†ç³»ç»Ÿ
åŸºäºå¸‚åœºçŠ¶æ€å’Œç­–ç•¥è¡¨ç°åŠ¨æ€è°ƒæ•´é£é™©å‚æ•°
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# MLç›¸å…³åº“
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import joblib

# æŠ€æœ¯åˆ†æ
import talib

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

class AdaptiveRiskManager:
    """è‡ªé€‚åº”é£é™©ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, initial_params=None):
        # åŸºç¡€é£é™©å‚æ•°
        self.base_params = initial_params or {
            'stop_loss': 0.02,
            'take_profit': 0.06,
            'trailing_stop': 0.015,
            'max_position_size': 0.3,
            'risk_per_trade': 0.01
        }
        
        # å½“å‰è‡ªé€‚åº”å‚æ•°
        self.current_params = self.base_params.copy()
        
        # MLæ¨¡å‹
        self.volatility_predictor = None
        self.regime_classifier = None
        self.anomaly_detector = None
        self.scaler = StandardScaler()
        
        # å¸‚åœºçŠ¶æ€
        self.market_regime = 'normal'  # normal, high_vol, trending, sideways
        self.volatility_forecast = 0.02
        self.risk_score = 0.5  # 0-1, è¶Šé«˜é£é™©è¶Šå¤§
        
        # å†å²æ•°æ®
        self.performance_history = []
        self.market_data_history = []
        self.risk_adjustments_history = []
        
        # é£é™©è°ƒæ•´å› å­
        self.adjustment_factors = {
            'volatility_factor': 1.0,
            'regime_factor': 1.0,
            'performance_factor': 1.0,
            'drawdown_factor': 1.0
        }
    
    def calculate_market_features(self, data, lookback=20):
        """è®¡ç®—å¸‚åœºç‰¹å¾"""
        df = data.copy()
        
        # åŸºç¡€ç‰¹å¾
        df['returns'] = df['Close'].pct_change()
        df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))
        
        # æ³¢åŠ¨ç‡ç‰¹å¾
        df['realized_vol'] = df['returns'].rolling(window=lookback).std() * np.sqrt(252)
        df['vol_5d'] = df['returns'].rolling(window=5).std() * np.sqrt(252)
        df['vol_20d'] = df['returns'].rolling(window=20).std() * np.sqrt(252)
        df['vol_ratio'] = df['vol_5d'] / df['vol_20d']
        
        # è¶‹åŠ¿ç‰¹å¾
        df['sma_20'] = df['Close'].rolling(window=20).mean()
        df['sma_50'] = df['Close'].rolling(window=50).mean()
        df['trend_strength'] = (df['Close'] - df['sma_20']) / df['sma_20']
        df['trend_direction'] = np.where(df['sma_20'] > df['sma_50'], 1, -1)
        
        # åŠ¨é‡ç‰¹å¾
        df['momentum_5d'] = df['Close'].pct_change(5)
        df['momentum_20d'] = df['Close'].pct_change(20)
        df['rsi'] = talib.RSI(df['Close'].values, timeperiod=14)
        
        # æˆäº¤é‡ç‰¹å¾
        df['volume_sma'] = df['Volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['Volume'] / df['volume_sma']
        
        # VIXä»£ç†æŒ‡æ ‡ï¼ˆåŸºäºæ”¶ç›Šç‡åˆ†å¸ƒï¼‰
        df['vix_proxy'] = df['returns'].rolling(window=20).apply(
            lambda x: np.percentile(np.abs(x), 95) * np.sqrt(252) * 100
        )
        
        # å¸‚åœºå‹åŠ›æŒ‡æ ‡
        df['stress_indicator'] = (
            df['vol_ratio'] * 0.3 +
            np.abs(df['trend_strength']) * 0.3 +
            (df['vix_proxy'] / 50) * 0.4
        )
        
        return df
    
    def train_volatility_predictor(self, market_data):
        """è®­ç»ƒæ³¢åŠ¨ç‡é¢„æµ‹æ¨¡å‹"""
        print("ğŸ“Š è®­ç»ƒæ³¢åŠ¨ç‡é¢„æµ‹æ¨¡å‹...")
        
        # è®¡ç®—ç‰¹å¾
        features_df = self.calculate_market_features(market_data)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        feature_cols = [
            'vol_5d', 'vol_20d', 'vol_ratio', 'trend_strength', 
            'momentum_5d', 'momentum_20d', 'rsi', 'volume_ratio', 'stress_indicator'
        ]
        
        # ç›®æ ‡å˜é‡ï¼šæœªæ¥5æ—¥æ³¢åŠ¨ç‡
        features_df['target_vol'] = features_df['realized_vol'].shift(-5)
        
        # æ¸…ç†æ•°æ®
        clean_data = features_df[feature_cols + ['target_vol']].dropna()
        
        if len(clean_data) < 50:
            print("âš ï¸  æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤æ³¢åŠ¨ç‡é¢„æµ‹")
            return
        
        X = clean_data[feature_cols]
        y = clean_data['target_vol']
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # è®­ç»ƒæ¨¡å‹
        self.volatility_predictor = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.volatility_predictor.fit(X_scaled, y)
        
        # è¯„ä¼°æ¨¡å‹
        predictions = self.volatility_predictor.predict(X_scaled)
        mse = mean_squared_error(y, predictions)
        r2 = self.volatility_predictor.score(X_scaled, y)
        
        print(f"   æ³¢åŠ¨ç‡é¢„æµ‹æ¨¡å‹ RÂ² å¾—åˆ†: {r2:.4f}")
        print(f"   å‡æ–¹è¯¯å·®: {mse:.6f}")
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(self.volatility_predictor, '/tmp/volatility_predictor.pkl')
        joblib.dump(self.scaler, '/tmp/volatility_scaler.pkl')
    
    def train_regime_classifier(self, market_data):
        """è®­ç»ƒå¸‚åœºçŠ¶æ€åˆ†ç±»å™¨"""
        print("ğŸ¯ è®­ç»ƒå¸‚åœºçŠ¶æ€åˆ†ç±»å™¨...")
        
        features_df = self.calculate_market_features(market_data)
        
        # å®šä¹‰å¸‚åœºçŠ¶æ€
        def classify_regime(row):
            if row['realized_vol'] > 0.25:  # é«˜æ³¢åŠ¨
                return 'high_vol'
            elif abs(row['trend_strength']) > 0.05:  # è¶‹åŠ¿å¸‚åœº
                return 'trending'
            elif row['vol_ratio'] < 0.8:  # ä½æ³¢åŠ¨
                return 'low_vol'
            else:
                return 'normal'
        
        features_df['regime'] = features_df.apply(classify_regime, axis=1)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        feature_cols = [
            'realized_vol', 'vol_ratio', 'trend_strength', 'momentum_20d', 
            'rsi', 'volume_ratio', 'stress_indicator'
        ]
        
        clean_data = features_df[feature_cols + ['regime']].dropna()
        
        if len(clean_data) < 50:
            print("âš ï¸  æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤å¸‚åœºçŠ¶æ€åˆ†ç±»")
            return
        
        X = clean_data[feature_cols]
        y = clean_data['regime']
        
        # ä½¿ç”¨èšç±»ä½œä¸ºæ— ç›‘ç£åˆ†ç±»å™¨
        self.regime_classifier = KMeans(n_clusters=4, random_state=42)
        X_scaled = StandardScaler().fit_transform(X)
        cluster_labels = self.regime_classifier.fit_predict(X_scaled)
        
        # æ˜ å°„èšç±»ç»“æœåˆ°å¸‚åœºçŠ¶æ€
        regime_mapping = {}
        for i in range(4):
            cluster_mask = cluster_labels == i
            if cluster_mask.sum() > 0:
                most_common_regime = y[cluster_mask].mode().iloc[0] if len(y[cluster_mask].mode()) > 0 else 'normal'
                regime_mapping[i] = most_common_regime
        
        self.regime_mapping = regime_mapping
        
        print(f"   å¸‚åœºçŠ¶æ€åˆ†ç±»å™¨è®­ç»ƒå®Œæˆï¼Œè¯†åˆ«å‡º {len(regime_mapping)} ç§çŠ¶æ€")
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(self.regime_classifier, '/tmp/regime_classifier.pkl')
    
    def train_anomaly_detector(self, market_data):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        print("ğŸš¨ è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹...")
        
        features_df = self.calculate_market_features(market_data)
        
        feature_cols = [
            'realized_vol', 'vol_ratio', 'trend_strength', 'momentum_5d',
            'volume_ratio', 'stress_indicator'
        ]
        
        clean_data = features_df[feature_cols].dropna()
        
        if len(clean_data) < 30:
            print("âš ï¸  æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å¼‚å¸¸æ£€æµ‹è®­ç»ƒ")
            return
        
        # è®­ç»ƒå­¤ç«‹æ£®æ—
        self.anomaly_detector = IsolationForest(
            contamination=0.1,  # å‡è®¾10%çš„æ•°æ®æ˜¯å¼‚å¸¸
            random_state=42
        )
        
        X_scaled = StandardScaler().fit_transform(clean_data)
        self.anomaly_detector.fit(X_scaled)
        
        # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
        anomaly_scores = self.anomaly_detector.decision_function(X_scaled)
        anomaly_labels = self.anomaly_detector.predict(X_scaled)
        
        anomaly_rate = (anomaly_labels == -1).mean()
        print(f"   å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ£€æµ‹åˆ° {anomaly_rate:.1%} çš„å¼‚å¸¸æ•°æ®")
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(self.anomaly_detector, '/tmp/anomaly_detector.pkl')
    
    def predict_market_state(self, current_data):
        """é¢„æµ‹å½“å‰å¸‚åœºçŠ¶æ€"""
        try:
            # è®¡ç®—å½“å‰ç‰¹å¾
            features_df = self.calculate_market_features(current_data)
            latest_features = features_df.iloc[-1]
            
            # é¢„æµ‹æ³¢åŠ¨ç‡
            if self.volatility_predictor is not None:
                vol_features = [
                    'vol_5d', 'vol_20d', 'vol_ratio', 'trend_strength',
                    'momentum_5d', 'momentum_20d', 'rsi', 'volume_ratio', 'stress_indicator'
                ]
                
                vol_input = latest_features[vol_features].values.reshape(1, -1)
                vol_input_scaled = self.scaler.transform(vol_input)
                self.volatility_forecast = self.volatility_predictor.predict(vol_input_scaled)[0]
            
            # é¢„æµ‹å¸‚åœºçŠ¶æ€
            if self.regime_classifier is not None:
                regime_features = [
                    'realized_vol', 'vol_ratio', 'trend_strength', 'momentum_20d',
                    'rsi', 'volume_ratio', 'stress_indicator'
                ]
                
                regime_input = latest_features[regime_features].values.reshape(1, -1)
                regime_input_scaled = StandardScaler().fit_transform(regime_input)
                cluster_pred = self.regime_classifier.predict(regime_input_scaled)[0]
                self.market_regime = self.regime_mapping.get(cluster_pred, 'normal')
            
            # å¼‚å¸¸æ£€æµ‹
            anomaly_score = 0.5  # é»˜è®¤æ­£å¸¸
            if self.anomaly_detector is not None:
                anomaly_features = [
                    'realized_vol', 'vol_ratio', 'trend_strength', 'momentum_5d',
                    'volume_ratio', 'stress_indicator'
                ]
                
                anomaly_input = latest_features[anomaly_features].values.reshape(1, -1)
                anomaly_input_scaled = StandardScaler().fit_transform(anomaly_input)
                anomaly_score = self.anomaly_detector.decision_function(anomaly_input_scaled)[0]
                
                # è½¬æ¢ä¸º0-1é£é™©åˆ†æ•°
                self.risk_score = max(0, min(1, (1 - anomaly_score) / 2))
            
            return {
                'volatility_forecast': self.volatility_forecast,
                'market_regime': self.market_regime,
                'risk_score': self.risk_score,
                'anomaly_score': anomaly_score
            }
            
        except Exception as e:
            print(f"âš ï¸  å¸‚åœºçŠ¶æ€é¢„æµ‹å¤±è´¥: {e}")
            return {
                'volatility_forecast': 0.02,
                'market_regime': 'normal',
                'risk_score': 0.5,
                'anomaly_score': 0
            }
    
    def calculate_adjustment_factors(self, market_state, performance_metrics=None):
        """è®¡ç®—é£é™©è°ƒæ•´å› å­"""
        
        # 1. æ³¢åŠ¨ç‡è°ƒæ•´å› å­
        expected_vol = 0.15  # åŸºå‡†å¹´åŒ–æ³¢åŠ¨ç‡
        vol_ratio = market_state['volatility_forecast'] / expected_vol
        self.adjustment_factors['volatility_factor'] = np.clip(vol_ratio, 0.5, 2.0)
        
        # 2. å¸‚åœºçŠ¶æ€è°ƒæ•´å› å­
        regime_adjustments = {
            'normal': 1.0,
            'high_vol': 1.5,    # é«˜æ³¢åŠ¨æ—¶å¢åŠ é£é™©æ§åˆ¶
            'trending': 0.8,    # è¶‹åŠ¿å¸‚åœºå¯ä»¥é€‚å½“æ”¾æ¾
            'low_vol': 0.9,     # ä½æ³¢åŠ¨æ—¶ç•¥å¾®æ”¾æ¾
            'sideways': 1.2     # éœ‡è¡å¸‚åœºå¢åŠ æ§åˆ¶
        }
        self.adjustment_factors['regime_factor'] = regime_adjustments.get(
            market_state['market_regime'], 1.0
        )
        
        # 3. é£é™©åˆ†æ•°è°ƒæ•´å› å­
        risk_factor = 1 + market_state['risk_score']  # 1.0 - 2.0
        self.adjustment_factors['risk_factor'] = risk_factor
        
        # 4. è¡¨ç°è°ƒæ•´å› å­
        if performance_metrics:
            recent_sharpe = performance_metrics.get('recent_sharpe', 1.0)
            recent_drawdown = performance_metrics.get('recent_drawdown', 0.05)
            
            # è¡¨ç°å¥½æ—¶å¯ä»¥é€‚å½“æ”¾æ¾ï¼Œè¡¨ç°å·®æ—¶æ”¶ç´§
            performance_factor = 1.0
            if recent_sharpe > 2.0:
                performance_factor = 0.9  # è¡¨ç°å¥½ï¼Œç•¥å¾®æ”¾æ¾
            elif recent_sharpe < 0.5:
                performance_factor = 1.3  # è¡¨ç°å·®ï¼Œæ”¶ç´§æ§åˆ¶
            
            # å›æ’¤è°ƒæ•´
            if recent_drawdown > 0.1:  # å›æ’¤è¶…è¿‡10%
                performance_factor *= 1.2
            
            self.adjustment_factors['performance_factor'] = performance_factor
        
        return self.adjustment_factors
    
    def adapt_risk_parameters(self, market_state, performance_metrics=None):
        """è‡ªé€‚åº”è°ƒæ•´é£é™©å‚æ•°"""
        
        # è®¡ç®—è°ƒæ•´å› å­
        factors = self.calculate_adjustment_factors(market_state, performance_metrics)
        
        # ç»¼åˆè°ƒæ•´å› å­
        total_factor = (
            factors['volatility_factor'] * 0.4 +
            factors['regime_factor'] * 0.3 +
            factors.get('risk_factor', 1.0) * 0.2 +
            factors.get('performance_factor', 1.0) * 0.1
        )
        
        # è°ƒæ•´é£é™©å‚æ•°
        self.current_params = {}
        
        # æ­¢æŸè°ƒæ•´ï¼šé£é™©é«˜æ—¶æ”¶ç´§
        self.current_params['stop_loss'] = self.base_params['stop_loss'] * total_factor
        self.current_params['stop_loss'] = np.clip(self.current_params['stop_loss'], 0.005, 0.1)
        
        # æ­¢ç›ˆè°ƒæ•´ï¼šé£é™©é«˜æ—¶ä¹Ÿç›¸åº”è°ƒæ•´
        profit_factor = min(total_factor, 1.5)  # æ­¢ç›ˆè°ƒæ•´å¹…åº¦è¾ƒå°
        self.current_params['take_profit'] = self.base_params['take_profit'] * profit_factor
        self.current_params['take_profit'] = np.clip(self.current_params['take_profit'], 0.02, 0.2)
        
        # è¿½è¸ªæ­¢æŸè°ƒæ•´
        self.current_params['trailing_stop'] = self.base_params['trailing_stop'] * total_factor
        self.current_params['trailing_stop'] = np.clip(self.current_params['trailing_stop'], 0.005, 0.05)
        
        # ä»“ä½å¤§å°è°ƒæ•´ï¼šé£é™©é«˜æ—¶å‡å°ä»“ä½
        position_factor = 1 / total_factor  # åå‘è°ƒæ•´
        self.current_params['max_position_size'] = self.base_params['max_position_size'] * position_factor
        self.current_params['max_position_size'] = np.clip(self.current_params['max_position_size'], 0.05, 0.5)
        
        # å•ç¬”é£é™©è°ƒæ•´
        self.current_params['risk_per_trade'] = self.base_params['risk_per_trade'] * position_factor
        self.current_params['risk_per_trade'] = np.clip(self.current_params['risk_per_trade'], 0.005, 0.03)
        
        # è®°å½•è°ƒæ•´å†å²
        adjustment_record = {
            'timestamp': datetime.now(),
            'market_state': market_state,
            'adjustment_factors': factors,
            'total_factor': total_factor,
            'old_params': self.base_params.copy(),
            'new_params': self.current_params.copy()
        }
        self.risk_adjustments_history.append(adjustment_record)
        
        return self.current_params
    
    def get_dynamic_risk_params(self, current_data, performance_metrics=None):
        """è·å–åŠ¨æ€é£é™©å‚æ•°"""
        
        # é¢„æµ‹å¸‚åœºçŠ¶æ€
        market_state = self.predict_market_state(current_data)
        
        # è‡ªé€‚åº”è°ƒæ•´å‚æ•°
        adapted_params = self.adapt_risk_parameters(market_state, performance_metrics)
        
        return {
            'risk_params': adapted_params,
            'market_state': market_state,
            'adjustment_factors': self.adjustment_factors
        }
    
    def evaluate_risk_adjustment_performance(self):
        """è¯„ä¼°é£é™©è°ƒæ•´çš„æ•ˆæœ"""
        if len(self.risk_adjustments_history) < 10:
            print("âš ï¸  è°ƒæ•´å†å²ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°æ•ˆæœ")
            return None
        
        # åˆ†æè°ƒæ•´é¢‘ç‡
        adjustments_df = pd.DataFrame([
            {
                'timestamp': record['timestamp'],
                'total_factor': record['total_factor'],
                'volatility_factor': record['adjustment_factors']['volatility_factor'],
                'regime_factor': record['adjustment_factors']['regime_factor'],
                'stop_loss': record['new_params']['stop_loss'],
                'take_profit': record['new_params']['take_profit'],
                'position_size': record['new_params']['max_position_size']
            }
            for record in self.risk_adjustments_history
        ])
        
        # è®¡ç®—è°ƒæ•´ç»Ÿè®¡
        stats = {
            'total_adjustments': len(adjustments_df),
            'avg_adjustment_factor': adjustments_df['total_factor'].mean(),
            'adjustment_volatility': adjustments_df['total_factor'].std(),
            'stop_loss_range': (adjustments_df['stop_loss'].min(), adjustments_df['stop_loss'].max()),
            'position_size_range': (adjustments_df['position_size'].min(), adjustments_df['position_size'].max())
        }
        
        print("ğŸ“Š é£é™©è°ƒæ•´æ•ˆæœè¯„ä¼°:")
        print(f"   æ€»è°ƒæ•´æ¬¡æ•°: {stats['total_adjustments']}")
        print(f"   å¹³å‡è°ƒæ•´å› å­: {stats['avg_adjustment_factor']:.3f}")
        print(f"   è°ƒæ•´æ³¢åŠ¨æ€§: {stats['adjustment_volatility']:.3f}")
        print(f"   æ­¢æŸèŒƒå›´: {stats['stop_loss_range'][0]:.3f} - {stats['stop_loss_range'][1]:.3f}")
        print(f"   ä»“ä½èŒƒå›´: {stats['position_size_range'][0]:.3f} - {stats['position_size_range'][1]:.3f}")
        
        return stats
    
    def visualize_risk_adaptation(self):
        """å¯è§†åŒ–é£é™©è‡ªé€‚åº”è¿‡ç¨‹"""
        if len(self.risk_adjustments_history) < 5:
            print("âš ï¸  è°ƒæ•´å†å²ä¸è¶³ï¼Œæ— æ³•å¯è§†åŒ–")
            return
        
        # å‡†å¤‡æ•°æ®
        timestamps = [record['timestamp'] for record in self.risk_adjustments_history]
        total_factors = [record['total_factor'] for record in self.risk_adjustments_history]
        stop_losses = [record['new_params']['stop_loss'] for record in self.risk_adjustments_history]
        position_sizes = [record['new_params']['max_position_size'] for record in self.risk_adjustments_history]
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('è‡ªé€‚åº”é£é™©ç®¡ç†å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        # 1. è°ƒæ•´å› å­æ—¶é—´åºåˆ—
        axes[0, 0].plot(timestamps, total_factors, 'b-', linewidth=2, marker='o')
        axes[0, 0].axhline(y=1.0, color='r', linestyle='--', alpha=0.7, label='åŸºå‡†çº¿')
        axes[0, 0].set_title('é£é™©è°ƒæ•´å› å­å˜åŒ–')
        axes[0, 0].set_ylabel('è°ƒæ•´å› å­')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. æ­¢æŸå‚æ•°å˜åŒ–
        axes[0, 1].plot(timestamps, stop_losses, 'r-', linewidth=2, marker='s')
        axes[0, 1].axhline(y=self.base_params['stop_loss'], color='g', linestyle='--', alpha=0.7, label='åŸºå‡†æ­¢æŸ')
        axes[0, 1].set_title('åŠ¨æ€æ­¢æŸå‚æ•°')
        axes[0, 1].set_ylabel('æ­¢æŸæ¯”ä¾‹')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ä»“ä½å¤§å°å˜åŒ–
        axes[1, 0].plot(timestamps, position_sizes, 'g-', linewidth=2, marker='^')
        axes[1, 0].axhline(y=self.base_params['max_position_size'], color='b', linestyle='--', alpha=0.7, label='åŸºå‡†ä»“ä½')
        axes[1, 0].set_title('åŠ¨æ€ä»“ä½å¤§å°')
        axes[1, 0].set_ylabel('æœ€å¤§ä»“ä½æ¯”ä¾‹')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. è°ƒæ•´å› å­åˆ†å¸ƒ
        axes[1, 1].hist(total_factors, bins=15, alpha=0.7, color='purple', edgecolor='black')
        axes[1, 1].axvline(x=np.mean(total_factors), color='red', linestyle='--', label=f'å‡å€¼: {np.mean(total_factors):.3f}')
        axes[1, 1].set_title('è°ƒæ•´å› å­åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('è°ƒæ•´å› å­')
        axes[1, 1].set_ylabel('é¢‘æ¬¡')
        axes[1, 1].legend()
        
        plt.tight_layout()
        plt.savefig('/tmp/adaptive_risk_management.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“Š é£é™©è‡ªé€‚åº”å¯è§†åŒ–å·²ä¿å­˜è‡³: /tmp/adaptive_risk_management.png")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºè‡ªé€‚åº”é£é™©ç®¡ç†"""
    print("ğŸ›¡ï¸  è‡ªé€‚åº”é£é™©ç®¡ç†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºé£é™©ç®¡ç†å™¨
    risk_manager = AdaptiveRiskManager()
    
    # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®
    np.random.seed(42)
    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')
    
    # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
    returns = np.random.normal(0.001, 0.02, len(dates))
    prices = 100 * np.exp(np.cumsum(returns))
    volumes = np.random.lognormal(15, 0.5, len(dates))
    
    market_data = pd.DataFrame({
        'Date': dates,
        'Close': prices,
        'High': prices * (1 + np.abs(np.random.normal(0, 0.01, len(dates)))),
        'Low': prices * (1 - np.abs(np.random.normal(0, 0.01, len(dates)))),
        'Volume': volumes
    }).set_index('Date')
    
    # è®­ç»ƒæ¨¡å‹
    risk_manager.train_volatility_predictor(market_data)
    risk_manager.train_regime_classifier(market_data)
    risk_manager.train_anomaly_detector(market_data)
    
    # æ¨¡æ‹Ÿå®æ—¶é£é™©è°ƒæ•´
    print("\nğŸ”„ æ¨¡æ‹Ÿå®æ—¶é£é™©è°ƒæ•´...")
    
    for i in range(10):
        # è·å–å½“å‰æ•°æ®çª—å£
        current_window = market_data.iloc[max(0, -50-i*10):-i*10] if i > 0 else market_data.iloc[-50:]
        
        # æ¨¡æ‹Ÿè¡¨ç°æŒ‡æ ‡
        performance_metrics = {
            'recent_sharpe': np.random.normal(1.5, 0.5),
            'recent_drawdown': abs(np.random.normal(0.05, 0.03))
        }
        
        # è·å–åŠ¨æ€é£é™©å‚æ•°
        risk_result = risk_manager.get_dynamic_risk_params(current_window, performance_metrics)
        
        print(f"\nè°ƒæ•´ {i+1}:")
        print(f"   å¸‚åœºçŠ¶æ€: {risk_result['market_state']['market_regime']}")
        print(f"   æ³¢åŠ¨ç‡é¢„æµ‹: {risk_result['market_state']['volatility_forecast']:.3f}")
        print(f"   é£é™©åˆ†æ•°: {risk_result['market_state']['risk_score']:.3f}")
        print(f"   æ­¢æŸ: {risk_result['risk_params']['stop_loss']:.3f}")
        print(f"   æ­¢ç›ˆ: {risk_result['risk_params']['take_profit']:.3f}")
        print(f"   æœ€å¤§ä»“ä½: {risk_result['risk_params']['max_position_size']:.3f}")
    
    # è¯„ä¼°è°ƒæ•´æ•ˆæœ
    print("\nğŸ“Š è¯„ä¼°é£é™©è°ƒæ•´æ•ˆæœ...")
    risk_manager.evaluate_risk_adjustment_performance()
    
    # å¯è§†åŒ–ç»“æœ
    risk_manager.visualize_risk_adaptation()
    
    print("\nğŸš€ è‡ªé€‚åº”é£é™©ç®¡ç†æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()