#!/usr/bin/env python3
"""
MLå¢å¼ºçš„å›æµ‹éªŒè¯æ¡†æ¶
åŒ…å«è¿‡æ‹Ÿåˆæ£€æµ‹ã€äº¤å‰éªŒè¯ã€ç¨³å¥æ€§æµ‹è¯•ç­‰åŠŸèƒ½
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# MLç›¸å…³åº“
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib

# ç»Ÿè®¡æµ‹è¯•
from scipy import stats
from scipy.stats import jarque_bera, shapiro, kstest

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append('.')

class MLBacktestFramework:
    """MLå¢å¼ºçš„å›æµ‹éªŒè¯æ¡†æ¶"""
    
    def __init__(self, strategy_func=None):
        self.strategy_func = strategy_func
        self.backtest_results = {}
        self.validation_results = {}
        self.overfitting_metrics = {}
        self.robustness_tests = {}
        
        # éªŒè¯é…ç½®
        self.validation_config = {
            'n_splits': 5,              # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯æŠ˜æ•°
            'test_size_ratio': 0.2,     # æµ‹è¯•é›†æ¯”ä¾‹
            'walk_forward_steps': 10,   # å‰å‘éªŒè¯æ­¥æ•°
            'bootstrap_samples': 100,   # è‡ªåŠ©æ³•æ ·æœ¬æ•°
            'monte_carlo_runs': 1000    # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ¬¡æ•°
        }
        
        # è¿‡æ‹Ÿåˆæ£€æµ‹é˜ˆå€¼
        self.overfitting_thresholds = {
            'performance_degradation': 0.3,  # æ ·æœ¬å¤–è¡¨ç°ä¸‹é™é˜ˆå€¼
            'stability_threshold': 0.5,      # ç¨³å®šæ€§é˜ˆå€¼
            'complexity_penalty': 0.1        # å¤æ‚åº¦æƒ©ç½š
        }
    
    def time_series_cross_validation(self, data, strategy_params):
        """æ—¶é—´åºåˆ—äº¤å‰éªŒè¯"""
        print("ğŸ”„ æ‰§è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
        
        # åˆ›å»ºæ—¶é—´åºåˆ—åˆ†å‰²å™¨
        tscv = TimeSeriesSplit(n_splits=self.validation_config['n_splits'])
        
        cv_results = []
        fold_performances = []
        
        for fold, (train_idx, test_idx) in enumerate(tscv.split(data)):
            print(f"   å¤„ç†ç¬¬ {fold + 1}/{self.validation_config['n_splits']} æŠ˜...")
            
            # åˆ†å‰²æ•°æ®
            train_data = data.iloc[train_idx]
            test_data = data.iloc[test_idx]
            
            # åœ¨è®­ç»ƒé›†ä¸Šè¿è¡Œç­–ç•¥
            if self.strategy_func:
                train_result = self.strategy_func(train_data, strategy_params)
                test_result = self.strategy_func(test_data, strategy_params)
            else:
                # æ¨¡æ‹Ÿç­–ç•¥ç»“æœ
                train_result = self._simulate_strategy_result(train_data, strategy_params)
                test_result = self._simulate_strategy_result(test_data, strategy_params)
            
            # è®°å½•ç»“æœ
            fold_result = {
                'fold': fold + 1,
                'train_period': (train_data.index[0], train_data.index[-1]),
                'test_period': (test_data.index[0], test_data.index[-1]),
                'train_performance': train_result,
                'test_performance': test_result,
                'performance_ratio': test_result['total_return'] / max(train_result['total_return'], 0.001)
            }
            
            cv_results.append(fold_result)
            fold_performances.append({
                'fold': fold + 1,
                'train_return': train_result['total_return'],
                'test_return': test_result['total_return'],
                'train_sharpe': train_result['sharpe_ratio'],
                'test_sharpe': test_result['sharpe_ratio'],
                'train_drawdown': train_result['max_drawdown'],
                'test_drawdown': test_result['max_drawdown']
            })
        
        # æ±‡æ€»äº¤å‰éªŒè¯ç»“æœ
        cv_summary = self._summarize_cv_results(fold_performances)
        
        self.validation_results['time_series_cv'] = {
            'fold_results': cv_results,
            'summary': cv_summary
        }
        
        return cv_summary
    
    def walk_forward_analysis(self, data, strategy_params):
        """å‰å‘åˆ†æéªŒè¯"""
        print("ğŸš¶ æ‰§è¡Œå‰å‘åˆ†æéªŒè¯...")
        
        n_steps = self.validation_config['walk_forward_steps']
        step_size = len(data) // (n_steps + 1)
        
        wf_results = []
        
        for step in range(n_steps):
            # è®¡ç®—è®­ç»ƒå’Œæµ‹è¯•çª—å£
            train_start = 0
            train_end = (step + 1) * step_size
            test_start = train_end
            test_end = min(test_start + step_size, len(data))
            
            if test_end <= test_start:
                break
            
            print(f"   æ­¥éª¤ {step + 1}/{n_steps}: è®­ç»ƒ {train_start}-{train_end}, æµ‹è¯• {test_start}-{test_end}")
            
            # åˆ†å‰²æ•°æ®
            train_data = data.iloc[train_start:train_end]
            test_data = data.iloc[test_start:test_end]
            
            # è¿è¡Œç­–ç•¥
            if self.strategy_func:
                train_result = self.strategy_func(train_data, strategy_params)
                test_result = self.strategy_func(test_data, strategy_params)
            else:
                train_result = self._simulate_strategy_result(train_data, strategy_params)
                test_result = self._simulate_strategy_result(test_data, strategy_params)
            
            wf_results.append({
                'step': step + 1,
                'train_period': (train_data.index[0], train_data.index[-1]),
                'test_period': (test_data.index[0], test_data.index[-1]),
                'train_return': train_result['total_return'],
                'test_return': test_result['total_return'],
                'train_sharpe': train_result['sharpe_ratio'],
                'test_sharpe': test_result['sharpe_ratio'],
                'performance_consistency': abs(test_result['sharpe_ratio'] - train_result['sharpe_ratio'])
            })
        
        # åˆ†æå‰å‘éªŒè¯ç»“æœ
        wf_summary = self._analyze_walk_forward_results(wf_results)
        
        self.validation_results['walk_forward'] = {
            'step_results': wf_results,
            'summary': wf_summary
        }
        
        return wf_summary
    
    def bootstrap_validation(self, data, strategy_params):
        """è‡ªåŠ©æ³•éªŒè¯"""
        print("ğŸ² æ‰§è¡Œè‡ªåŠ©æ³•éªŒè¯...")
        
        n_samples = self.validation_config['bootstrap_samples']
        bootstrap_results = []
        
        for i in range(n_samples):
            if (i + 1) % 20 == 0:
                print(f"   å®Œæˆ {i + 1}/{n_samples} ä¸ªè‡ªåŠ©æ ·æœ¬...")
            
            # ç”Ÿæˆè‡ªåŠ©æ ·æœ¬
            bootstrap_data = data.sample(n=len(data), replace=True).sort_index()
            
            # è¿è¡Œç­–ç•¥
            if self.strategy_func:
                result = self.strategy_func(bootstrap_data, strategy_params)
            else:
                result = self._simulate_strategy_result(bootstrap_data, strategy_params)
            
            bootstrap_results.append({
                'sample': i + 1,
                'total_return': result['total_return'],
                'sharpe_ratio': result['sharpe_ratio'],
                'max_drawdown': result['max_drawdown'],
                'win_rate': result.get('win_rate', 0.5)
            })
        
        # åˆ†æè‡ªåŠ©æ³•ç»“æœ
        bootstrap_summary = self._analyze_bootstrap_results(bootstrap_results)
        
        self.validation_results['bootstrap'] = {
            'sample_results': bootstrap_results,
            'summary': bootstrap_summary
        }
        
        return bootstrap_summary
    
    def detect_overfitting(self):
        """æ£€æµ‹è¿‡æ‹Ÿåˆ"""
        print("ğŸ” æ£€æµ‹ç­–ç•¥è¿‡æ‹Ÿåˆ...")
        
        overfitting_signals = {}
        
        # 1. æ ·æœ¬å†…å¤–è¡¨ç°å·®å¼‚æ£€æµ‹
        if 'time_series_cv' in self.validation_results:
            cv_results = self.validation_results['time_series_cv']['summary']
            
            # è®¡ç®—è¡¨ç°ä¸‹é™ç¨‹åº¦
            train_test_ratio = cv_results['avg_test_return'] / max(cv_results['avg_train_return'], 0.001)
            performance_degradation = 1 - train_test_ratio
            
            overfitting_signals['performance_degradation'] = {
                'value': performance_degradation,
                'threshold': self.overfitting_thresholds['performance_degradation'],
                'is_overfitted': performance_degradation > self.overfitting_thresholds['performance_degradation']
            }
        
        # 2. ç¨³å®šæ€§æ£€æµ‹
        if 'walk_forward' in self.validation_results:
            wf_results = self.validation_results['walk_forward']['step_results']
            test_returns = [r['test_return'] for r in wf_results]
            
            # è®¡ç®—æ”¶ç›Šç‡ç¨³å®šæ€§
            return_stability = np.std(test_returns) / max(np.mean(test_returns), 0.001)
            
            overfitting_signals['stability'] = {
                'value': return_stability,
                'threshold': self.overfitting_thresholds['stability_threshold'],
                'is_overfitted': return_stability > self.overfitting_thresholds['stability_threshold']
            }
        
        # 3. è‡ªåŠ©æ³•ä¸€è‡´æ€§æ£€æµ‹
        if 'bootstrap' in self.validation_results:
            bootstrap_summary = self.validation_results['bootstrap']['summary']
            
            # æ£€æŸ¥ç½®ä¿¡åŒºé—´æ˜¯å¦åŒ…å«é›¶
            return_ci = bootstrap_summary['return_confidence_interval']
            sharpe_ci = bootstrap_summary['sharpe_confidence_interval']
            
            overfitting_signals['bootstrap_consistency'] = {
                'return_includes_zero': return_ci[0] <= 0 <= return_ci[1],
                'sharpe_includes_zero': sharpe_ci[0] <= 0 <= sharpe_ci[1],
                'is_overfitted': return_ci[0] <= 0 or sharpe_ci[0] <= 0
            }
        
        # 4. ç»¼åˆè¿‡æ‹Ÿåˆè¯„åˆ†
        overfitting_score = 0
        total_signals = 0
        
        for signal_name, signal_data in overfitting_signals.items():
            if isinstance(signal_data, dict) and 'is_overfitted' in signal_data:
                if signal_data['is_overfitted']:
                    overfitting_score += 1
                total_signals += 1
        
        overall_overfitting = {
            'overfitting_score': overfitting_score / max(total_signals, 1),
            'is_likely_overfitted': overfitting_score / max(total_signals, 1) > 0.5,
            'signals': overfitting_signals
        }
        
        self.overfitting_metrics = overall_overfitting
        
        print(f"   è¿‡æ‹Ÿåˆè¯„åˆ†: {overall_overfitting['overfitting_score']:.2f}")
        print(f"   å¯èƒ½è¿‡æ‹Ÿåˆ: {'æ˜¯' if overall_overfitting['is_likely_overfitted'] else 'å¦'}")
        
        return overall_overfitting
    
    def robustness_testing(self, data, base_params):
        """ç¨³å¥æ€§æµ‹è¯•"""
        print("ğŸ›¡ï¸  æ‰§è¡Œç¨³å¥æ€§æµ‹è¯•...")
        
        robustness_results = {}
        
        # 1. å‚æ•°æ•æ„Ÿæ€§æµ‹è¯•
        param_sensitivity = self._test_parameter_sensitivity(data, base_params)
        robustness_results['parameter_sensitivity'] = param_sensitivity
        
        # 2. æ•°æ®æ‰°åŠ¨æµ‹è¯•
        noise_robustness = self._test_noise_robustness(data, base_params)
        robustness_results['noise_robustness'] = noise_robustness
        
        # 3. å­æœŸé—´ç¨³å®šæ€§æµ‹è¯•
        period_stability = self._test_period_stability(data, base_params)
        robustness_results['period_stability'] = period_stability
        
        # 4. å¸‚åœºåˆ¶åº¦ç¨³å®šæ€§æµ‹è¯•
        market_regime_stability = self._test_market_regime_stability(data, base_params)
        robustness_results['market_regime_stability'] = market_regime_stability
        
        # 5. å¸‚åœºçŠ¶æ€é€‚åº”æ€§æµ‹è¯•
        market_adaptability = self._test_market_adaptability(data, base_params)
        robustness_results['market_adaptability'] = market_adaptability
        
        self.robustness_tests = robustness_results
        
        return robustness_results
    
    def _simulate_strategy_result(self, data, params):
        """æ¨¡æ‹Ÿç­–ç•¥ç»“æœï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        # ç®€å•çš„å‡å€¼å›å½’ç­–ç•¥æ¨¡æ‹Ÿ
        returns = data['Close'].pct_change().dropna()
        
        # æ¨¡æ‹Ÿäº¤æ˜“ä¿¡å·
        signals = np.random.choice([-1, 0, 1], size=len(returns), p=[0.3, 0.4, 0.3])
        strategy_returns = signals[:-1] * returns.values[1:] * 0.5  # 50%ä»“ä½
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_return = np.prod(1 + strategy_returns) - 1
        sharpe_ratio = np.mean(strategy_returns) / max(np.std(strategy_returns), 0.001) * np.sqrt(252)
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        cumulative = np.cumprod(1 + strategy_returns)
        running_max = np.maximum.accumulate(cumulative)
        drawdowns = (cumulative - running_max) / running_max
        max_drawdown = np.min(drawdowns)
        
        return {
            'total_return': total_return,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': abs(max_drawdown),
            'win_rate': (strategy_returns > 0).mean()
        }
    
    def _summarize_cv_results(self, fold_performances):
        """æ±‡æ€»äº¤å‰éªŒè¯ç»“æœ"""
        df = pd.DataFrame(fold_performances)
        
        return {
            'n_folds': len(df),
            'avg_train_return': df['train_return'].mean(),
            'avg_test_return': df['test_return'].mean(),
            'avg_train_sharpe': df['train_sharpe'].mean(),
            'avg_test_sharpe': df['test_sharpe'].mean(),
            'return_consistency': df['test_return'].std(),
            'sharpe_consistency': df['test_sharpe'].std(),
            'performance_degradation': 1 - (df['test_return'].mean() / max(df['train_return'].mean(), 0.001))
        }
    
    def _analyze_walk_forward_results(self, wf_results):
        """åˆ†æå‰å‘éªŒè¯ç»“æœ"""
        df = pd.DataFrame(wf_results)
        
        return {
            'n_steps': len(df),
            'avg_test_return': df['test_return'].mean(),
            'avg_test_sharpe': df['test_sharpe'].mean(),
            'return_trend': stats.linregress(range(len(df)), df['test_return']).slope,
            'sharpe_trend': stats.linregress(range(len(df)), df['test_sharpe']).slope,
            'consistency_score': 1 / (1 + df['performance_consistency'].mean())
        }
    
    def _analyze_bootstrap_results(self, bootstrap_results):
        """åˆ†æè‡ªåŠ©æ³•ç»“æœ"""
        df = pd.DataFrame(bootstrap_results)
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        return_ci = np.percentile(df['total_return'], [2.5, 97.5])
        sharpe_ci = np.percentile(df['sharpe_ratio'], [2.5, 97.5])
        drawdown_ci = np.percentile(df['max_drawdown'], [2.5, 97.5])
        
        return {
            'mean_return': df['total_return'].mean(),
            'mean_sharpe': df['sharpe_ratio'].mean(),
            'mean_drawdown': df['max_drawdown'].mean(),
            'return_confidence_interval': return_ci,
            'sharpe_confidence_interval': sharpe_ci,
            'drawdown_confidence_interval': drawdown_ci,
            'return_stability': df['total_return'].std(),
            'positive_return_probability': (df['total_return'] > 0).mean()
        }
    
    def _test_parameter_sensitivity(self, data, base_params):
        """æµ‹è¯•å‚æ•°æ•æ„Ÿæ€§"""
        sensitivity_results = {}
        
        # å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œæ•æ„Ÿæ€§æµ‹è¯•
        for param_name, base_value in base_params.items():
            if isinstance(base_value, (int, float)):
                # æµ‹è¯•å‚æ•°å˜åŒ–å¯¹ç»“æœçš„å½±å“
                param_variations = [0.8, 0.9, 1.0, 1.1, 1.2]  # Â±20%å˜åŒ–
                variation_results = []
                
                for variation in param_variations:
                    test_params = base_params.copy()
                    test_params[param_name] = base_value * variation
                    
                    result = self._simulate_strategy_result(data, test_params)
                    variation_results.append({
                        'variation': variation,
                        'return': result['total_return'],
                        'sharpe': result['sharpe_ratio']
                    })
                
                # è®¡ç®—æ•æ„Ÿæ€§æŒ‡æ ‡
                returns = [r['return'] for r in variation_results]
                sensitivity_score = np.std(returns) / max(np.mean(returns), 0.001)
                
                sensitivity_results[param_name] = {
                    'variations': variation_results,
                    'sensitivity_score': sensitivity_score,
                    'is_sensitive': sensitivity_score > 0.5
                }
        
        return sensitivity_results
    
    def _test_noise_robustness(self, data, params):
        """æµ‹è¯•å™ªéŸ³ç¨³å¥æ€§"""
        noise_levels = [0.01, 0.02, 0.05, 0.1]  # ä¸åŒå™ªéŸ³æ°´å¹³
        noise_results = []
        
        for noise_level in noise_levels:
            # æ·»åŠ å™ªéŸ³åˆ°ä»·æ ¼æ•°æ®
            noisy_data = data.copy()
            noise = np.random.normal(0, noise_level, len(data))
            noisy_data['Close'] = data['Close'] * (1 + noise)
            
            # æµ‹è¯•ç­–ç•¥è¡¨ç°
            result = self._simulate_strategy_result(noisy_data, params)
            noise_results.append({
                'noise_level': noise_level,
                'return': result['total_return'],
                'sharpe': result['sharpe_ratio']
            })
        
        # è®¡ç®—ç¨³å¥æ€§åˆ†æ•°
        returns = [r['return'] for r in noise_results]
        robustness_score = 1 - (np.std(returns) / max(np.mean(returns), 0.001))
        
        return {
            'noise_tests': noise_results,
            'robustness_score': max(0, robustness_score),
            'is_robust': robustness_score > 0.7
        }
    
    def _test_period_stability(self, data, params):
        """æµ‹è¯•å­æœŸé—´ç¨³å®šæ€§"""
        # å°†æ•°æ®åˆ†æˆ4ä¸ªå­æœŸé—´
        n_periods = 4
        period_size = len(data) // n_periods
        period_results = []
        
        for i in range(n_periods):
            start_idx = i * period_size
            end_idx = (i + 1) * period_size if i < n_periods - 1 else len(data)
            
            period_data = data.iloc[start_idx:end_idx]
            result = self._simulate_strategy_result(period_data, params)
            
            period_results.append({
                'period': i + 1,
                'start_date': period_data.index[0],
                'end_date': period_data.index[-1],
                'return': result['total_return'],
                'sharpe': result['sharpe_ratio']
            })
        
        # è®¡ç®—æœŸé—´ç¨³å®šæ€§
        returns = [r['return'] for r in period_results]
        stability_score = 1 - (np.std(returns) / max(np.mean(returns), 0.001))
        
        return {
            'period_results': period_results,
            'stability_score': max(0, stability_score),
            'is_stable': stability_score > 0.6
        }
    
    def _test_market_regime_stability(self, data, params):
        """æµ‹è¯•ç­–ç•¥åœ¨ä¸åŒå¸‚åœºåˆ¶åº¦ä¸‹çš„ç¨³å®šæ€§"""
        # åŸºäºæ³¢åŠ¨ç‡åˆ†ç±»å¸‚åœºçŠ¶æ€
        returns = data['Close'].pct_change().dropna()
        volatility = returns.rolling(window=20).std().dropna()
        
        # ç¡®ä¿ç´¢å¼•å¯¹é½
        valid_idx = volatility.index
        data_aligned = data.loc[valid_idx]
        
        # å®šä¹‰å¸‚åœºçŠ¶æ€
        vol_low = volatility.quantile(0.33)
        vol_high = volatility.quantile(0.67)
        
        market_states = []
        for vol in volatility:
            if vol <= vol_low:
                market_states.append('low_vol')
            elif vol >= vol_high:
                market_states.append('high_vol')
            else:
                market_states.append('normal')
        
        # æµ‹è¯•æ¯ä¸ªå¸‚åœºçŠ¶æ€ä¸‹çš„è¡¨ç°
        state_results = {}
        for state in ['low_vol', 'normal', 'high_vol']:
            state_mask = pd.Series(market_states, index=valid_idx) == state
            if state_mask.sum() > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                state_data = data_aligned[state_mask]
                result = self._simulate_strategy_result(state_data, params)
                state_results[state] = result
        
        return state_results
    
    def _test_market_adaptability(self, data, params):
        """æµ‹è¯•ç­–ç•¥åœ¨ä¸åŒå¸‚åœºçŠ¶æ€ä¸‹çš„é€‚åº”æ€§"""
        results = {}
        
        # è®¡ç®—å¸‚åœºçŠ¶æ€æŒ‡æ ‡
        volatility = data['Close'].rolling(20).std()
        trend = data['Close'].rolling(20).apply(lambda x: (x[-1] - x[0]) / x[0])
        
        # åˆ é™¤NaNå€¼ä»¥ç¡®ä¿ç´¢å¼•å¯¹é½
        valid_idx = ~(volatility.isna() | trend.isna())
        data_clean = data[valid_idx].copy()
        volatility_clean = volatility[valid_idx]
        trend_clean = trend[valid_idx]
        
        # å®šä¹‰å¸‚åœºçŠ¶æ€
        vol_threshold = volatility_clean.quantile(0.5)
        trend_threshold = 0.02
        
        states = {
            'high_vol_bull': (volatility_clean > vol_threshold) & (trend_clean > trend_threshold),
            'high_vol_bear': (volatility_clean > vol_threshold) & (trend_clean < -trend_threshold),
            'low_vol_bull': (volatility_clean <= vol_threshold) & (trend_clean > trend_threshold),
            'low_vol_bear': (volatility_clean <= vol_threshold) & (trend_clean < -trend_threshold)
        }
        
        state_results = {}
        for state_name, state_mask in states.items():
            if state_mask.sum() > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
                state_data = data_clean[state_mask]
                performance = self._simulate_strategy_result(state_data, params)
                state_results[state_name] = performance
        
        # è®¡ç®—é€‚åº”æ€§åˆ†æ•°
        if len(state_results) >= 2:
            returns = [r['total_return'] for r in state_results.values()]
            adaptability_score = 1 - (np.std(returns) / max(np.mean(returns), 0.001))
        else:
            adaptability_score = 0.5
        
        return {
            'state_results': state_results,
            'adaptability_score': max(0, adaptability_score),
            'is_adaptable': adaptability_score > 0.5
        }
    
    def generate_validation_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\nğŸ“Š ç”ŸæˆMLå¢å¼ºå›æµ‹éªŒè¯æŠ¥å‘Š...")
        
        report = {
            'timestamp': datetime.now(),
            'validation_summary': {},
            'overfitting_analysis': self.overfitting_metrics,
            'robustness_analysis': self.robustness_tests,
            'recommendations': []
        }
        
        # æ±‡æ€»éªŒè¯ç»“æœ
        if 'time_series_cv' in self.validation_results:
            cv_summary = self.validation_results['time_series_cv']['summary']
            report['validation_summary']['cross_validation'] = {
                'avg_test_return': cv_summary['avg_test_return'],
                'avg_test_sharpe': cv_summary['avg_test_sharpe'],
                'performance_degradation': cv_summary['performance_degradation']
            }
        
        if 'walk_forward' in self.validation_results:
            wf_summary = self.validation_results['walk_forward']['summary']
            report['validation_summary']['walk_forward'] = {
                'avg_test_return': wf_summary['avg_test_return'],
                'return_trend': wf_summary['return_trend'],
                'consistency_score': wf_summary['consistency_score']
            }
        
        if 'bootstrap' in self.validation_results:
            bs_summary = self.validation_results['bootstrap']['summary']
            report['validation_summary']['bootstrap'] = {
                'mean_return': bs_summary['mean_return'],
                'return_confidence_interval': bs_summary['return_confidence_interval'],
                'positive_return_probability': bs_summary['positive_return_probability']
            }
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        
        if self.overfitting_metrics.get('is_likely_overfitted', False):
            recommendations.append("âš ï¸  æ£€æµ‹åˆ°å¯èƒ½çš„è¿‡æ‹Ÿåˆï¼Œå»ºè®®ç®€åŒ–æ¨¡å‹æˆ–å¢åŠ æ­£åˆ™åŒ–")
        
        if 'parameter_sensitivity' in self.robustness_tests:
            sensitive_params = [
                param for param, data in self.robustness_tests['parameter_sensitivity'].items()
                if data.get('is_sensitive', False)
            ]
            if sensitive_params:
                recommendations.append(f"ğŸ”§ å‚æ•° {', '.join(sensitive_params)} è¾ƒä¸ºæ•æ„Ÿï¼Œéœ€è¦è°¨æ…è°ƒæ•´")
        
        if 'noise_robustness' in self.robustness_tests:
            if not self.robustness_tests['noise_robustness'].get('is_robust', True):
                recommendations.append("ğŸ›¡ï¸  ç­–ç•¥å¯¹å™ªéŸ³æ•æ„Ÿï¼Œå»ºè®®å¢åŠ æ»¤æ³¢æˆ–å¹³æ»‘æœºåˆ¶")
        
        report['recommendations'] = recommendations
        
        return report
    
    def visualize_validation_results(self):
        """å¯è§†åŒ–éªŒè¯ç»“æœ"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('MLå¢å¼ºå›æµ‹éªŒè¯ç»“æœ', fontsize=16, fontweight='bold')
        
        # 1. äº¤å‰éªŒè¯ç»“æœ
        if 'time_series_cv' in self.validation_results:
            cv_data = self.validation_results['time_series_cv']['fold_results']
            folds = [r['fold'] for r in cv_data]
            train_returns = [r['train_performance']['total_return'] for r in cv_data]
            test_returns = [r['test_performance']['total_return'] for r in cv_data]
            
            axes[0, 0].bar([f-0.2 for f in folds], train_returns, width=0.4, label='è®­ç»ƒé›†', alpha=0.7)
            axes[0, 0].bar([f+0.2 for f in folds], test_returns, width=0.4, label='æµ‹è¯•é›†', alpha=0.7)
            axes[0, 0].set_title('æ—¶é—´åºåˆ—äº¤å‰éªŒè¯')
            axes[0, 0].set_xlabel('æŠ˜æ•°')
            axes[0, 0].set_ylabel('æ”¶ç›Šç‡')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å‰å‘åˆ†æç»“æœ
        if 'walk_forward' in self.validation_results:
            wf_data = self.validation_results['walk_forward']['step_results']
            steps = [r['step'] for r in wf_data]
            test_returns = [r['test_return'] for r in wf_data]
            
            axes[0, 1].plot(steps, test_returns, 'o-', linewidth=2, markersize=6)
            axes[0, 1].set_title('å‰å‘åˆ†æéªŒè¯')
            axes[0, 1].set_xlabel('æ­¥éª¤')
            axes[0, 1].set_ylabel('æµ‹è¯•æ”¶ç›Šç‡')
            axes[0, 1].grid(True, alpha=0.3)
        
        # 3. è‡ªåŠ©æ³•ç»“æœåˆ†å¸ƒ
        if 'bootstrap' in self.validation_results:
            bs_data = self.validation_results['bootstrap']['sample_results']
            returns = [r['total_return'] for r in bs_data]
            
            axes[0, 2].hist(returns, bins=30, alpha=0.7, edgecolor='black')
            axes[0, 2].axvline(np.mean(returns), color='red', linestyle='--', label=f'å‡å€¼: {np.mean(returns):.3f}')
            axes[0, 2].set_title('è‡ªåŠ©æ³•æ”¶ç›Šç‡åˆ†å¸ƒ')
            axes[0, 2].set_xlabel('æ”¶ç›Šç‡')
            axes[0, 2].set_ylabel('é¢‘æ¬¡')
            axes[0, 2].legend()
        
        # 4. è¿‡æ‹Ÿåˆæ£€æµ‹
        if self.overfitting_metrics:
            signals = self.overfitting_metrics.get('signals', {})
            signal_names = []
            signal_values = []
            
            for name, data in signals.items():
                if isinstance(data, dict) and 'value' in data:
                    signal_names.append(name.replace('_', '\n'))
                    signal_values.append(data['value'])
            
            if signal_names:
                colors = ['red' if v > 0.5 else 'green' for v in signal_values]
                axes[1, 0].bar(signal_names, signal_values, color=colors, alpha=0.7)
                axes[1, 0].axhline(y=0.5, color='orange', linestyle='--', label='é£é™©é˜ˆå€¼')
                axes[1, 0].set_title('è¿‡æ‹Ÿåˆæ£€æµ‹ä¿¡å·')
                axes[1, 0].set_ylabel('é£é™©åˆ†æ•°')
                axes[1, 0].legend()
        
        # 5. ç¨³å¥æ€§æµ‹è¯•
        if 'parameter_sensitivity' in self.robustness_tests:
            param_data = self.robustness_tests['parameter_sensitivity']
            param_names = list(param_data.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ªå‚æ•°
            sensitivity_scores = [param_data[name]['sensitivity_score'] for name in param_names]
            
            colors = ['red' if s > 0.5 else 'green' for s in sensitivity_scores]
            axes[1, 1].bar(param_names, sensitivity_scores, color=colors, alpha=0.7)
            axes[1, 1].axhline(y=0.5, color='orange', linestyle='--', label='æ•æ„Ÿé˜ˆå€¼')
            axes[1, 1].set_title('å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
            axes[1, 1].set_ylabel('æ•æ„Ÿæ€§åˆ†æ•°')
            axes[1, 1].tick_params(axis='x', rotation=45)
            axes[1, 1].legend()
        
        # 6. ç»¼åˆè¯„ä¼°é›·è¾¾å›¾
        if self.validation_results and self.robustness_tests:
            # è®¡ç®—å„ç»´åº¦å¾—åˆ†
            scores = {}
            
            if 'time_series_cv' in self.validation_results:
                cv_score = 1 - self.validation_results['time_series_cv']['summary']['performance_degradation']
                scores['äº¤å‰éªŒè¯'] = max(0, min(1, cv_score))
            
            if 'walk_forward' in self.validation_results:
                wf_score = self.validation_results['walk_forward']['summary']['consistency_score']
                scores['å‰å‘åˆ†æ'] = max(0, min(1, wf_score))
            
            if 'bootstrap' in self.validation_results:
                bs_score = self.validation_results['bootstrap']['summary']['positive_return_probability']
                scores['è‡ªåŠ©æ³•'] = max(0, min(1, bs_score))
            
            if 'noise_robustness' in self.robustness_tests:
                scores['å™ªéŸ³ç¨³å¥æ€§'] = self.robustness_tests['noise_robustness']['robustness_score']
            
            if 'period_stability' in self.robustness_tests:
                scores['æœŸé—´ç¨³å®šæ€§'] = self.robustness_tests['period_stability']['stability_score']
            
            if scores:
                categories = list(scores.keys())
                values = list(scores.values())
                
                # åˆ›å»ºé›·è¾¾å›¾
                angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
                values += values[:1]  # é—­åˆå›¾å½¢
                angles = np.concatenate((angles, [angles[0]]))
                
                axes[1, 2].plot(angles, values, 'o-', linewidth=2, label='ç­–ç•¥å¾—åˆ†')
                axes[1, 2].fill(angles, values, alpha=0.25)
                axes[1, 2].set_xticks(angles[:-1])
                axes[1, 2].set_xticklabels(categories)
                axes[1, 2].set_ylim(0, 1)
                axes[1, 2].set_title('ç»¼åˆè¯„ä¼°é›·è¾¾å›¾')
                axes[1, 2].grid(True)
        
        plt.tight_layout()
        plt.savefig('/tmp/ml_backtest_validation.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“Š éªŒè¯ç»“æœå¯è§†åŒ–å·²ä¿å­˜è‡³: /tmp/ml_backtest_validation.png")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºMLå¢å¼ºå›æµ‹éªŒè¯æ¡†æ¶"""
    print("ğŸ§ª MLå¢å¼ºå›æµ‹éªŒè¯æ¡†æ¶æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºéªŒè¯æ¡†æ¶
    framework = MLBacktestFramework()
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range(start='2022-01-01', end='2024-01-01', freq='D')
    
    # ç”Ÿæˆæ›´çœŸå®çš„ä»·æ ¼æ•°æ®
    returns = np.random.normal(0.0005, 0.015, len(dates))  # æ—¥æ”¶ç›Šç‡
    # æ·»åŠ ä¸€äº›è¶‹åŠ¿å’Œå‘¨æœŸæ€§
    trend = np.linspace(0, 0.1, len(dates))
    cycle = 0.02 * np.sin(2 * np.pi * np.arange(len(dates)) / 252)  # å¹´åº¦å‘¨æœŸ
    returns += trend / len(dates) + cycle / len(dates)
    
    prices = 100 * np.exp(np.cumsum(returns))
    volumes = np.random.lognormal(15, 0.3, len(dates))
    
    market_data = pd.DataFrame({
        'Date': dates,
        'Close': prices,
        'High': prices * (1 + np.abs(np.random.normal(0, 0.005, len(dates)))),
        'Low': prices * (1 - np.abs(np.random.normal(0, 0.005, len(dates)))),
        'Volume': volumes
    }).set_index('Date')
    
    # æ¨¡æ‹Ÿç­–ç•¥å‚æ•°
    strategy_params = {
        'signal_threshold': 0.03,
        'stop_loss': 0.02,
        'take_profit': 0.06,
        'max_position_size': 0.3
    }
    
    print(f"ğŸ“Š æ•°æ®æœŸé—´: {market_data.index[0]} è‡³ {market_data.index[-1]}")
    print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {len(market_data)}")
    
    # æ‰§è¡Œå„ç§éªŒè¯
    print("\nğŸ”„ å¼€å§‹æ‰§è¡ŒMLå¢å¼ºéªŒè¯...")
    
    # 1. æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    cv_results = framework.time_series_cross_validation(market_data, strategy_params)
    print(f"   äº¤å‰éªŒè¯å¹³å‡æµ‹è¯•æ”¶ç›Šç‡: {cv_results['avg_test_return']:.3f}")
    print(f"   è¡¨ç°ä¸‹é™ç¨‹åº¦: {cv_results['performance_degradation']:.3f}")
    
    # 2. å‰å‘åˆ†æéªŒè¯
    wf_results = framework.walk_forward_analysis(market_data, strategy_params)
    print(f"   å‰å‘åˆ†æå¹³å‡æµ‹è¯•æ”¶ç›Šç‡: {wf_results['avg_test_return']:.3f}")
    print(f"   ä¸€è‡´æ€§å¾—åˆ†: {wf_results['consistency_score']:.3f}")
    
    # 3. è‡ªåŠ©æ³•éªŒè¯
    bs_results = framework.bootstrap_validation(market_data, strategy_params)
    print(f"   è‡ªåŠ©æ³•å¹³å‡æ”¶ç›Šç‡: {bs_results['mean_return']:.3f}")
    print(f"   æ­£æ”¶ç›Šæ¦‚ç‡: {bs_results['positive_return_probability']:.3f}")
    
    # 4. è¿‡æ‹Ÿåˆæ£€æµ‹
    overfitting_results = framework.detect_overfitting()
    
    # 5. ç¨³å¥æ€§æµ‹è¯•
    robustness_results = framework.robustness_testing(market_data, strategy_params)
    
    # 6. ç”ŸæˆéªŒè¯æŠ¥å‘Š
    report = framework.generate_validation_report()
    
    print("\nğŸ“‹ éªŒè¯æŠ¥å‘Šæ‘˜è¦:")
    print(f"   è¿‡æ‹Ÿåˆé£é™©: {'é«˜' if report['overfitting_analysis'].get('is_likely_overfitted', False) else 'ä½'}")
    
    if report['recommendations']:
        print("   å»ºè®®:")
        for rec in report['recommendations']:
            print(f"     {rec}")
    
    # 7. å¯è§†åŒ–ç»“æœ
    framework.visualize_validation_results()
    
    print("\nğŸš€ MLå¢å¼ºå›æµ‹éªŒè¯æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()