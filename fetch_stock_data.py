#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®æ‰¹é‡è·å–è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®å¹¶å­˜å‚¨åˆ°PostgreSQLæ•°æ®åº“ä¸­
æ”¯æŒå¤šç§æ•°æ®æºï¼šQlibã€yfinanceã€OpenBBç­‰
"""

import sys
import os
import time
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.data.data_manager import DataManager
from src.database.dao import stock_data_dao
from src.database.connection import get_db_session
import pandas as pd

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é»˜è®¤è‚¡ç¥¨åˆ—è¡¨
DEFAULT_SYMBOLS = [
    # ç§‘æŠ€è‚¡
    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',
    # é‡‘èè‚¡
    'JPM', 'BAC', 'WFC', 'GS', 'MS', 'V', 'MA', 'PYPL',
    # æ¶ˆè´¹è‚¡
    'JNJ', 'PG', 'KO', 'PEP', 'WMT', 'HD', 'MCD', 'NKE',
    # å·¥ä¸šè‚¡
    'BA', 'CAT', 'GE', 'MMM', 'UPS', 'HON', 'LMT', 'RTX',
    # åŒ»ç–—è‚¡
    'UNH', 'PFE', 'ABT', 'TMO', 'DHR', 'BMY', 'AMGN', 'GILD'
]

def fetch_and_store_stock_data(
    symbols: List[str] = None,
    start_date: str = None,
    end_date: str = None,
    batch_size: int = 5
) -> Dict[str, Any]:
    """
    æ‰¹é‡è·å–å¹¶å­˜å‚¨è‚¡ç¥¨æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨DEFAULT_SYMBOLS
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸º1å¹´å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        batch_size: æ‰¹å¤„ç†å¤§å°ï¼Œé¿å…APIé™åˆ¶
    
    Returns:
        åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
    """
    # è®¾ç½®é»˜è®¤å‚æ•°
    if symbols is None:
        symbols = DEFAULT_SYMBOLS
    
    if start_date is None:
        start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
    
    if end_date is None:
        end_date = datetime.now().strftime('%Y-%m-%d')
    
    logger.info(f"å¼€å§‹æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®")
    logger.info(f"è‚¡ç¥¨æ•°é‡: {len(symbols)}")
    logger.info(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
    logger.info(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    data_manager = DataManager()
    
    # ç»Ÿè®¡ä¿¡æ¯
    results = {
        'total_symbols': len(symbols),
        'successful': 0,
        'failed': 0,
        'total_records': 0,
        'failed_symbols': [],
        'processing_time': 0
    }
    
    start_time = time.time()
    
    try:
        # è·å–æ•°æ®åº“ä¼šè¯
        with get_db_session() as session:
            
            # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨
            for i in range(0, len(symbols), batch_size):
                batch_symbols = symbols[i:i + batch_size]
                logger.info(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {batch_symbols}")
                
                for symbol in batch_symbols:
                    try:
                        logger.info(f"è·å– {symbol} æ•°æ®...")
                        
                        # è·å–è‚¡ç¥¨æ•°æ®
                        stock_data = data_manager.get_stock_data(
                            symbol=symbol,
                            start_date=start_date,
                            end_date=end_date
                        )
                        
                        if stock_data is not None and not stock_data.empty:
                            # å‡†å¤‡æ•°æ®åº“è®°å½•
                            records = []
                            for date, row in stock_data.iterrows():
                                record_data = {
                                    'symbol': symbol,
                                    'date': date.date() if hasattr(date, 'date') else date,
                                    'open_price': float(row.get('Open', row.get('open', 0))),
                                    'high_price': float(row.get('High', row.get('high', 0))),
                                    'low_price': float(row.get('Low', row.get('low', 0))),
                                    'close_price': float(row.get('Close', row.get('close', 0))),
                                    'volume': int(row.get('Volume', row.get('volume', 0))),
                                    'adjusted_close': float(row.get('Adj Close', row.get('adj_close', row.get('Close', row.get('close', 0)))))
                                }
                                records.append(record_data)
                            
                            # æ‰¹é‡æ’å…¥æ•°æ®åº“
                            if records:
                                stock_data_dao.batch_create(records)
                                results['total_records'] += len(records)
                                logger.info(f"âœ… {symbol}: æˆåŠŸå­˜å‚¨ {len(records)} æ¡è®°å½•")
                                results['successful'] += 1
                            else:
                                logger.warning(f"âš ï¸ {symbol}: æ— æœ‰æ•ˆæ•°æ®")
                                results['failed'] += 1
                                results['failed_symbols'].append(symbol)
                        else:
                            logger.warning(f"âš ï¸ {symbol}: è·å–æ•°æ®å¤±è´¥æˆ–ä¸ºç©º")
                            results['failed'] += 1
                            results['failed_symbols'].append(symbol)
                    
                    except Exception as e:
                        logger.error(f"âŒ {symbol}: å¤„ç†å¤±è´¥ - {str(e)}")
                        results['failed'] += 1
                        results['failed_symbols'].append(symbol)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(0.5)
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                if i + batch_size < len(symbols):
                    logger.info("æ‰¹æ¬¡é—´ä¼‘æ¯2ç§’...")
                    time.sleep(2)
    
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}")
        raise
    
    # è®¡ç®—å¤„ç†æ—¶é—´
    results['processing_time'] = time.time() - start_time
    
    return results

def print_summary(results: Dict[str, Any]):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š è‚¡ç¥¨æ•°æ®è·å–ç»“æœæ‘˜è¦")
    print("="*60)
    print(f"ğŸ“ˆ æ€»è‚¡ç¥¨æ•°é‡: {results['total_symbols']}")
    print(f"âœ… æˆåŠŸè·å–: {results['successful']}")
    print(f"âŒ è·å–å¤±è´¥: {results['failed']}")
    print(f"ğŸ“„ æ€»è®°å½•æ•°: {results['total_records']:,}")
    print(f"â±ï¸ å¤„ç†æ—¶é—´: {results['processing_time']:.2f} ç§’")
    
    if results['failed_symbols']:
        print(f"\nâŒ å¤±è´¥çš„è‚¡ç¥¨ä»£ç :")
        for symbol in results['failed_symbols']:
            print(f"   - {symbol}")
    
    success_rate = (results['successful'] / results['total_symbols']) * 100
    print(f"\nğŸ¯ æˆåŠŸç‡: {success_rate:.1f}%")
    
    if results['total_records'] > 0:
        avg_records = results['total_records'] / results['successful']
        print(f"ğŸ“Š å¹³å‡æ¯è‚¡è®°å½•æ•°: {avg_records:.0f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è‚¡ç¥¨æ•°æ®æ‰¹é‡è·å–æµç¨‹...")
    
    try:
        # æ‰§è¡Œæ•°æ®è·å–
        results = fetch_and_store_stock_data(
            symbols=DEFAULT_SYMBOLS[:10],  # å…ˆæµ‹è¯•å‰10åªè‚¡ç¥¨
            start_date='2023-01-01',
            end_date='2024-01-01'
        )
        
        # æ‰“å°ç»“æœæ‘˜è¦
        print_summary(results)
        
        print("\nğŸ‰ è‚¡ç¥¨æ•°æ®è·å–æµç¨‹å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"æ•°æ®è·å–æµç¨‹å¤±è´¥: {str(e)}")
        print(f"\nâŒ æ•°æ®è·å–æµç¨‹å¤±è´¥: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)