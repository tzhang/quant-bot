#!/usr/bin/env python3
"""
ç´¢å¼•æ¯”è¾ƒè°ƒè¯•è„šæœ¬

ä¸“é—¨è°ƒè¯•IBæ•°æ®å’Œyfinanceæ•°æ®çš„ç´¢å¼•æ¯”è¾ƒé—®é¢˜

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import logging
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.data.ib_data_provider import create_ib_provider

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def debug_index_comparison():
    """è°ƒè¯•ç´¢å¼•æ¯”è¾ƒé—®é¢˜"""
    
    # æµ‹è¯•å‚æ•°
    symbol = 'AAPL'
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    
    print(f"ğŸ” è°ƒè¯•ç´¢å¼•æ¯”è¾ƒé—®é¢˜")
    print(f"ğŸ“Š è‚¡ç¥¨: {symbol}")
    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
    print("=" * 80)
    
    # è·å–æ•°æ®
    ib_provider = create_ib_provider()
    ib_data = ib_provider.get_stock_data(symbol, start_date, end_date)
    
    ticker = yf.Ticker(symbol)
    yf_data = ticker.history(start=start_date, end=end_date)
    yf_data.columns = [col.lower() for col in yf_data.columns]
    
    print(f"\nğŸ“ˆ æ•°æ®è·å–ç»“æœ:")
    print(f"   IBæ•°æ®: {len(ib_data)} æ¡è®°å½•")
    print(f"   YFæ•°æ®: {len(yf_data)} æ¡è®°å½•")
    
    # è¯¦ç»†æ£€æŸ¥ç´¢å¼•
    print(f"\nğŸ” ç´¢å¼•è¯¦ç»†åˆ†æ:")
    print(f"   IBç´¢å¼•ç±»å‹: {type(ib_data.index)}")
    print(f"   YFç´¢å¼•ç±»å‹: {type(yf_data.index)}")
    
    print(f"\n   IBç´¢å¼•å‰3ä¸ª:")
    for i, idx in enumerate(ib_data.index[:3]):
        print(f"     [{i}] {idx} (ç±»å‹: {type(idx)})")
    
    print(f"\n   YFç´¢å¼•å‰3ä¸ª:")
    for i, idx in enumerate(yf_data.index[:3]):
        print(f"     [{i}] {idx} (ç±»å‹: {type(idx)})")
    
    # æµ‹è¯•ç´¢å¼•äº¤é›†
    print(f"\nğŸ” ç´¢å¼•äº¤é›†æµ‹è¯•:")
    common_indices = ib_data.index.intersection(yf_data.index)
    print(f"   ç›´æ¥äº¤é›†æ•°é‡: {len(common_indices)}")
    
    if len(common_indices) > 0:
        print(f"   äº¤é›†ç¤ºä¾‹: {common_indices[:3].tolist()}")
    else:
        print("   âŒ æ²¡æœ‰ç›´æ¥äº¤é›†")
        
        # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
        print(f"\nğŸ” å°è¯•æ—¥æœŸè½¬æ¢æ¯”è¾ƒ:")
        
        # è½¬æ¢IBç´¢å¼•ä¸ºæ—¥æœŸ
        if hasattr(ib_data.index, 'date'):
            ib_dates = ib_data.index.date
        elif hasattr(ib_data.index, 'normalize'):
            ib_dates = ib_data.index.normalize()
        else:
            ib_dates = pd.to_datetime(ib_data.index).date
            
        # è½¬æ¢YFç´¢å¼•ä¸ºæ—¥æœŸ
        if hasattr(yf_data.index, 'date'):
            yf_dates = yf_data.index.date
        elif hasattr(yf_data.index, 'normalize'):
            yf_dates = yf_data.index.normalize()
        else:
            yf_dates = pd.to_datetime(yf_data.index).date
        
        print(f"   IBæ—¥æœŸç¤ºä¾‹: {ib_dates[:3] if hasattr(ib_dates, '__getitem__') else list(ib_dates)[:3]}")
        print(f"   YFæ—¥æœŸç¤ºä¾‹: {yf_dates[:3] if hasattr(yf_dates, '__getitem__') else list(yf_dates)[:3]}")
        
        # æ‰¾åˆ°å…±åŒæ—¥æœŸ
        ib_date_set = set(ib_dates) if hasattr(ib_dates, '__iter__') else {ib_dates}
        yf_date_set = set(yf_dates) if hasattr(yf_dates, '__iter__') else {yf_dates}
        
        common_dates = ib_date_set.intersection(yf_date_set)
        print(f"   å…±åŒæ—¥æœŸæ•°é‡: {len(common_dates)}")
        
        if common_dates:
            print(f"   å…±åŒæ—¥æœŸç¤ºä¾‹: {sorted(list(common_dates))[:3]}")
    
    # æµ‹è¯•æ—¶åŒºé—®é¢˜
    print(f"\nğŸ” æ—¶åŒºä¿¡æ¯:")
    print(f"   IBç´¢å¼•æ—¶åŒº: {getattr(ib_data.index, 'tz', 'None')}")
    print(f"   YFç´¢å¼•æ—¶åŒº: {getattr(yf_data.index, 'tz', 'None')}")
    
    # å°è¯•æ ‡å‡†åŒ–ç´¢å¼•
    print(f"\nğŸ” å°è¯•æ ‡å‡†åŒ–ç´¢å¼•:")
    try:
        # ç§»é™¤æ—¶åŒºä¿¡æ¯å¹¶æ ‡å‡†åŒ–ä¸ºæ—¥æœŸ
        ib_normalized = ib_data.copy()
        yf_normalized = yf_data.copy()
        
        # æ ‡å‡†åŒ–IBç´¢å¼•
        if hasattr(ib_normalized.index, 'tz_localize'):
            ib_normalized.index = ib_normalized.index.tz_localize(None)
        ib_normalized.index = pd.to_datetime(ib_normalized.index.date)
        
        # æ ‡å‡†åŒ–YFç´¢å¼•
        if hasattr(yf_normalized.index, 'tz_localize'):
            yf_normalized.index = yf_normalized.index.tz_localize(None)
        yf_normalized.index = pd.to_datetime(yf_normalized.index.date)
        
        # é‡æ–°æµ‹è¯•äº¤é›†
        normalized_common = ib_normalized.index.intersection(yf_normalized.index)
        print(f"   æ ‡å‡†åŒ–åäº¤é›†æ•°é‡: {len(normalized_common)}")
        
        if len(normalized_common) > 0:
            print(f"   æ ‡å‡†åŒ–åäº¤é›†ç¤ºä¾‹: {normalized_common[:3].tolist()}")
            
            # æµ‹è¯•æ•°æ®ä¸€è‡´æ€§
            print(f"\nğŸ“Š æ ‡å‡†åŒ–åæ•°æ®ä¸€è‡´æ€§æµ‹è¯•:")
            for date in normalized_common[:3]:
                ib_close = ib_normalized.loc[date, 'close']
                yf_close = yf_normalized.loc[date, 'close']
                diff = abs(ib_close - yf_close) / yf_close * 100
                print(f"   {date.date()}: IB={ib_close:.2f}, YF={yf_close:.2f}, å·®å¼‚={diff:.4f}%")
        
    except Exception as e:
        print(f"   æ ‡å‡†åŒ–å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)
    print("ğŸ” ç´¢å¼•æ¯”è¾ƒè°ƒè¯•å®Œæˆ")


if __name__ == "__main__":
    debug_index_comparison()