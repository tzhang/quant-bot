#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®ä¸€è‡´æ€§éªŒè¯ï¼ˆä½¿ç”¨æ¨¡æ‹ŸIBæ•°æ®ï¼‰

ä½¿ç”¨æ¨¡æ‹Ÿçš„IBæ•°æ®æ¥æµ‹è¯•ä¿®å¤åçš„æ•°æ®ä¸€è‡´æ€§éªŒè¯é€»è¾‘

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_mock_ib_data(symbol: str, days: int = 22) -> pd.DataFrame:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„IBæ•°æ® - ä»…ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    # ç”Ÿæˆæ—¥æœŸèŒƒå›´ - æ¨¡æ‹Ÿæ•°æ®ä»…ç”¨äºæµ‹è¯•
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # ç”Ÿæˆäº¤æ˜“æ—¥ï¼ˆæ’é™¤å‘¨æœ«ï¼‰- æ¨¡æ‹Ÿæ•°æ®ä»…ç”¨äºæ¼”ç¤º
    date_range = pd.bdate_range(start=start_date, end=end_date)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ® - ä»…ç”¨äºæµ‹è¯•
    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
    base_price = 150.0
    
    # ç”Ÿæˆéšæœºä»·æ ¼å˜åŒ– - æ¨¡æ‹Ÿæ•°æ®ä»…ç”¨äºæ¼”ç¤º
    price_changes = np.random.normal(0, 0.02, len(date_range))  # 2%æ ‡å‡†å·®
    prices = [base_price]
    
    for change in price_changes[1:]:
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)
    
    # åˆ›å»ºOHLCVæ•°æ® - æ¨¡æ‹Ÿæ•°æ®ä»…ç”¨äºæµ‹è¯•
    data = []
    for i, (date, close_price) in enumerate(zip(date_range, prices)):
        # ç”Ÿæˆå¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ä»· - æ¨¡æ‹Ÿæ•°æ®ä»…ç”¨äºæ¼”ç¤º
        open_price = close_price * (1 + np.random.normal(0, 0.005))
        high_price = max(open_price, close_price) * (1 + abs(np.random.normal(0, 0.01)))
        low_price = min(open_price, close_price) * (1 - abs(np.random.normal(0, 0.01)))
        volume = int(np.random.normal(1000000, 200000))  # å¹³å‡100ä¸‡è‚¡äº¤æ˜“é‡ - ä»…ç”¨äºæµ‹è¯•
        
        data.append({
            'open': open_price,
            'high': high_price,
            'low': low_price,
            'close': close_price,
            'volume': max(volume, 100000)  # ç¡®ä¿æœ€å°äº¤æ˜“é‡
        })
    
    df = pd.DataFrame(data, index=date_range)
    df.index.name = 'date'
    
    return df


def compare_price_data_fixed(data1: pd.DataFrame, data2: pd.DataFrame, 
                           source1: str, source2: str) -> dict:
    """ä¿®å¤åçš„ä»·æ ¼æ•°æ®æ¯”è¾ƒå‡½æ•°"""
    # æ ‡å‡†åŒ–ç´¢å¼•ä¸ºæ—¥æœŸï¼ˆç§»é™¤æ—¶åŒºä¿¡æ¯ï¼‰
    data1_normalized = data1.copy()
    data2_normalized = data2.copy()
    
    # æ ‡å‡†åŒ–ç´¢å¼•
    if hasattr(data1_normalized.index, 'tz_localize'):
        data1_normalized.index = data1_normalized.index.tz_localize(None)
    if hasattr(data2_normalized.index, 'tz_localize'):
        data2_normalized.index = data2_normalized.index.tz_localize(None)
    
    # è½¬æ¢ä¸ºæ—¥æœŸç´¢å¼•
    data1_normalized.index = pd.to_datetime(data1_normalized.index.date)
    data2_normalized.index = pd.to_datetime(data2_normalized.index.date)
    
    # æ‰¾åˆ°å…±åŒçš„æ—¥æœŸ
    common_dates = data1_normalized.index.intersection(data2_normalized.index)
    
    print(f"ğŸ“Š {source1} vs {source2} æ¯”è¾ƒ:")
    print(f"   {source1}æ•°æ®: {len(data1_normalized)} æ¡è®°å½•")
    print(f"   {source2}æ•°æ®: {len(data2_normalized)} æ¡è®°å½•")
    print(f"   å…±åŒæ—¥æœŸ: {len(common_dates)} ä¸ª")
    
    if len(common_dates) == 0:
        print("   âŒ æ²¡æœ‰å…±åŒæ—¥æœŸ")
        return {
            'common_dates': 0,
            'close_correlation': 0.0,
            'close_mean_diff_pct': 100.0,
            'volume_correlation': 0.0,
            'volume_mean_diff_pct': 100.0
        }
    
    # è·å–å…±åŒæ—¥æœŸçš„æ•°æ®
    df1_common = data1_normalized.loc[common_dates]
    df2_common = data2_normalized.loc[common_dates]
    
    # ä»·æ ¼æ¯”è¾ƒ
    close_corr = df1_common['close'].corr(df2_common['close'])
    close_diff_pct = abs((df1_common['close'] - df2_common['close']) / df1_common['close'] * 100).mean()
    
    # æˆäº¤é‡æ¯”è¾ƒ
    volume_corr = 0.0
    volume_diff_pct = 100.0
    
    if 'volume' in df1_common.columns and 'volume' in df2_common.columns:
        # è¿‡æ»¤æ‰é›¶æˆäº¤é‡çš„æ•°æ®
        valid_volume = (df1_common['volume'] > 0) & (df2_common['volume'] > 0)
        if valid_volume.sum() > 0:
            volume_corr = df1_common.loc[valid_volume, 'volume'].corr(
                df2_common.loc[valid_volume, 'volume']
            )
            volume_diff_pct = abs(
                (df1_common.loc[valid_volume, 'volume'] - df2_common.loc[valid_volume, 'volume']) / 
                df1_common.loc[valid_volume, 'volume'] * 100
            ).mean()
    
    print(f"   ğŸ“ˆ ä»·æ ¼ç›¸å…³æ€§: {close_corr:.4f}")
    print(f"   ğŸ“ˆ ä»·æ ¼å¹³å‡å·®å¼‚: {close_diff_pct:.2f}%")
    print(f"   ğŸ“Š æˆäº¤é‡ç›¸å…³æ€§: {volume_corr:.4f}")
    print(f"   ğŸ“Š æˆäº¤é‡å¹³å‡å·®å¼‚: {volume_diff_pct:.2f}%")
    
    return {
        'common_dates': len(common_dates),
        'close_correlation': close_corr if not np.isnan(close_corr) else 0.0,
        'close_mean_diff_pct': close_diff_pct if not np.isnan(close_diff_pct) else 100.0,
        'volume_correlation': volume_corr if not np.isnan(volume_corr) else 0.0,
        'volume_mean_diff_pct': volume_diff_pct if not np.isnan(volume_diff_pct) else 100.0
    }


def test_consistency_validation():
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§éªŒè¯"""
    symbol = 'AAPL'
    print(f"ğŸ” æµ‹è¯•æ•°æ®ä¸€è‡´æ€§éªŒè¯: {symbol}")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡æ‹ŸIBæ•°æ®
    print("ğŸ“Š åˆ›å»ºæ¨¡æ‹ŸIBæ•°æ®...")
    mock_ib_data = create_mock_ib_data(symbol)
    print(f"   âœ… æ¨¡æ‹ŸIBæ•°æ®åˆ›å»ºæˆåŠŸ: {len(mock_ib_data)} æ¡è®°å½•")
    print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {mock_ib_data.index.min()} åˆ° {mock_ib_data.index.max()}")
    
    # è·å–yfinanceæ•°æ®
    print("\nğŸ“Š è·å–yfinanceæ•°æ®...")
    try:
        ticker = yf.Ticker(symbol)
        yf_data = ticker.history(period='1mo')
        
        if not yf_data.empty:
            # æ ‡å‡†åŒ–åˆ—åä¸ºå°å†™
            yf_data.columns = [col.lower() for col in yf_data.columns]
            print(f"   âœ… yfinanceæ•°æ®è·å–æˆåŠŸ: {len(yf_data)} æ¡è®°å½•")
            print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {yf_data.index.min()} åˆ° {yf_data.index.max()}")
        else:
            print("   âŒ yfinanceæ•°æ®ä¸ºç©º")
            return
    except Exception as e:
        print(f"   âŒ yfinanceæ•°æ®è·å–å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•ä¿®å¤åçš„æ¯”è¾ƒé€»è¾‘
    print("\nğŸ” æµ‹è¯•ä¿®å¤åçš„æ¯”è¾ƒé€»è¾‘:")
    print("-" * 60)
    
    # æµ‹è¯•1: æ¨¡æ‹ŸIBæ•°æ® vs yfinanceæ•°æ®
    result1 = compare_price_data_fixed(mock_ib_data, yf_data, "Mock_IB", "yfinance")
    
    # æµ‹è¯•2: åˆ›å»ºç›¸åŒçš„æ•°æ®è¿›è¡Œæ¯”è¾ƒï¼ˆåº”è¯¥å®Œå…¨ä¸€è‡´ï¼‰
    print(f"\nğŸ” æµ‹è¯•ç›¸åŒæ•°æ®æ¯”è¾ƒï¼ˆåº”è¯¥å®Œå…¨ä¸€è‡´ï¼‰:")
    print("-" * 60)
    identical_data = mock_ib_data.copy()
    result2 = compare_price_data_fixed(mock_ib_data, identical_data, "Mock_IB", "Mock_IB_Copy")
    
    # æµ‹è¯•3: åˆ›å»ºè½»å¾®å·®å¼‚çš„æ•°æ®
    print(f"\nğŸ” æµ‹è¯•è½»å¾®å·®å¼‚æ•°æ®æ¯”è¾ƒ:")
    print("-" * 60)
    slightly_different_data = mock_ib_data.copy()
    # æ·»åŠ 1%çš„éšæœºå™ªå£°
    np.random.seed(123)
    noise = np.random.normal(1, 0.01, len(slightly_different_data))
    slightly_different_data['close'] = slightly_different_data['close'] * noise
    
    result3 = compare_price_data_fixed(mock_ib_data, slightly_different_data, "Mock_IB", "Mock_IB_Noisy")
    
    print("\n" + "=" * 80)
    print("ğŸ” æ•°æ®ä¸€è‡´æ€§éªŒè¯æµ‹è¯•å®Œæˆ")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   Mock_IB vs yfinance: ç›¸å…³æ€§={result1['close_correlation']:.4f}, å·®å¼‚={result1['close_mean_diff_pct']:.2f}%")
    print(f"   ç›¸åŒæ•°æ®æ¯”è¾ƒ: ç›¸å…³æ€§={result2['close_correlation']:.4f}, å·®å¼‚={result2['close_mean_diff_pct']:.2f}%")
    print(f"   è½»å¾®å·®å¼‚æ•°æ®: ç›¸å…³æ€§={result3['close_correlation']:.4f}, å·®å¼‚={result3['close_mean_diff_pct']:.2f}%")


if __name__ == "__main__":
    test_consistency_validation()