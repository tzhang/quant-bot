# ä½¿ç”¨æŒ‡å— (Usage Guide) - v1.6.0 æ•°æ®æºä¿®å¤ç‰ˆ

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹é‡åŒ–äº¤æ˜“ç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬æœ€æ–°çš„æ•°æ®æºä¿®å¤å’ŒMVPæ¼”ç¤ºç³»ç»Ÿã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-repo/quant-system.git
cd quant-system

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (å¼ºåˆ¶è¦æ±‚ Python 3.12)
python3.12 -m venv venv
source venv/bin/activate  # Linux/Mac

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 1.1 MVPæ¼”ç¤ºç³»ç»Ÿæµ‹è¯• (v1.6.0 æ–°å¢)

```bash
# è¿è¡ŒMVPæ¼”ç¤ºç³»ç»Ÿ - ç«¯åˆ°ç«¯é‡åŒ–äº¤æ˜“æ¼”ç¤º
python mvp_demo.py

# ç”Ÿæˆçš„ä¸“ä¸šå›¾è¡¨æ–‡ä»¶:
# - mvp_net_value_curve.png (å‡€å€¼æ›²çº¿å›¾)
# - mvp_drawdown_analysis.png (å›æ’¤åˆ†æå›¾)
# - mvp_returns_distribution.png (æ”¶ç›Šåˆ†å¸ƒå›¾)
# - mvp_rolling_metrics.png (æ»šåŠ¨æŒ‡æ ‡å›¾)
# - mvp_risk_return_scatter.png (é£é™©æ”¶ç›Šæ•£ç‚¹å›¾)
# - mvp_monthly_returns_heatmap.png (æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾)
```

### 1.2 æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯• (v3.0.0)

```bash
# è¿è¡Œé›†æˆä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•
python examples/final_integration_test.py

# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
python examples/test_optimized_parallel_performance.py

# è¿è¡Œå¤§è§„æ¨¡æ€§èƒ½æµ‹è¯•
python examples/test_large_scale_performance.py
```

### 2. åŸºæœ¬é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```env
# APIå¯†é’¥
ALPHA_VANTAGE_API_KEY=your_key_here
QUANDL_API_KEY=your_key_here
OPENBB_API_KEY=your_key_here  # v1.5.0 æ–°å¢
ALPACA_API_KEY=your_key_here  # v1.6.0 æ–°å¢
ALPACA_SECRET_KEY=your_secret_here  # v1.6.0 æ–°å¢

# æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼‰
DATABASE_URL=postgresql://user:password@localhost:5432/quant_db
REDIS_URL=redis://localhost:6379/0

# ç¼“å­˜é…ç½®
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# æ•°æ®æºé…ç½® (v1.6.0 æ›´æ–° - æ™ºèƒ½å›é€€æœºåˆ¶)
DEFAULT_DATA_SOURCE=auto  # auto, ib, qlib, openbb
DATA_SOURCE_PRIORITY=ib,qlib,openbb  # v1.6.0 æ–°å¢æ™ºèƒ½å›é€€é¡ºåº
ENABLE_DATA_FALLBACK=true  # v1.6.0 æ–°å¢ - å¯ç”¨æ•°æ®æºå›é€€
COLUMN_COMPATIBILITY_MODE=true  # v1.6.0 æ–°å¢ - åˆ—åå…¼å®¹æ€§å¤„ç†
API_RATE_LIMIT_ENABLED=true  # v1.6.0 æ–°å¢ - APIé™æµä¿æŠ¤
```

### 3. ç¬¬ä¸€ä¸ªç¤ºä¾‹

```python
import src as quant

# åˆ›å»ºæ•°æ®é€‚é…å™¨ (v1.6.0 æ›´æ–° - æ™ºèƒ½æ•°æ®æºå›é€€)
from src.data.data_adapter import DataAdapter
data_adapter = DataAdapter()

# è·å–è‚¡ç¥¨æ•°æ® - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®æºï¼Œæ”¯æŒæ™ºèƒ½å›é€€
data = data_adapter.get_data(['AAPL', 'GOOGL'], period='1y')
print(f"è·å–åˆ° {len(data)} æ¡æ•°æ®")
print(f"ä½¿ç”¨çš„æ•°æ®æº: {data_adapter.get_last_used_source()}")

# æŸ¥çœ‹ç³»ç»Ÿç‰ˆæœ¬
print(f"ç³»ç»Ÿç‰ˆæœ¬: {quant.get_version()}")
```

### 3.1 MVPæ¼”ç¤ºç³»ç»Ÿä½¿ç”¨ (v1.6.0 æ–°å¢)

```python
from mvp_demo import MVPDemo

# åˆ›å»ºMVPæ¼”ç¤ºå®ä¾‹
mvp = MVPDemo()

# è¿è¡Œå®Œæ•´çš„é‡åŒ–äº¤æ˜“æ¼”ç¤º
results = mvp.run_full_demo()

# æŸ¥çœ‹æ¼”ç¤ºç»“æœ
print(f"ç­–ç•¥æ€»æ”¶ç›Š: {results['total_return']:.2%}")
print(f"æœ€å¤§å›æ’¤: {results['max_drawdown']:.2%}")
print(f"å¤æ™®æ¯”ç‡: {results['sharpe_ratio']:.2f}")

# ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶å°†ä¿å­˜åœ¨å½“å‰ç›®å½•
print("ç”Ÿæˆçš„ä¸“ä¸šå›¾è¡¨:")
for chart in results['generated_charts']:
    print(f"- {chart}")
```

### 3.1 æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿä½¿ç”¨ (v3.0.0 æœ€æ–°)

```python
from optimization.cache_system import SmartCacheSystem
from optimization.memory_pool import MemoryPoolManager
from optimization.performance_profiler import PerformanceProfiler
from optimization.adaptive_executor import AdaptiveExecutor

# åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
cache_system = SmartCacheSystem()
memory_pool = MemoryPoolManager()
profiler = PerformanceProfiler()
executor = AdaptiveExecutor()

# ä½¿ç”¨æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
cache_system.set('stock_data_AAPL', data)
cached_data = cache_system.get('stock_data_AAPL')
print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_system.get_hit_rate():.2%}")

# ä½¿ç”¨å†…å­˜æ± ç®¡ç†å™¨
with memory_pool.get_buffer(1024*1024) as buffer:  # 1MBç¼“å†²åŒº
    # åœ¨è¿™é‡Œè¿›è¡Œæ•°æ®å¤„ç†
    processed_data = process_large_dataset(data, buffer)
print(f"å†…å­˜ä½¿ç”¨ä¼˜åŒ–: {memory_pool.get_memory_savings():.1f}MB")

# ä½¿ç”¨æ€§èƒ½åˆ†æå™¨
with profiler.profile('data_processing'):
    result = complex_calculation(data)
print(f"å¤„ç†æ—¶é—´: {profiler.get_last_duration():.3f}ç§’")

# ä½¿ç”¨è‡ªé€‚åº”æ‰§è¡Œå™¨
optimized_result = executor.execute_adaptive(
    func=calculate_factors,
    data=data,
    auto_optimize=True
)
print(f"æ€§èƒ½æå‡: {executor.get_performance_gain():.1f}x")
```

## ğŸ“Š æ•°æ®ç®¡ç† (v1.6.0 æ•°æ®æºä¿®å¤ç‰ˆ)

### æ™ºèƒ½æ•°æ®æºå›é€€ç³»ç»Ÿ (v1.6.0 æ–°å¢)

**é‡å¤§æ›´æ–°**: ç³»ç»Ÿç°åœ¨æ”¯æŒ IB TWS API â†’ Qlib â†’ OpenBB æ™ºèƒ½å›é€€æœºåˆ¶ï¼Œç¡®ä¿æ•°æ®è·å–çš„ç¨³å®šæ€§

```python
from src.data.data_adapter import DataAdapter

# åˆ›å»ºæ•°æ®é€‚é…å™¨ (v1.6.0 - æ”¯æŒæ™ºèƒ½å›é€€)
adapter = DataAdapter()

# è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®æºï¼Œæ”¯æŒæ™ºèƒ½å›é€€
data = adapter.get_data('AAPL', start='2023-01-01', end='2024-01-01')
print(f"ä½¿ç”¨çš„æ•°æ®æº: {adapter.get_last_used_source()}")
print(f"å›é€€æ¬¡æ•°: {adapter.get_fallback_count()}")

# æ£€æŸ¥æ•°æ®å¯ç”¨æ€§å’Œå›é€€çŠ¶æ€
availability = adapter.check_data_availability(['AAPL', 'GOOGL', 'MSFT'])
print("æ•°æ®æºå¯ç”¨æ€§:", availability)

# å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šæ•°æ®æº
data_alpaca = adapter.get_data('AAPL', source='alpaca')  # v1.6.0 æ–°å¢
data_ib = adapter.get_data('AAPL', source='ib')
data_qlib = adapter.get_data('AAPL', source='qlib')
data_openbb = adapter.get_data('AAPL', source='openbb')
```

### æ•°æ®æºä¿®å¤åŠŸèƒ½ (v1.6.0 æ ¸å¿ƒç‰¹æ€§)

```python
# åˆ—åå…¼å®¹æ€§å¤„ç†
data = adapter.get_data('AAPL', normalize_columns=True)  # è‡ªåŠ¨æ ‡å‡†åŒ–åˆ—å
print("æ ‡å‡†åŒ–åçš„åˆ—å:", data.columns.tolist())

# APIé™æµå¤„ç†
adapter.set_rate_limit(requests_per_minute=60)  # è®¾ç½®APIé™æµ
data = adapter.get_data_with_retry('AAPL', max_retries=3)  # æ”¯æŒé‡è¯•

# æ•°æ®è´¨é‡éªŒè¯
quality_report = adapter.validate_data_quality(data)
print(f"æ•°æ®å®Œæ•´æ€§: {quality_report['completeness']:.2%}")
print(f"æ•°æ®ä¸€è‡´æ€§: {quality_report['consistency']:.2%}")
```

### æ•°æ®æºæ€§èƒ½å¯¹æ¯” (v1.6.0 æ›´æ–°)

| æ•°æ®æº | è·å–é€Ÿåº¦ | åŠ é€Ÿæ¯” | é€‚ç”¨åœºæ™¯ | ç¨³å®šæ€§ | v1.6.0æ”¹è¿› |
|--------|----------|--------|----------|--------|------------|
| Alpaca API | 0.45ç§’ | 5.2x | å®æ—¶äº¤æ˜“æ•°æ® | 99.5% | æ–°å¢ä¸»æ•°æ®æº |
| yfinance | 2.34ç§’ | 1.0x | é€šç”¨è‚¡ç¥¨æ•°æ® | 95.8% | æ™ºèƒ½å›é€€ |
| Qlib æœ¬åœ°æ•°æ® | 0.03ç§’ | 78.0x | æœ¬åœ°é‡åŒ–ç ”ç©¶ | 99.9% | åˆ—åå…¼å®¹ |
| OpenBB å¹³å° | 0.89ç§’ | 2.6x | ä¸“ä¸šé‡‘èåˆ†æ | 97.2% | é”™è¯¯å¤„ç† |
| æ™ºèƒ½ç¼“å­˜ | 0.08ç§’ | 29.3x | é‡å¤æŸ¥è¯¢ | 100% | ç¼“å­˜ä¼˜åŒ– |

### æ‰¹é‡è·å–å¤šè‚¡ç¥¨æ•°æ® (v1.6.0 å¢å¼º)

```python
# æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ® - æ”¯æŒæ™ºèƒ½å›é€€
symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']
data_dict = adapter.get_multiple_data(
    symbols=symbols,
    start='2023-01-01',
    end='2024-01-01',
    enable_fallback=True  # v1.6.0 æ–°å¢
)

# æŸ¥çœ‹æ¯ä¸ªè‚¡ç¥¨ä½¿ç”¨çš„æ•°æ®æº
for symbol, data in data_dict.items():
    source_info = adapter.get_source_info(symbol)
    print(f"{symbol}: {len(data)} æ¡æ•°æ®, æ•°æ®æº: {source_info['source']}")
    if source_info['fallback_used']:
        print(f"  - ä½¿ç”¨äº†å›é€€æœºåˆ¶: {source_info['fallback_chain']}")
```

for symbol, data in data_dict.items():
    print(f"{symbol}: {len(data)} æ¡æ•°æ®")
```

### ä¼ ç»Ÿæ•°æ®è·å–æ–¹æ³• (å…¼å®¹æ€§ä¿æŒ)

**é‡è¦æç¤º**: è¯·ä½¿ç”¨æ–°çš„ `DataAdapter` ç±»è¿›è¡Œæ•°æ®è·å–ï¼Œä½†æ—§çš„ `DataManager` ä»ç„¶å¯ç”¨

```python
from src.data.data_manager import DataManager

# åˆ›å»ºæ•°æ®ç®¡ç†å™¨ (æ—§ç‰ˆæœ¬å…¼å®¹)
data_manager = DataManager()

# è·å–å•åªè‚¡ç¥¨æ•°æ®
data = data_manager.get_data(
    symbol='AAPL',
    start_date='2023-01-01',
    end_date='2024-01-01',
    data_type='ohlcv'
)

# è·å–å¤šåªè‚¡ç¥¨æ•°æ®
symbols = ['AAPL', 'GOOGL', 'MSFT']
for symbol in symbols:
    data = data_manager.get_data(
        symbol=symbol,
        start_date='2023-01-01',
        end_date='2024-01-01'
    )
    print(f"{symbol} æ•°æ®å½¢çŠ¶: {data.shape}")
```

### ä½¿ç”¨ç¼“å­˜æ•°æ®é¿å…APIé™åˆ¶

```python
import pandas as pd
from pathlib import Path

def load_cached_data(symbol='AAPL'):
    """åŠ è½½ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®"""
    cache_dir = Path('data_cache')
    cache_files = list(cache_dir.glob(f'ohlcv_{symbol}_*.csv'))
    
    if cache_files:
        cache_file = cache_files[0]
        # è¯»å–CSVæ–‡ä»¶ï¼Œè·³è¿‡å‰ä¸¤è¡Œ
        df = pd.read_csv(cache_file, skiprows=2)
        df = df.iloc[:, 1:]  # å»æ‰ç¬¬ä¸€åˆ—
        df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        df.index = pd.to_datetime(df.index)
        df.index.name = 'Date'
        return df
    return None

# ä½¿ç”¨ç¼“å­˜æ•°æ®
cached_data = load_cached_data('AAPL')
if cached_data is not None:
    print(f"æˆåŠŸåŠ è½½ç¼“å­˜æ•°æ®: {cached_data.shape}")
```

### æ•°æ®è·å–æœ€ä½³å®è·µ

```python
import time

def safe_get_data(data_manager, symbol, start_date, end_date, max_retries=3):
    """å®‰å…¨çš„æ•°æ®è·å–å‡½æ•°ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            data = data_manager.get_data(symbol, start_date, end_date)
            return data
        except Exception as e:
            print(f"å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                print(f"âŒ {symbol} æ•°æ®è·å–æœ€ç»ˆå¤±è´¥")
                return None

# æ‰¹é‡è·å–æ•°æ®æ—¶æ·»åŠ å»¶è¿Ÿ
symbols = ['AAPL', 'GOOGL', 'MSFT']
for symbol in symbols:
    data = safe_get_data(data_manager, symbol, '2023-01-01', '2024-01-01')
    if data is not None:
        print(f"âœ… {symbol} æ•°æ®è·å–æˆåŠŸ")
    time.sleep(1)  # é¿å…APIé™åˆ¶
```

## ğŸ§® å› å­è®¡ç®—

### æ­£ç¡®çš„å› å­è®¡ç®—æµç¨‹

```python
from src.factors.engine import FactorEngine
from src.data.data_adapter import DataAdapter  # v1.5.0 æ›´æ–°

# 1. è·å–æ•°æ® (ä½¿ç”¨æ–°çš„æ•°æ®é€‚é…å™¨)
data_adapter = DataAdapter()
data = data_adapter.get_data('AAPL', start='2023-01-01', end='2024-01-01')

# 2. åˆ›å»ºå› å­å¼•æ“
factor_engine = FactorEngine()

# 3. è®¡ç®—æŠ€æœ¯å› å­
tech_factors = factor_engine.compute_technical(data)
print(f"è®¡ç®—äº† {len(tech_factors.columns)} ä¸ªæŠ€æœ¯å› å­")

# 4. è®¡ç®—é£é™©å› å­
risk_factors = factor_engine.compute_risk(data)
print(f"è®¡ç®—äº† {len(risk_factors.columns)} ä¸ªé£é™©å› å­")

# 5. è®¡ç®—æ‰€æœ‰å› å­
all_factors = factor_engine.compute_all(data)
print(f"æ€»å…±è®¡ç®—äº† {len(all_factors.columns)} ä¸ªå› å­")
```

### å› å­æ ‡å‡†åŒ–å’Œå¤„ç†

```python
# å› å­æ ‡å‡†åŒ–
normalized_factors = factor_engine.normalize_factors(all_factors)

# å› å­å»æå€¼
winsorized_factors = factor_engine.winsorize_factors(all_factors)

# è®¡ç®—å› å­å¾—åˆ†
factor_scores = factor_engine.compute_factor_score(all_factors)
print(f"å› å­å¾—åˆ†: {factor_scores}")
```

## ğŸ“ˆ ç­–ç•¥å¼€å‘ä¸å›æµ‹ (v1.4.0 æ–°å¢)

### ç­–ç•¥æ¡†æ¶

```python
from src.strategies.base_strategy import BaseStrategy
from src.strategies.multi_factor_strategy import MultiFactorStrategy

# åˆ›å»ºå¤šå› å­ç­–ç•¥
strategy = MultiFactorStrategy(
    factors=['momentum', 'value', 'quality'],
    weights=[0.4, 0.3, 0.3],
    rebalance_freq='monthly'
)

# è‡ªå®šä¹‰ç­–ç•¥
class MyCustomStrategy(BaseStrategy):
    def __init__(self, param1, param2):
        super().__init__()
        self.param1 = param1
        self.param2 = param2
    
    def generate_signals(self, data):
        # å®ç°ä¿¡å·ç”Ÿæˆé€»è¾‘
        signals = {}
        # ... ç­–ç•¥é€»è¾‘
        return signals
    
    def calculate_positions(self, signals, current_positions):
        # å®ç°ä»“ä½è®¡ç®—é€»è¾‘
        new_positions = {}
        # ... ä»“ä½é€»è¾‘
        return new_positions
```

### å›æµ‹å¼•æ“

```python
from src.backtesting.backtest_engine import BacktestEngine
from src.backtesting.performance_analyzer import PerformanceAnalyzer

# åˆ›å»ºå›æµ‹å¼•æ“
backtest_engine = BacktestEngine(
    initial_capital=1000000,
    commission_rate=0.001,
    slippage_rate=0.0005,
    benchmark='SPY'
)

# è¿è¡Œå›æµ‹
results = backtest_engine.run_backtest(
    strategy=strategy,
    start_date='2020-01-01',
    end_date='2023-12-31',
    universe=['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']
)

# æ€§èƒ½åˆ†æ
analyzer = PerformanceAnalyzer()
performance_metrics = analyzer.analyze(results)

print(f"æ€»æ”¶ç›Šç‡: {performance_metrics['total_return']:.2%}")
print(f"å¹´åŒ–æ”¶ç›Šç‡: {performance_metrics['annual_return']:.2%}")
print(f"å¤æ™®æ¯”ç‡: {performance_metrics['sharpe_ratio']:.2f}")
print(f"æœ€å¤§å›æ’¤: {performance_metrics['max_drawdown']:.2%}")
print(f"ä¿¡æ¯æ¯”ç‡: {performance_metrics['information_ratio']:.2f}")
```

### ç­–ç•¥æ€§èƒ½å¯è§†åŒ–

```python
from src.visualization.strategy_visualizer import StrategyVisualizer

# åˆ›å»ºå¯è§†åŒ–å™¨
visualizer = StrategyVisualizer()

# ç”Ÿæˆç­–ç•¥æŠ¥å‘Š
visualizer.generate_strategy_report(
    results=results,
    save_path='reports/strategy_performance.html'
)

# ç»˜åˆ¶å‡€å€¼æ›²çº¿
visualizer.plot_equity_curve(results)

# ç»˜åˆ¶å›æ’¤åˆ†æ
visualizer.plot_drawdown_analysis(results)

# ç»˜åˆ¶æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾
visualizer.plot_monthly_returns_heatmap(results)
```

## ğŸ“Š æŠ•èµ„ç»„åˆä¼˜åŒ–

### åŸºæœ¬ä¼˜åŒ–

```python
from src.portfolio.optimizer import PortfolioOptimizer
from src.portfolio.constraints import OptimizationConstraint

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = PortfolioOptimizer()

# è®¾ç½®çº¦æŸæ¡ä»¶
constraints = [
    OptimizationConstraint('weight_sum', target=1.0),  # æƒé‡å’Œä¸º1
    OptimizationConstraint('long_only', bounds=(0, 1)),  # åªåšå¤š
    OptimizationConstraint('max_weight', bounds=(0, 0.1))  # å•åªè‚¡ç¥¨æœ€å¤§æƒé‡10%
]

# æ‰§è¡Œä¼˜åŒ–
result = optimizer.optimize(
    expected_returns=expected_returns,
    covariance_matrix=cov_matrix,
    constraints=constraints,
    objective='max_sharpe'  # 'max_return', 'min_risk', 'max_sharpe'
)

print(f"æœ€ä¼˜æƒé‡: {result.weights}")
print(f"é¢„æœŸæ”¶ç›Š: {result.expected_return:.4f}")
print(f"é¢„æœŸé£é™©: {result.expected_risk:.4f}")
```

### é«˜çº§ä¼˜åŒ–ç­–ç•¥

```python
# Black-Littermanä¼˜åŒ–
from src.portfolio.black_litterman import BlackLittermanOptimizer

bl_optimizer = BlackLittermanOptimizer()
bl_result = bl_optimizer.optimize(
    market_caps=market_caps,
    returns=historical_returns,
    views=investor_views,  # æŠ•èµ„è€…è§‚ç‚¹
    view_confidences=confidences
)

# é£é™©å¹³ä»·ä¼˜åŒ–
from src.portfolio.risk_parity import RiskParityOptimizer

rp_optimizer = RiskParityOptimizer()
rp_result = rp_optimizer.optimize(covariance_matrix=cov_matrix)
```

## ğŸ”„ ä¼ ç»Ÿå›æµ‹æ–¹æ³• (å…¼å®¹æ€§ä¿æŒ)

### åŸºæœ¬å›æµ‹

```python
# åˆ›å»ºå›æµ‹å¼•æ“ (æ—§ç‰ˆæœ¬å…¼å®¹)
backtest_engine = quant.create_backtest_engine(
    initial_capital=100000,
    commission=0.001,  # æ‰‹ç»­è´¹ç‡
    slippage=0.001     # æ»‘ç‚¹
)

# å®šä¹‰ç®€å•ç­–ç•¥
from src.strategies import SimpleMovingAverageStrategy

strategy = SimpleMovingAverageStrategy(
    short_window=20,
    long_window=50
)

# è¿è¡Œå›æµ‹
results = backtest_engine.run_backtest(
    strategy=strategy,
    data=data,
    start_date='2023-01-01',
    end_date='2023-12-31'
)

# æŸ¥çœ‹ç»“æœ
print(f"æ€»æ”¶ç›Šç‡: {results.total_return:.2%}")
print(f"å¹´åŒ–æ”¶ç›Šç‡: {results.annual_return:.2%}")
print(f"å¤æ™®æ¯”ç‡: {results.sharpe_ratio:.2f}")
print(f"æœ€å¤§å›æ’¤: {results.max_drawdown:.2%}")
```

### å¢å¼ºå›æµ‹

```python
from src.backtesting import EnhancedBacktestEngine

# åˆ›å»ºå¢å¼ºå›æµ‹å¼•æ“
enhanced_engine = EnhancedBacktestEngine(
    initial_capital=100000,
    commission_rate=0.001,
    slippage_rate=0.001,
    risk_free_rate=0.02
)

# æ·»åŠ é£é™©ç®¡ç†
enhanced_engine.add_risk_manager(
    max_position_size=0.1,  # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½
    max_drawdown=0.2,       # æœ€å¤§å›æ’¤é™åˆ¶
    stop_loss=0.05          # æ­¢æŸæ¯”ä¾‹
)

# è¿è¡Œå¢å¼ºå›æµ‹
enhanced_results = enhanced_engine.run_backtest(
    strategy=strategy,
    data=data,
    benchmark_data=benchmark_data
)
```

## âš ï¸ é£é™©ç®¡ç†

### VaRè®¡ç®—

```python
from src.risk.risk_manager import RiskManager

# åˆ›å»ºé£é™©ç®¡ç†å™¨
risk_manager = RiskManager()

# è®¡ç®—æŠ•èµ„ç»„åˆVaR
var_result = risk_manager.calculate_portfolio_var(
    weights=portfolio_weights,
    returns=return_data,
    confidence_level=0.95,
    method='historical'  # 'historical', 'parametric', 'monte_carlo'
)

print(f"95% VaR: {var_result['var']:.4f}")
print(f"é¢„æœŸæŸå¤±: {var_result['expected_shortfall']:.4f}")
```

### å‹åŠ›æµ‹è¯•

```python
# å®šä¹‰å‹åŠ›æµ‹è¯•æƒ…æ™¯
from src.risk.stress_test import StressTestScenario

scenarios = [
    StressTestScenario(
        name="å¸‚åœºå´©ç›˜",
        market_shock=-0.3,
        volatility_shock=2.0
    ),
    StressTestScenario(
        name="åˆ©ç‡ä¸Šå‡",
        interest_rate_shock=0.02,
        market_shock=-0.1
    )
]

# è¿è¡Œå‹åŠ›æµ‹è¯•
stress_results = risk_manager.run_stress_test(
    portfolio_weights=weights,
    scenarios=scenarios,
    historical_data=return_data
)

for result in stress_results:
    print(f"{result.scenario_name}: {result.portfolio_loss:.2%}")
```

### é£é™©å½’å› 

```python
# é£é™©å½’å› åˆ†æ
attribution_result = risk_manager.get_risk_attribution(
    portfolio_weights=weights,
    factor_exposures=factor_exposures,
    factor_covariance=factor_cov
)

print("é£é™©è´¡çŒ®:")
for factor, contribution in attribution_result.items():
    print(f"  {factor}: {contribution:.2%}")
```

## ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ– (v1.5.0 å¢å¼º)

### ç¼“å­˜ç®¡ç†

```python
from src.data.data_adapter import DataAdapter

# åˆ›å»ºæ•°æ®é€‚é…å™¨
adapter = DataAdapter()

# è·å–ç¼“å­˜æ•°æ®
cached_data = adapter.get_cached_data(
    symbol='AAPL',
    start='2023-01-01',
    end='2024-01-01'
)

# æ¸…ç†è¿‡æœŸç¼“å­˜
adapter.cleanup_cache(max_age_days=30)

# è·å–ç¼“å­˜ç»Ÿè®¡
cache_stats = adapter.get_cache_stats()
print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
print(f"ç¼“å­˜å¤§å°: {cache_stats['size_mb']:.1f} MB")
```

## ğŸ“Š å¯è§†åŒ–åˆ†æ (v1.4.0 å¢å¼º)

### åŸºæœ¬å›¾è¡¨

```python
from src.visualization.visualizer import Visualizer

viz = Visualizer()

# ç»˜åˆ¶å‡€å€¼æ›²çº¿
viz.plot_equity_curve(
    equity_data=backtest_results.equity_curve,
    benchmark_data=benchmark_equity
)

# ç»˜åˆ¶å›æ’¤å›¾
viz.plot_drawdown(backtest_results.drawdown)

# ç»˜åˆ¶æ”¶ç›Šåˆ†å¸ƒ
viz.plot_returns_distribution(backtest_results.returns)
```

### å› å­åˆ†æå›¾è¡¨

```python
# ICåˆ†æå›¾
viz.plot_ic_analysis(
    ic_data=factor_ic_results,
    factor_name="momentum_20"
)

# åˆ†å±‚æ”¶ç›Šå›¾
viz.plot_quantile_returns(
    quantile_returns=layered_returns,
    factor_name="value_factor"
)

# å› å­æš´éœ²å›¾
viz.plot_factor_exposure(
    exposures=factor_exposures,
    portfolio_weights=weights
)
```

### ç­–ç•¥æ€§èƒ½ä»ªè¡¨æ¿ (v1.4.0 æ–°å¢)

```python
from src.visualization.dashboard import StrategyDashboard

# åˆ›å»ºç­–ç•¥ä»ªè¡¨æ¿
dashboard = StrategyDashboard()

# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
dashboard.generate_full_report(
    strategy_results=results,
    output_path='reports/strategy_dashboard.html'
)

# å®æ—¶ç›‘æ§
dashboard.start_live_monitoring(
    strategy=strategy,
    update_interval=60  # ç§’
)
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿé«˜çº§ç”¨æ³• (v3.0.0 æ–°å¢)

```python
from optimization.integrated_optimizer import IntegratedOptimizer
from optimization.performance_profiler import PerformanceProfiler
from optimization.adaptive_executor import AdaptiveExecutor

# åˆ›å»ºé›†æˆä¼˜åŒ–å™¨
optimizer = IntegratedOptimizer()

# é…ç½®ä¼˜åŒ–å‚æ•°
optimizer.configure({
    'cache_size': 1000,
    'memory_pool_size': 512,  # MB
    'profiling_enabled': True,
    'adaptive_execution': True,
    'parallel_workers': 4
})

# ä¼˜åŒ–å› å­è®¡ç®—
@optimizer.optimize
def calculate_complex_factors(data, factor_list):
    """ä½¿ç”¨ä¼˜åŒ–å™¨è£…é¥°å™¨è‡ªåŠ¨ä¼˜åŒ–å‡½æ•°"""
    results = {}
    for factor_name in factor_list:
        # å¤æ‚çš„å› å­è®¡ç®—é€»è¾‘
        results[factor_name] = compute_factor(data, factor_name)
    return results

# æ‰¹é‡ä¼˜åŒ–å¤„ç†
optimized_results = optimizer.batch_process(
    func=calculate_complex_factors,
    data_batches=[data1, data2, data3],
    factor_list=['momentum', 'value', 'quality']
)

# è·å–ä¼˜åŒ–æŠ¥å‘Š
optimization_report = optimizer.get_performance_report()
print(f"æ€»ä½“æ€§èƒ½æå‡: {optimization_report['overall_speedup']:.1f}x")
print(f"å†…å­˜ä½¿ç”¨å‡å°‘: {optimization_report['memory_savings']:.1f}%")
print(f"ç¼“å­˜å‘½ä¸­ç‡: {optimization_report['cache_hit_rate']:.1%}")
```

### å¤§è§„æ¨¡æ•°æ®å¤„ç†ä¼˜åŒ–

```python
from optimization.large_scale_processor import LargeScaleProcessor

# åˆ›å»ºå¤§è§„æ¨¡å¤„ç†å™¨
processor = LargeScaleProcessor(
    chunk_size=10000,
    parallel_workers=8,
    memory_limit='2GB'
)

# å¤„ç†å¤§è§„æ¨¡è‚¡ç¥¨æ•°æ®
large_dataset = load_large_stock_data()  # å‡è®¾æœ‰100ä¸‡æ¡æ•°æ®
processed_results = processor.process_in_chunks(
    data=large_dataset,
    processing_func=calculate_all_factors,
    progress_callback=lambda p: print(f"å¤„ç†è¿›åº¦: {p:.1%}")
)

print(f"å¤„ç†å®Œæˆï¼Œç»“æœåŒ…å« {len(processed_results)} æ¡è®°å½•")
```

### è‡ªå®šä¹‰ç­–ç•¥ (v1.4.0 æ¡†æ¶)

```python
from src.strategies.base_strategy import BaseStrategy

class MyCustomStrategy(BaseStrategy):
    """è‡ªå®šä¹‰ç­–ç•¥ç¤ºä¾‹"""
    
    def __init__(self, param1=10, param2=0.05):
        super().__init__()
        self.param1 = param1
        self.param2 = param2
    
    def generate_signals(self, data):
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        signals = pd.DataFrame(index=data.index, columns=data.columns)
        
        # å®ç°æ‚¨çš„ç­–ç•¥é€»è¾‘
        # ...
        
        return signals
    
    def calculate_positions(self, signals, current_positions):
        """è®¡ç®—ç›®æ ‡ä»“ä½"""
        # å®ç°ä»“ä½è®¡ç®—é€»è¾‘
        # ...
        
        return target_positions

# ä½¿ç”¨è‡ªå®šä¹‰ç­–ç•¥
custom_strategy = MyCustomStrategy(param1=15, param2=0.03)
results = backtest_engine.run_backtest(custom_strategy, data)
```

### è‡ªå®šä¹‰å› å­

```python
from src.factors.base_factor import BaseFactor

class MyCustomFactor(BaseFactor):
    """è‡ªå®šä¹‰å› å­ç¤ºä¾‹"""
    
    def __init__(self, window=20):
        super().__init__()
        self.window = window
    
    def calculate(self, data):
        """è®¡ç®—å› å­å€¼"""
        # å®ç°æ‚¨çš„å› å­è®¡ç®—é€»è¾‘
        factor_values = data['Close'].rolling(self.window).apply(
            lambda x: your_custom_calculation(x)
        )
        
        return factor_values

# æ³¨å†Œè‡ªå®šä¹‰å› å­
factor_engine.register_factor('my_custom_factor', MyCustomFactor)
```

## ğŸš€ åˆ¸å•†é›†æˆ (v1.2.0 æ–°å¢)

### æ”¯æŒçš„åˆ¸å•†

```python
from src.brokers import BrokerFactory

# åˆ›å»ºåˆ¸å•†è¿æ¥
broker = BrokerFactory.create_broker(
    broker_type='td_ameritrade',  # 'charles_schwab', 'etrade', 'robinhood'
    api_key='your_api_key',
    secret_key='your_secret_key'
)

# è·å–è´¦æˆ·ä¿¡æ¯
account_info = broker.get_account_info()
print(f"è´¦æˆ·ä½™é¢: ${account_info['balance']:,.2f}")

# è·å–æŒä»“
positions = broker.get_positions()
for position in positions:
    print(f"{position['symbol']}: {position['quantity']} è‚¡")

# ä¸‹å•
order_result = broker.place_order(
    symbol='AAPL',
    quantity=100,
    order_type='market',
    side='buy'
)
```

### å®ç›˜äº¤æ˜“ç›‘æ§

```python
from src.brokers.monitor import TradingMonitor

# åˆ›å»ºäº¤æ˜“ç›‘æ§
monitor = TradingMonitor(broker=broker)

# å¯åŠ¨å®æ—¶ç›‘æ§
monitor.start_monitoring(
    strategies=[strategy1, strategy2],
    risk_limits={
        'max_daily_loss': 0.02,
        'max_position_size': 0.1
    }
)
```

## ğŸ“± ç§»åŠ¨ç«¯æ”¯æŒ (v1.4.0 æ–°å¢)

### ç§»åŠ¨ç«¯API

```python
from src.mobile.api import MobileAPI

# åˆ›å»ºç§»åŠ¨ç«¯API
mobile_api = MobileAPI()

# è·å–ç®€åŒ–çš„æŠ•èµ„ç»„åˆä¿¡æ¯
portfolio_summary = mobile_api.get_portfolio_summary()

# è·å–å…³é”®æŒ‡æ ‡
key_metrics = mobile_api.get_key_metrics()

# å‘é€æ¨é€é€šçŸ¥
mobile_api.send_notification(
    title="ç­–ç•¥æé†’",
    message="AAPL è§¦å‘ä¹°å…¥ä¿¡å·",
    priority="high"
)
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®è·å–å¤±è´¥**
   ```python
   # æ£€æŸ¥æ•°æ®æºçŠ¶æ€
   adapter = DataAdapter()
   status = adapter.check_data_sources_status()
   print("æ•°æ®æºçŠ¶æ€:", status)
   
   # ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
   data = adapter.get_data('AAPL', source='yfinance', fallback=True)
   ```

2. **APIé™åˆ¶é—®é¢˜**
   ```python
   # ä½¿ç”¨ç¼“å­˜æ•°æ®
   cached_data = adapter.get_cached_data('AAPL')
   if cached_data is not None:
       print("ä½¿ç”¨ç¼“å­˜æ•°æ®")
   ```

3. **æ€§èƒ½ä¼˜åŒ–**
   ```python
   # æ‰¹é‡è·å–æ•°æ®
   symbols = ['AAPL', 'GOOGL', 'MSFT']
   data_dict = adapter.get_multiple_data(symbols, batch_size=10)
   ```

### æ—¥å¿—å’Œè°ƒè¯•

```python
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

# æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
from src.utils.system_info import SystemInfo
system_info = SystemInfo()
print(system_info.get_system_status())
```

## ğŸ“š æ›´å¤šèµ„æº

- ğŸ“– [å®Œæ•´APIæ–‡æ¡£](docs/api_reference.md)
- ğŸ¯ [ç­–ç•¥å¼€å‘æŒ‡å—](docs/strategy_development.md)
- ğŸ“Š [å› å­ç ”ç©¶æ‰‹å†Œ](docs/factor_research.md)
- ğŸ”§ [ç³»ç»Ÿé…ç½®æŒ‡å—](docs/configuration.md)
- ğŸš€ [éƒ¨ç½²æŒ‡å—](docs/deployment.md)
- âš¡ [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](docs/OPTIMIZATION_GUIDE.md) (v3.0.0 æ–°å¢)
- ğŸ“ˆ [æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š](docs/PERFORMANCE_REPORT.md) (v3.0.0 æ–°å¢)
- ğŸ”— [é›†æˆä¼˜åŒ–æŒ‡å—](docs/INTEGRATION_GUIDE.md) (v3.0.0 æ–°å¢)

---

**ç‰ˆæœ¬ä¿¡æ¯**: æœ¬æŒ‡å—é€‚ç”¨äº v3.0.0 æ€§èƒ½ä¼˜åŒ–ç‰ˆ

**æ›´æ–°æ—¥å¿—**:
- v3.0.0: æ–°å¢æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿï¼ŒåŒ…å«æ™ºèƒ½ç¼“å­˜ã€å†…å­˜æ± ç®¡ç†ã€æ€§èƒ½åˆ†æå™¨ç­‰
- v1.5.0: æ–°å¢ä¸‰æ•°æ®æºé›†æˆç³»ç»Ÿ
- v1.4.0: æ–°å¢ç­–ç•¥å¼€å‘ä¸å›æµ‹æ¡†æ¶
- v1.3.0: æ–°å¢é«˜çº§æ•°æ®æŠ“å–ä¼˜åŒ–
- v1.2.0: æ–°å¢åˆ¸å•†é›†æˆæ”¯æŒ

## ğŸ“‹ ç¤ºä¾‹è„šæœ¬

ç³»ç»Ÿæä¾›äº†å¤šä¸ªç¤ºä¾‹è„šæœ¬å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ï¼š

### 1. æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯• (v3.0.0 æ–°å¢)
```bash
# é›†æˆä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•
python examples/final_integration_test.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python examples/test_optimized_parallel_performance.py

# å¤§è§„æ¨¡æ€§èƒ½æµ‹è¯•
python examples/test_large_scale_performance.py
```

### 2. æ•°æ®è·å–æ•™ç¨‹
```bash
# åŸºç¡€æ•°æ®è·å–æ¼”ç¤º
python examples/data_tutorial.py

# æ•°æ®è·å–æ¼”ç¤ºï¼ˆé¿å…APIé™åˆ¶ï¼‰
python examples/data_fetch_demo.py

# ç¼“å­˜æ•°æ®ä½¿ç”¨æ¼”ç¤º
python examples/cached_data_demo.py
```

### 3. å› å­åˆ†ææ•™ç¨‹
```bash
# å› å­è®¡ç®—æ•™ç¨‹
python examples/factor_tutorial.py

# å› å­è¯„ä¼°æ¼”ç¤º
python examples/factor_evaluation.py
```

### 4. ç­–ç•¥æµ‹è¯•
```bash
# ç­–ç•¥æµ‹è¯•æ¼”ç¤º
python examples/strategy_testing_demo.py

# MVPæ¼”ç¤º
python examples/mvp_demo.py
```

## ğŸš¨ å¸¸è§é—®é¢˜

### Q: æ•°æ®è·å–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼š`python examples/cached_data_demo.py`
3. æ·»åŠ è¯·æ±‚å»¶è¿Ÿé¿å…APIé™åˆ¶
4. æ£€æŸ¥ yfinance åº“ç‰ˆæœ¬

### Q: FactorEngine æ²¡æœ‰ get_data æ–¹æ³•ï¼Ÿ
**A**: 
è¯·ä½¿ç”¨ `DataManager` ç±»è·å–æ•°æ®ï¼š
```python
from src.data.data_manager import DataManager
data_manager = DataManager()
data = data_manager.get_data('AAPL', '2023-01-01', '2024-01-01')
```

### Q: yfinance å‡ºç° YFRateLimitErrorï¼Ÿ
**A**: 
1. ä½¿ç”¨ç¼“å­˜æ•°æ®é¿å…é¢‘ç¹è¯·æ±‚
2. æ·»åŠ è¯·æ±‚é—´éš”ï¼š`time.sleep(1)`
3. ä½¿ç”¨é‡è¯•æœºåˆ¶
4. è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨

### Q: æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Ÿ
**A**: 
ç³»ç»Ÿå¯ä»¥åœ¨æ²¡æœ‰æ•°æ®åº“çš„æƒ…å†µä¸‹æ­£å¸¸è¿è¡Œï¼Œä½¿ç”¨æ–‡ä»¶ç¼“å­˜ä½œä¸ºæ›¿ä»£ã€‚

### Q: ç¼“å­˜æ•°æ®æ ¼å¼é—®é¢˜ï¼Ÿ
**A**: 
ä½¿ç”¨æä¾›çš„ `load_cached_data()` å‡½æ•°æ­£ç¡®åŠ è½½ç¼“å­˜æ•°æ®ã€‚

## ğŸ“š æ›´å¤šèµ„æº

- [è¯¦ç»†æ•°æ®ä½¿ç”¨æŒ‡å—](docs/DATA_USAGE_GUIDE.md)
- [APIæ–‡æ¡£](docs/api.md)
- [ç­–ç•¥å¼€å‘æŒ‡å—](docs/strategy_development.md)
- [å› å­å¼€å‘æŒ‡å—](docs/factor_development.md)
- [æœ€ä½³å®è·µ](docs/best_practices.md)
- [å¸¸è§é—®é¢˜è§£ç­”](docs/FAQ_TROUBLESHOOTING.md)

## ğŸ’¡ æç¤ºå’ŒæŠ€å·§ (v3.0.0 ä¼˜åŒ–ç‰ˆ)

1. **ä¼˜å…ˆä½¿ç”¨æ€§èƒ½ä¼˜åŒ–**: å……åˆ†åˆ©ç”¨æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿå’Œå†…å­˜æ± ç®¡ç†å™¨
2. **ç›‘æ§æ€§èƒ½æŒ‡æ ‡**: ä½¿ç”¨æ€§èƒ½åˆ†æå™¨è¯†åˆ«ç“¶é¢ˆå¹¶ä¼˜åŒ–
3. **è‡ªé€‚åº”æ‰§è¡Œ**: å¯ç”¨è‡ªé€‚åº”æ‰§è¡Œå™¨è‡ªåŠ¨ä¼˜åŒ–è®¡ç®—å¯†é›†å‹ä»»åŠ¡
4. **æ‰¹é‡å¤„ç†ä¼˜åŒ–**: ä½¿ç”¨å¤§è§„æ¨¡å¤„ç†å™¨å¤„ç†å¤§é‡æ•°æ®
5. **å†…å­˜ç®¡ç†**: åˆ©ç”¨å†…å­˜æ± å‡å°‘å†…å­˜åˆ†é…å¼€é”€
6. **ç¼“å­˜ç­–ç•¥**: åˆç†é…ç½®ç¼“å­˜å¤§å°å’Œè¿‡æœŸæ—¶é—´
7. **å¹¶è¡Œè®¡ç®—**: å……åˆ†åˆ©ç”¨å¤šæ ¸CPUè¿›è¡Œå¹¶è¡Œå¤„ç†
8. **é¿å…APIé™åˆ¶**: æ·»åŠ é€‚å½“çš„è¯·æ±‚å»¶è¿Ÿï¼Œä½¿ç”¨é‡è¯•æœºåˆ¶
9. **æ­£ç¡®çš„æ•°æ®è·å–**: ä½¿ç”¨ `DataManager` è€Œä¸æ˜¯ `FactorEngine.get_data()`
10. **å‚æ•°è°ƒä¼˜**: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œå‚æ•°è°ƒä¼˜
11. **é£é™©æ§åˆ¶**: å§‹ç»ˆè®¾ç½®åˆç†çš„é£é™©é™åˆ¶å’Œæ­¢æŸæœºåˆ¶

### æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

```python
# 1. ä½¿ç”¨é›†æˆä¼˜åŒ–å™¨
from optimization.integrated_optimizer import IntegratedOptimizer
optimizer = IntegratedOptimizer()

# 2. é…ç½®åˆé€‚çš„å‚æ•°
optimizer.configure({
    'cache_size': 2000,      # æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´
    'memory_pool_size': 1024, # MB
    'parallel_workers': 8     # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
})

# 3. ä½¿ç”¨è£…é¥°å™¨è‡ªåŠ¨ä¼˜åŒ–
@optimizer.optimize
def your_compute_intensive_function(data):
    # æ‚¨çš„è®¡ç®—é€»è¾‘
    return results

# 4. ç›‘æ§æ€§èƒ½
performance_report = optimizer.get_performance_report()
print(f"æ€§èƒ½æå‡: {performance_report['overall_speedup']:.1f}x")
```

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ [FAQæ–‡æ¡£](docs/FAQ_TROUBLESHOOTING.md) æˆ–æŸ¥çœ‹ç¤ºä¾‹è„šæœ¬ã€‚