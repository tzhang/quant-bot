# â“ å¸¸è§é—®é¢˜ä¸æ•…éšœæ’é™¤

æœ¬æ–‡æ¡£æ”¶é›†äº†ä½¿ç”¨é‡åŒ–äº¤æ˜“ç³»ç»Ÿæ—¶çš„å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿè§£å†³é‡åˆ°çš„å›°éš¾ã€‚

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒé…ç½®é—®é¢˜](#ç¯å¢ƒé…ç½®é—®é¢˜)
2. [æ•°æ®è·å–é—®é¢˜](#æ•°æ®è·å–é—®é¢˜)
3. [å› å­è®¡ç®—é—®é¢˜](#å› å­è®¡ç®—é—®é¢˜)
4. [å›¾è¡¨ç”Ÿæˆé—®é¢˜](#å›¾è¡¨ç”Ÿæˆé—®é¢˜)
5. [æ€§èƒ½ä¼˜åŒ–é—®é¢˜](#æ€§èƒ½ä¼˜åŒ–é—®é¢˜)
6. [ç³»ç»Ÿé”™è¯¯å¤„ç†](#ç³»ç»Ÿé”™è¯¯å¤„ç†)

---

## ğŸ”§ ç¯å¢ƒé…ç½®é—®é¢˜

### Q1: å®‰è£…ä¾èµ–åŒ…æ—¶å‡ºç°é”™è¯¯

**é—®é¢˜æè¿°**: è¿è¡Œ `pip install -r requirements.txt` æ—¶å‡ºç°å®‰è£…å¤±è´¥

**å¸¸è§é”™è¯¯**:
```bash
ERROR: Could not find a version that satisfies the requirement
ERROR: No matching distribution found
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ1: å‡çº§pip
pip install --upgrade pip

# æ–¹æ¡ˆ2: ä½¿ç”¨å›½å†…é•œåƒæº
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/

# æ–¹æ¡ˆ3: é€ä¸ªå®‰è£…æ ¸å¿ƒåŒ…
pip install pandas numpy matplotlib yfinance requests

# æ–¹æ¡ˆ4: ä½¿ç”¨condaå®‰è£…
conda install pandas numpy matplotlib
pip install yfinance requests
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨Python 3.12ç‰ˆæœ¬ï¼ˆå¼ºåˆ¶è¦æ±‚ï¼‰
- å®šæœŸæ›´æ–°pipå’Œsetuptools
- åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ä¾èµ–

### Q2: å¯¼å…¥æ¨¡å—æ—¶å‡ºç°ModuleNotFoundError

**é—®é¢˜æè¿°**: 
```python
ModuleNotFoundError: No module named 'src.factors.engine'
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

# æ–¹æ¡ˆ2: è®¾ç½®PYTHONPATHç¯å¢ƒå˜é‡
export PYTHONPATH="${PYTHONPATH}:/path/to/your/project"

# æ–¹æ¡ˆ3: åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /path/to/my-quant
python examples/data_tutorial.py
```

### Q3: ç¯å¢ƒæµ‹è¯•è„šæœ¬æŠ¥é”™

**é—®é¢˜æè¿°**: è¿è¡Œ `python test_environment.py` æ—¶å‡ºç°å„ç§é”™è¯¯

**è§£å†³æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # åº”è¯¥æ˜¯3.8+

# 2. æ£€æŸ¥å½“å‰ç›®å½•
pwd  # åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•

# 3. æ£€æŸ¥æ–‡ä»¶ç»“æ„
ls -la  # åº”è¯¥çœ‹åˆ°src/, examples/, docs/ç­‰ç›®å½•

# 4. é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt --force-reinstall

# 5. æ¸…ç†ç¼“å­˜
pip cache purge
```

---

## ğŸ“Š æ•°æ®è·å–é—®é¢˜

### Q4: yfinanceè·å–æ•°æ®å¤±è´¥

**é—®é¢˜æè¿°**: 
```python
Exception: No data found, symbol may be delisted
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼
# æ­£ç¡®æ ¼å¼
symbols = ['AAPL', 'GOOGL', 'MSFT']  # ç¾è‚¡
symbols = ['000001.SZ', '000002.SZ']  # Aè‚¡éœ€è¦åç¼€

# æ–¹æ¡ˆ2: æ·»åŠ é‡è¯•æœºåˆ¶
import time
import yfinance as yf

def get_data_with_retry(symbol, max_retries=3):
    for i in range(max_retries):
        try:
            data = yf.download(symbol, period='1y')
            if not data.empty:
                return data
        except Exception as e:
            print(f"å°è¯• {i+1}/{max_retries} å¤±è´¥: {e}")
            time.sleep(2)
    return None

# æ–¹æ¡ˆ3: ä½¿ç”¨æ›´çŸ­çš„æ—¶é—´å‘¨æœŸ
data = yf.download('AAPL', period='1m')  # æ”¹ä¸º1ä¸ªæœˆ
```

### Q5: ç½‘ç»œè¿æ¥è¶…æ—¶

**é—®é¢˜æè¿°**: 
```python
requests.exceptions.ConnectTimeout: HTTPSConnectionPool
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: å¢åŠ è¶…æ—¶æ—¶é—´
import yfinance as yf
yf.pdr_override()
data = yf.download('AAPL', period='1y', timeout=30)

# æ–¹æ¡ˆ2: ä½¿ç”¨ä»£ç†
import os
os.environ['HTTP_PROXY'] = 'http://your-proxy:port'
os.environ['HTTPS_PROXY'] = 'https://your-proxy:port'

# æ–¹æ¡ˆ3: åˆ†æ‰¹è·å–æ•°æ®
symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']
batch_size = 2
for i in range(0, len(symbols), batch_size):
    batch = symbols[i:i+batch_size]
    data = yf.download(batch, period='1y')
    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
```

### Q6: æ•°æ®ç¼“å­˜é—®é¢˜

**é—®é¢˜æè¿°**: ç¼“å­˜æ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ1: æ¸…ç†ç¼“å­˜ç›®å½•
rm -rf data_cache/
mkdir data_cache

# æ–¹æ¡ˆ2: æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ–¹æ¡ˆ3: ä¿®å¤æƒé™é—®é¢˜
chmod -R 755 data_cache/
```

```python
# æ–¹æ¡ˆ4: åœ¨ä»£ç ä¸­å¤„ç†ç¼“å­˜é”™è¯¯
try:
    data = engine.get_data(symbols, period='1y')
except Exception as e:
    print(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
    # æ¸…ç†ç¼“å­˜å¹¶é‡æ–°è·å–
    import shutil
    shutil.rmtree('data_cache', ignore_errors=True)
    data = engine.get_data(symbols, period='1y')
```

---

## ğŸ§® å› å­è®¡ç®—é—®é¢˜

### Q7: å› å­è®¡ç®—ç»“æœä¸ºNaN

**é—®é¢˜æè¿°**: è®¡ç®—çš„å› å­å€¼å…¨éƒ¨ä¸ºNaNæˆ–ç©ºå€¼

**å¸¸è§åŸå› åŠè§£å†³æ–¹æ¡ˆ**:
```python
# åŸå› 1: æ•°æ®ä¸è¶³
def check_data_length(data, min_length=20):
    if len(data) < min_length:
        print(f"æ•°æ®é•¿åº¦ä¸è¶³: {len(data)} < {min_length}")
        return False
    return True

# åŸå› 2: æ•°æ®åŒ…å«NaNå€¼
def clean_data(data):
    # æ£€æŸ¥NaNå€¼
    nan_count = data.isnull().sum().sum()
    if nan_count > 0:
        print(f"å‘ç° {nan_count} ä¸ªNaNå€¼")
        # å‰å‘å¡«å……
        data = data.fillna(method='ffill')
        # åå‘å¡«å……
        data = data.fillna(method='bfill')
    return data

# åŸå› 3: é™¤é›¶é”™è¯¯
def safe_divide(numerator, denominator):
    return np.where(denominator != 0, numerator / denominator, np.nan)

# ä½¿ç”¨ç¤ºä¾‹
momentum = safe_divide(
    data['close'].iloc[-1] - data['close'].iloc[-21],
    data['close'].iloc[-21]
)
```

### Q8: å› å­è¯„ä¼°ICå€¼å¼‚å¸¸

**é—®é¢˜æè¿°**: ICå€¼è¿‡é«˜(>0.5)æˆ–è®¡ç®—å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥æ•°æ®è´¨é‡
def validate_factor_data(factor_values, returns):
    # 1. æ£€æŸ¥æ•°æ®é•¿åº¦
    if len(factor_values) != len(returns):
        print("å› å­å€¼å’Œæ”¶ç›Šç‡é•¿åº¦ä¸åŒ¹é…")
        return False
    
    # 2. æ£€æŸ¥NaNå€¼
    factor_nan = pd.isna(factor_values).sum()
    returns_nan = pd.isna(returns).sum()
    if factor_nan > 0 or returns_nan > 0:
        print(f"å› å­NaN: {factor_nan}, æ”¶ç›ŠNaN: {returns_nan}")
        return False
    
    # 3. æ£€æŸ¥æ•°æ®èŒƒå›´
    if factor_values.std() == 0:
        print("å› å­å€¼æ— å˜åŒ–")
        return False
    
    return True

# è®¡ç®—ICæ—¶çš„é”™è¯¯å¤„ç†
def calculate_ic_safe(factor_values, returns):
    try:
        # ç§»é™¤NaNå€¼
        valid_mask = ~(pd.isna(factor_values) | pd.isna(returns))
        factor_clean = factor_values[valid_mask]
        returns_clean = returns[valid_mask]
        
        if len(factor_clean) < 10:  # è‡³å°‘éœ€è¦10ä¸ªæœ‰æ•ˆæ ·æœ¬
            return np.nan
        
        ic = factor_clean.corr(returns_clean)
        
        # æ£€æŸ¥ICå€¼åˆç†æ€§
        if abs(ic) > 0.8:
            print(f"è­¦å‘Š: ICå€¼å¼‚å¸¸é«˜ {ic:.4f}")
        
        return ic
    except Exception as e:
        print(f"ICè®¡ç®—é”™è¯¯: {e}")
        return np.nan
```

### Q9: åˆ†å±‚æµ‹è¯•ç»“æœä¸åˆç†

**é—®é¢˜æè¿°**: åˆ†å±‚æµ‹è¯•æ²¡æœ‰æ˜¾ç¤ºå•è°ƒæ€§æˆ–æ”¶ç›Šå·®å¼‚å¾ˆå°

**è§£å†³æ–¹æ¡ˆ**:
```python
def analyze_layered_test(factor_values, returns, n_layers=5):
    # 1. æ£€æŸ¥æ ·æœ¬æ•°é‡
    if len(factor_values) < n_layers * 2:
        print(f"æ ·æœ¬æ•°é‡ä¸è¶³è¿›è¡Œ{n_layers}å±‚æµ‹è¯•")
        return None
    
    # 2. å› å­æ ‡å‡†åŒ–
    factor_standardized = (factor_values - factor_values.mean()) / factor_values.std()
    
    # 3. åˆ†å±‚
    df = pd.DataFrame({
        'factor': factor_standardized,
        'returns': returns
    }).dropna()
    
    df['layer'] = pd.qcut(df['factor'], n_layers, labels=False)
    
    # 4. è®¡ç®—å„å±‚æ”¶ç›Š
    layer_returns = df.groupby('layer')['returns'].mean()
    
    # 5. æ£€æŸ¥å•è°ƒæ€§
    monotonic = all(layer_returns.iloc[i] <= layer_returns.iloc[i+1] 
                   for i in range(len(layer_returns)-1))
    
    print(f"å•è°ƒæ€§æ£€æŸ¥: {'é€šè¿‡' if monotonic else 'æœªé€šè¿‡'}")
    print("å„å±‚æ”¶ç›Š:")
    for i, ret in enumerate(layer_returns):
        print(f"  ç¬¬{i+1}å±‚: {ret:.4f}")
    
    return layer_returns
```

---

## ğŸ“Š å›¾è¡¨ç”Ÿæˆé—®é¢˜

### Q10: matplotlibä¸­æ–‡æ˜¾ç¤ºä¹±ç 

**é—®é¢˜æè¿°**: å›¾è¡¨ä¸­çš„ä¸­æ–‡æ˜¾ç¤ºä¸ºæ–¹æ¡†æˆ–ä¹±ç 

**è§£å†³æ–¹æ¡ˆ**:
```python
import matplotlib.pyplot as plt
import matplotlib as mpl

# æ–¹æ¡ˆ1: è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ–¹æ¡ˆ2: ä½¿ç”¨ç³»ç»Ÿå­—ä½“
from matplotlib.font_manager import FontProperties
font = FontProperties(fname='/System/Library/Fonts/Arial Unicode.ttf')
plt.title('ä¸­æ–‡æ ‡é¢˜', fontproperties=font)

# æ–¹æ¡ˆ3: å®‰è£…ä¸­æ–‡å­—ä½“åŒ…
# pip install matplotlib -U
# ä¸‹è½½å¹¶å®‰è£…SimHeiå­—ä½“

# æ–¹æ¡ˆ4: æ£€æŸ¥å¯ç”¨å­—ä½“
from matplotlib.font_manager import fontManager
fonts = [f.name for f in fontManager.ttflist if 'Chinese' in f.name or 'SimHei' in f.name]
print("å¯ç”¨ä¸­æ–‡å­—ä½“:", fonts)
```

### Q11: å›¾è¡¨ä¿å­˜å¤±è´¥

**é—®é¢˜æè¿°**: 
```python
PermissionError: [Errno 13] Permission denied: 'examples/chart.png'
```

**è§£å†³æ–¹æ¡ˆ**:
```python
import os
from pathlib import Path

# æ–¹æ¡ˆ1: æ£€æŸ¥ç›®å½•æƒé™
output_dir = Path('examples')
if not output_dir.exists():
    output_dir.mkdir(parents=True, exist_ok=True)

# æ–¹æ¡ˆ2: ä½¿ç”¨ç»å¯¹è·¯å¾„
import tempfile
temp_dir = tempfile.gettempdir()
output_path = os.path.join(temp_dir, 'chart.png')

# æ–¹æ¡ˆ3: é”™è¯¯å¤„ç†
try:
    plt.savefig('examples/chart.png', dpi=300, bbox_inches='tight')
    print("å›¾è¡¨ä¿å­˜æˆåŠŸ")
except PermissionError:
    # ä¿å­˜åˆ°ç”¨æˆ·ç›®å½•
    home_dir = Path.home()
    backup_path = home_dir / 'chart.png'
    plt.savefig(backup_path, dpi=300, bbox_inches='tight')
    print(f"å›¾è¡¨ä¿å­˜åˆ°: {backup_path}")
```

### Q12: å›¾è¡¨æ˜¾ç¤ºä¸å®Œæ•´

**é—®é¢˜æè¿°**: å›¾è¡¨æ ‡ç­¾è¢«æˆªæ–­æˆ–é‡å 

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: è°ƒæ•´å›¾è¡¨å¸ƒå±€
plt.figure(figsize=(12, 8))
plt.tight_layout()

# æ–¹æ¡ˆ2: æ‰‹åŠ¨è°ƒæ•´è¾¹è·
plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)

# æ–¹æ¡ˆ3: æ—‹è½¬æ ‡ç­¾
plt.xticks(rotation=45)
plt.ylabel('æ”¶ç›Šç‡', rotation=90)

# æ–¹æ¡ˆ4: ä½¿ç”¨bbox_inches
plt.savefig('chart.png', bbox_inches='tight', pad_inches=0.2)

# æ–¹æ¡ˆ5: è®¾ç½®å­—ä½“å¤§å°
plt.rcParams.update({'font.size': 10})
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–é—®é¢˜

### Q13: ç¨‹åºè¿è¡Œé€Ÿåº¦æ…¢

**é—®é¢˜æè¿°**: æ•°æ®å¤„ç†æˆ–å› å­è®¡ç®—è€—æ—¶è¿‡é•¿

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
# æ…¢é€Ÿå¾ªç¯æ–¹å¼
results = []
for i in range(len(data)):
    result = data.iloc[i]['close'] / data.iloc[i]['open'] - 1
    results.append(result)

# å¿«é€Ÿå‘é‡åŒ–æ–¹å¼
results = data['close'] / data['open'] - 1

# æ–¹æ¡ˆ2: ä½¿ç”¨numbaåŠ é€Ÿ
from numba import jit

@jit(nopython=True)
def fast_calculation(prices):
    returns = np.zeros(len(prices)-1)
    for i in range(1, len(prices)):
        returns[i-1] = prices[i] / prices[i-1] - 1
    return returns

# æ–¹æ¡ˆ3: å¹¶è¡Œå¤„ç†
from concurrent.futures import ThreadPoolExecutor
import multiprocessing

def process_symbol(symbol):
    # å¤„ç†å•ä¸ªè‚¡ç¥¨çš„é€»è¾‘
    return result

# å¹¶è¡Œå¤„ç†å¤šä¸ªè‚¡ç¥¨
with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
    results = list(executor.map(process_symbol, symbols))
```

### Q14: å†…å­˜ä½¿ç”¨è¿‡å¤š

**é—®é¢˜æè¿°**: ç¨‹åºå ç”¨å†…å­˜è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´ç³»ç»Ÿå¡é¡¿

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: åˆ†æ‰¹å¤„ç†
def process_in_batches(symbols, batch_size=10):
    results = []
    for i in range(0, len(symbols), batch_size):
        batch = symbols[i:i+batch_size]
        batch_result = process_batch(batch)
        results.extend(batch_result)
        
        # æ¸…ç†å†…å­˜
        import gc
        gc.collect()
    
    return results

# æ–¹æ¡ˆ2: ä½¿ç”¨ç”Ÿæˆå™¨
def data_generator(symbols):
    for symbol in symbols:
        data = get_data(symbol)
        yield symbol, data

# æ–¹æ¡ˆ3: ä¼˜åŒ–æ•°æ®ç±»å‹
# ä½¿ç”¨æ›´å°çš„æ•°æ®ç±»å‹
data['close'] = data['close'].astype('float32')  # è€Œä¸æ˜¯float64
data['volume'] = data['volume'].astype('int32')   # è€Œä¸æ˜¯int64

# æ–¹æ¡ˆ4: åŠæ—¶åˆ é™¤ä¸éœ€è¦çš„å˜é‡
del large_dataframe
import gc
gc.collect()
```

### Q15: ç¼“å­˜æ–‡ä»¶è¿‡å¤§

**é—®é¢˜æè¿°**: data_cacheç›®å½•å ç”¨ç£ç›˜ç©ºé—´è¿‡å¤š

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: å®šæœŸæ¸…ç†ç¼“å­˜
import os
import time
from pathlib import Path

def clean_old_cache(cache_dir='data_cache', days=7):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„ç¼“å­˜æ–‡ä»¶"""
    cache_path = Path(cache_dir)
    if not cache_path.exists():
        return
    
    cutoff_time = time.time() - (days * 24 * 3600)
    
    for file_path in cache_path.glob('*.meta'):
        if file_path.stat().st_mtime < cutoff_time:
            file_path.unlink()
            print(f"åˆ é™¤è¿‡æœŸç¼“å­˜: {file_path}")

# æ–¹æ¡ˆ2: å‹ç¼©ç¼“å­˜æ–‡ä»¶
import pickle
import gzip

def save_compressed_cache(data, filename):
    with gzip.open(filename, 'wb') as f:
        pickle.dump(data, f)

def load_compressed_cache(filename):
    with gzip.open(filename, 'rb') as f:
        return pickle.load(f)

# æ–¹æ¡ˆ3: è®¾ç½®ç¼“å­˜å¤§å°é™åˆ¶
def manage_cache_size(cache_dir='data_cache', max_size_mb=1000):
    """é™åˆ¶ç¼“å­˜ç›®å½•å¤§å°"""
    cache_path = Path(cache_dir)
    if not cache_path.exists():
        return
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in cache_path.glob('*'))
    total_size_mb = total_size / (1024 * 1024)
    
    if total_size_mb > max_size_mb:
        # åˆ é™¤æœ€æ—§çš„æ–‡ä»¶
        files = sorted(cache_path.glob('*'), key=lambda x: x.stat().st_mtime)
        for file_path in files:
            file_path.unlink()
            total_size -= file_path.stat().st_size
            if total_size / (1024 * 1024) <= max_size_mb * 0.8:
                break
```

---

## ğŸš¨ ç³»ç»Ÿé”™è¯¯å¤„ç†

### Q16: ç¨‹åºæ„å¤–å´©æºƒ

**é—®é¢˜æè¿°**: ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­çªç„¶åœæ­¢ï¼Œæ²¡æœ‰æ˜ç¡®é”™è¯¯ä¿¡æ¯

**è°ƒè¯•æ–¹æ¡ˆ**:
```python
import logging
import traceback

# æ–¹æ¡ˆ1: è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

# æ–¹æ¡ˆ2: å…¨å±€å¼‚å¸¸å¤„ç†
def handle_exception(exc_type, exc_value, exc_traceback):
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return
    
    logging.error("æœªæ•è·çš„å¼‚å¸¸", exc_info=(exc_type, exc_value, exc_traceback))

sys.excepthook = handle_exception

# æ–¹æ¡ˆ3: ä½¿ç”¨try-exceptåŒ…è£…ä¸»è¦é€»è¾‘
def safe_main():
    try:
        # ä¸»è¦ç¨‹åºé€»è¾‘
        main_logic()
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        logging.error(traceback.format_exc())
        return False
    return True

if __name__ == "__main__":
    success = safe_main()
    if not success:
        print("ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹debug.logè·å–è¯¦ç»†ä¿¡æ¯")
```

### Q17: æ•°æ®ç±»å‹é”™è¯¯

**é—®é¢˜æè¿°**: 
```python
TypeError: unsupported operand type(s) for /: 'str' and 'int'
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: æ•°æ®ç±»å‹æ£€æŸ¥å’Œè½¬æ¢
def ensure_numeric(data, column):
    """ç¡®ä¿åˆ—ä¸ºæ•°å€¼ç±»å‹"""
    if data[column].dtype == 'object':
        # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
        data[column] = pd.to_numeric(data[column], errors='coerce')
    return data

# æ–¹æ¡ˆ2: å®‰å…¨çš„æ•°å­¦è¿ç®—
def safe_math_operation(a, b, operation='divide'):
    """å®‰å…¨çš„æ•°å­¦è¿ç®—"""
    try:
        a = float(a) if not pd.isna(a) else np.nan
        b = float(b) if not pd.isna(b) else np.nan
        
        if operation == 'divide':
            return a / b if b != 0 else np.nan
        elif operation == 'multiply':
            return a * b
        # å…¶ä»–æ“ä½œ...
    except (ValueError, TypeError):
        return np.nan

# æ–¹æ¡ˆ3: æ•°æ®éªŒè¯å‡½æ•°
def validate_dataframe(df, required_columns):
    """éªŒè¯DataFrameçš„ç»“æ„å’Œæ•°æ®ç±»å‹"""
    errors = []
    
    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_cols = set(required_columns) - set(df.columns)
    if missing_cols:
        errors.append(f"ç¼ºå°‘åˆ—: {missing_cols}")
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    for col in ['open', 'high', 'low', 'close', 'volume']:
        if col in df.columns:
            if not pd.api.types.is_numeric_dtype(df[col]):
                errors.append(f"åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹")
    
    if errors:
        raise ValueError("æ•°æ®éªŒè¯å¤±è´¥: " + "; ".join(errors))
    
    return True
```

### Q18: æ–‡ä»¶è·¯å¾„é—®é¢˜

**é—®é¢˜æè¿°**: 
```python
FileNotFoundError: [Errno 2] No such file or directory
```

**è§£å†³æ–¹æ¡ˆ**:
```python
import os
from pathlib import Path

# æ–¹æ¡ˆ1: ä½¿ç”¨ç»å¯¹è·¯å¾„
def get_project_root():
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    return Path(__file__).parent.parent

def get_safe_path(*path_parts):
    """æ„å»ºå®‰å…¨çš„æ–‡ä»¶è·¯å¾„"""
    root = get_project_root()
    return root / Path(*path_parts)

# ä½¿ç”¨ç¤ºä¾‹
config_path = get_safe_path('config', 'settings.json')
data_path = get_safe_path('data', 'stock_data.csv')

# æ–¹æ¡ˆ2: æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
def safe_file_operation(file_path, operation='read'):
    """å®‰å…¨çš„æ–‡ä»¶æ“ä½œ"""
    path = Path(file_path)
    
    if operation == 'read':
        if not path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        if not path.is_file():
            raise ValueError(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {path}")
    
    elif operation == 'write':
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        path.parent.mkdir(parents=True, exist_ok=True)
    
    return path

# æ–¹æ¡ˆ3: è·¨å¹³å°è·¯å¾„å¤„ç†
def normalize_path(path_str):
    """æ ‡å‡†åŒ–è·¯å¾„ï¼Œå¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿçš„å·®å¼‚"""
    return str(Path(path_str).resolve())
```

---

## ğŸ†˜ è·å–å¸®åŠ©

### è”ç³»æ–¹å¼
- **GitHub Issues**: åœ¨é¡¹ç›®ä»“åº“æäº¤é—®é¢˜
- **é‚®ä»¶æ”¯æŒ**: support@example.com
- **æŠ€æœ¯æ–‡æ¡£**: æŸ¥çœ‹ `docs/` ç›®å½•ä¸‹çš„è¯¦ç»†æ–‡æ¡£

### æäº¤é—®é¢˜æ—¶è¯·åŒ…å«
1. **é”™è¯¯ä¿¡æ¯**: å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
2. **ç¯å¢ƒä¿¡æ¯**: Pythonç‰ˆæœ¬ã€æ“ä½œç³»ç»Ÿã€ä¾èµ–åŒ…ç‰ˆæœ¬
3. **é‡ç°æ­¥éª¤**: è¯¦ç»†çš„æ“ä½œæ­¥éª¤
4. **ç›¸å…³ä»£ç **: å‡ºé”™çš„ä»£ç ç‰‡æ®µ
5. **æ•°æ®æ ·æœ¬**: å¦‚æœæ¶‰åŠæ•°æ®é—®é¢˜ï¼Œæä¾›æ ·æœ¬æ•°æ®

### è‡ªåŠ©æ’æŸ¥æ¸…å•
- [ ] æ£€æŸ¥Pythonç‰ˆæœ¬æ˜¯å¦ä¸º3.8+
- [ ] ç¡®è®¤æ‰€æœ‰ä¾èµ–åŒ…å·²æ­£ç¡®å®‰è£…
- [ ] éªŒè¯é¡¹ç›®ç›®å½•ç»“æ„å®Œæ•´
- [ ] æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
- [ ] æŸ¥çœ‹æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
- [ ] ç¡®è®¤æ–‡ä»¶æƒé™è®¾ç½®æ­£ç¡®
- [ ] æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [åˆå­¦è€…ä½¿ç”¨æŒ‡å—](BEGINNER_GUIDE.md)
- [å›¾è¡¨è§£è¯»æŒ‡å—](CHART_INTERPRETATION_GUIDE.md)
- [APIå‚è€ƒæ–‡æ¡£](API_REFERENCE.md)
- [å¼€å‘è€…æŒ‡å—](DEVELOPER_GUIDE.md)

---

**è®°ä½**: é‡åˆ°é—®é¢˜æ—¶ä¸è¦æ…Œå¼ ï¼Œå¤§å¤šæ•°é—®é¢˜éƒ½æœ‰è§£å†³æ–¹æ¡ˆã€‚ä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯ï¼ŒæŒ‰ç…§æœ¬æ–‡æ¡£çš„æŒ‡å¯¼é€æ­¥æ’æŸ¥ï¼Œé€šå¸¸èƒ½å¤Ÿå¿«é€Ÿè§£å†³é—®é¢˜ã€‚å¦‚æœé—®é¢˜ä¾ç„¶å­˜åœ¨ï¼Œè¯·ä¸è¦çŠ¹è±«å¯»æ±‚å¸®åŠ©ï¼