#!/usr/bin/env python3
"""
MLå¢å¼ºçš„Citadelé«˜é¢‘äº¤æ˜“ç­–ç•¥
é›†æˆç‰¹å¾åˆ†æã€å‚æ•°ä¼˜åŒ–å’Œè‡ªé€‚åº”é£é™©ç®¡ç†
"""

import numpy as np
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# MLç›¸å…³åº“
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.feature_selection import SelectKBest, f_regression, RFE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import optuna
from scipy.optimize import minimize
import joblib

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn-v0_8')

class MLEnhancedCitadelStrategy:
    """MLå¢å¼ºçš„Citadelç­–ç•¥"""
    
    def __init__(self, initial_capital=1000000):
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.positions = {}
        self.trades = []
        self.portfolio_value = []
        self.dates = []
        
        # MLæ¨¡å‹å’Œç»„ä»¶
        self.feature_selector = None
        self.risk_model = None
        self.parameter_optimizer = None
        self.scaler = StandardScaler()
        
        # åŠ¨æ€å‚æ•°ï¼ˆå°†é€šè¿‡MLä¼˜åŒ–ï¼‰
        self.params = {
            'signal_threshold': 0.03,
            'volume_threshold': 1.2,
            'volatility_threshold': 0.02,
            'momentum_weight': 0.4,
            'mean_reversion_weight': 0.3,
            'microstructure_weight': 0.1,
            'volume_weight': 0.1,
            'technical_weight': 0.1,
            'stop_loss': 0.02,
            'take_profit': 0.06,
            'trailing_stop': 0.015,
            'max_position_size': 0.3,
            'lookback_period': 20
        }
        
        # ç‰¹å¾é‡è¦æ€§è®°å½•
        self.feature_importance = {}
        self.feature_names = []
        
        # è‡ªé€‚åº”é£é™©ç®¡ç†å‚æ•°
        self.adaptive_risk_params = {
            'volatility_lookback': 10,
            'risk_adjustment_factor': 1.0,
            'max_drawdown_threshold': 0.05
        }
    
    def fetch_data(self, symbol, period="1y"):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            stock = yf.Ticker(symbol)
            data = stock.history(period=period, interval="1d")
            if data.empty:
                print(f"âš ï¸  æ— æ³•è·å– {symbol} çš„æ•°æ®")
                return None
            return data
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            return None
    
    def calculate_technical_indicators(self, data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        df = data.copy()
        
        # åŸºç¡€æŒ‡æ ‡
        df['Returns'] = df['Close'].pct_change()
        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))
        
        # ç§»åŠ¨å¹³å‡
        for period in [5, 10, 20, 50]:
            df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()
            df[f'MA_Ratio_{period}'] = df['Close'] / df[f'MA_{period}']
        
        # æ³¢åŠ¨ç‡æŒ‡æ ‡
        df['Volatility_5'] = df['Returns'].rolling(window=5).std()
        df['Volatility_20'] = df['Returns'].rolling(window=20).std()
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['Close'].ewm(span=12).mean()
        exp2 = df['Close'].ewm(span=26).mean()
        df['MACD'] = exp1 - exp2
        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
        
        # å¸ƒæ—å¸¦
        df['BB_Middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
        df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
        df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
        
        # æˆäº¤é‡æŒ‡æ ‡
        df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']
        
        # ä»·æ ¼åŠ¨é‡
        for period in [1, 3, 5, 10]:
            df[f'Price_Momentum_{period}'] = df['Close'].pct_change(period)
        
        # é«˜ä½ä»·æ¯”ç‡
        df['High_Low_Ratio'] = df['High'] / df['Low']
        df['Close_Position'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])
        
        return df
    
    def extract_features(self, data):
        """æå–MLç‰¹å¾"""
        df = self.calculate_technical_indicators(data)
        
        # å®šä¹‰ç‰¹å¾åˆ—
        feature_columns = [
            'MA_Ratio_5', 'MA_Ratio_10', 'MA_Ratio_20', 'MA_Ratio_50',
            'Volatility_5', 'Volatility_20',
            'RSI', 'MACD', 'MACD_Signal', 'MACD_Histogram',
            'BB_Position', 'Volume_Ratio',
            'Price_Momentum_1', 'Price_Momentum_3', 'Price_Momentum_5', 'Price_Momentum_10',
            'High_Low_Ratio', 'Close_Position'
        ]
        
        # æ·»åŠ æ»åç‰¹å¾
        for col in ['Returns', 'Volume_Ratio', 'RSI']:
            for lag in [1, 2, 3]:
                feature_columns.append(f'{col}_lag_{lag}')
                df[f'{col}_lag_{lag}'] = df[col].shift(lag)
        
        # æ·»åŠ æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
        for window in [5, 10]:
            df[f'Returns_Mean_{window}'] = df['Returns'].rolling(window=window).mean()
            df[f'Returns_Std_{window}'] = df['Returns'].rolling(window=window).std()
            df[f'Volume_Mean_{window}'] = df['Volume_Ratio'].rolling(window=window).mean()
            feature_columns.extend([f'Returns_Mean_{window}', f'Returns_Std_{window}', f'Volume_Mean_{window}'])
        
        # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆæœªæ¥æ”¶ç›Šï¼‰
        df['Target'] = df['Returns'].shift(-1)  # é¢„æµ‹ä¸‹ä¸€æœŸæ”¶ç›Š
        
        self.feature_names = feature_columns
        return df[feature_columns + ['Target']].dropna()
    
    def perform_feature_analysis(self, features_data):
        """æ‰§è¡ŒMLç‰¹å¾åˆ†æ"""
        print("ğŸ” æ‰§è¡ŒMLç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        X = features_data[self.feature_names]
        y = features_data['Target']
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # 1. éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_scaled, y)
        rf_importance = rf.feature_importances_
        
        # 2. æ¢¯åº¦æå‡ç‰¹å¾é‡è¦æ€§
        gb = GradientBoostingRegressor(n_estimators=100, random_state=42)
        gb.fit(X_scaled, y)
        gb_importance = gb.feature_importances_
        
        # 3. å•å˜é‡ç‰¹å¾é€‰æ‹©
        selector = SelectKBest(score_func=f_regression, k='all')
        selector.fit(X_scaled, y)
        univariate_scores = selector.scores_
        
        # 4. é€’å½’ç‰¹å¾æ¶ˆé™¤
        rfe = RFE(estimator=RandomForestRegressor(n_estimators=50, random_state=42), n_features_to_select=10)
        rfe.fit(X_scaled, y)
        rfe_ranking = rfe.ranking_
        
        # ç»¼åˆç‰¹å¾é‡è¦æ€§
        feature_importance_df = pd.DataFrame({
            'Feature': self.feature_names,
            'RF_Importance': rf_importance,
            'GB_Importance': gb_importance,
            'Univariate_Score': univariate_scores / np.max(univariate_scores),  # å½’ä¸€åŒ–
            'RFE_Ranking': rfe_ranking
        })
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        feature_importance_df['Combined_Score'] = (
            feature_importance_df['RF_Importance'] * 0.3 +
            feature_importance_df['GB_Importance'] * 0.3 +
            feature_importance_df['Univariate_Score'] * 0.3 +
            (1 / feature_importance_df['RFE_Ranking']) * 0.1
        )
        
        # æ’åºå¹¶ä¿å­˜
        feature_importance_df = feature_importance_df.sort_values('Combined_Score', ascending=False)
        self.feature_importance = feature_importance_df.set_index('Feature')['Combined_Score'].to_dict()
        
        # æ˜¾ç¤ºç»“æœ
        print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ (Top 10):")
        print("-" * 60)
        for i, (feature, score) in enumerate(feature_importance_df.head(10)[['Feature', 'Combined_Score']].values):
            importance_level = "é«˜" if score > 0.05 else "ä¸­" if score > 0.02 else "ä½"
            print(f"{i+1:2d}. {feature:<25} {score:.4f} ({importance_level}é‡è¦æ€§)")
        
        # è¯†åˆ«å…³é”®ç‰¹å¾
        self.key_features = feature_importance_df.head(15)['Feature'].tolist()
        print(f"\nâœ… è¯†åˆ«å‡º {len(self.key_features)} ä¸ªå…³é”®ç‰¹å¾ç”¨äºç­–ç•¥ä¼˜åŒ–")
        
        return feature_importance_df
    
    def bayesian_parameter_optimization(self, features_data):
        """è´å¶æ–¯å‚æ•°ä¼˜åŒ–"""
        print("\nğŸ¯ æ‰§è¡Œè´å¶æ–¯å‚æ•°ä¼˜åŒ–...")
        
        def objective(trial):
            # å®šä¹‰å‚æ•°æœç´¢ç©ºé—´
            params = {
                'signal_threshold': trial.suggest_float('signal_threshold', 0.01, 0.10),
                'volume_threshold': trial.suggest_float('volume_threshold', 1.0, 2.0),
                'volatility_threshold': trial.suggest_float('volatility_threshold', 0.01, 0.05),
                'momentum_weight': trial.suggest_float('momentum_weight', 0.1, 0.6),
                'mean_reversion_weight': trial.suggest_float('mean_reversion_weight', 0.1, 0.5),
                'stop_loss': trial.suggest_float('stop_loss', 0.01, 0.05),
                'take_profit': trial.suggest_float('take_profit', 0.03, 0.10),
                'max_position_size': trial.suggest_float('max_position_size', 0.1, 0.5)
            }
            
            # ä½¿ç”¨å‚æ•°è¿›è¡Œå¿«é€Ÿå›æµ‹è¯„ä¼°
            score = self.evaluate_parameters(params, features_data)
            return score
        
        # åˆ›å»ºä¼˜åŒ–ç ”ç©¶
        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())
        study.optimize(objective, n_trials=50, show_progress_bar=True)
        
        # è·å–æœ€ä¼˜å‚æ•°
        best_params = study.best_params
        best_score = study.best_value
        
        print(f"\nğŸ† è´å¶æ–¯ä¼˜åŒ–å®Œæˆ!")
        print(f"   æœ€ä¼˜å¾—åˆ†: {best_score:.4f}")
        print(f"   æœ€ä¼˜å‚æ•°:")
        for param, value in best_params.items():
            print(f"      {param}: {value:.4f}")
        
        # æ›´æ–°ç­–ç•¥å‚æ•°
        self.params.update(best_params)
        
        return best_params, best_score
    
    def evaluate_parameters(self, params, features_data, quick_eval=True):
        """è¯„ä¼°å‚æ•°ç»„åˆçš„æ€§èƒ½"""
        # ç®€åŒ–çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äºå‚æ•°ä¼˜åŒ–
        try:
            # æ¨¡æ‹Ÿç­–ç•¥æ”¶ç›Š
            X = features_data[self.key_features[:10]]  # ä½¿ç”¨å…³é”®ç‰¹å¾
            y = features_data['Target']
            
            # ä½¿ç”¨å‚æ•°æƒé‡è®¡ç®—ä¿¡å·
            signal_weights = np.array([
                params.get('momentum_weight', 0.4),
                params.get('mean_reversion_weight', 0.3),
                0.1, 0.1, 0.1  # å…¶ä»–æƒé‡
            ])
            
            # ç®€åŒ–çš„ä¿¡å·è®¡ç®—
            signals = np.random.normal(0, params.get('signal_threshold', 0.03), len(X))
            
            # è®¡ç®—æ”¶ç›Š
            returns = signals * y.values
            
            # åº”ç”¨é£é™©æ§åˆ¶
            returns = np.clip(returns, -params.get('stop_loss', 0.02), params.get('take_profit', 0.06))
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            total_return = np.sum(returns)
            volatility = np.std(returns)
            sharpe_ratio = total_return / (volatility + 1e-8)
            
            # ç»¼åˆå¾—åˆ†
            score = sharpe_ratio * 0.6 + total_return * 0.4
            
            return score
            
        except Exception as e:
            return -1.0  # è¿”å›è´Ÿåˆ†è¡¨ç¤ºå‚æ•°æ— æ•ˆ
    
    def build_adaptive_risk_model(self, features_data):
        """æ„å»ºè‡ªé€‚åº”é£é™©ç®¡ç†æ¨¡å‹"""
        print("\nğŸ›¡ï¸  æ„å»ºè‡ªé€‚åº”é£é™©ç®¡ç†æ¨¡å‹...")
        
        # å‡†å¤‡é£é™©å»ºæ¨¡æ•°æ®
        X = features_data[self.key_features]
        
        # è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡ä½œä¸ºé£é™©ç›®æ ‡
        returns = features_data['Target']
        rolling_vol = returns.rolling(window=self.adaptive_risk_params['volatility_lookback']).std()
        
        # è®­ç»ƒé£é™©é¢„æµ‹æ¨¡å‹
        valid_idx = ~(rolling_vol.isna() | X.isna().any(axis=1))
        X_risk = X[valid_idx]
        y_risk = rolling_vol[valid_idx]
        
        if len(X_risk) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
            self.risk_model = RandomForestRegressor(n_estimators=100, random_state=42)
            self.risk_model.fit(X_risk, y_risk)
            
            # è¯„ä¼°æ¨¡å‹æ€§èƒ½
            risk_score = self.risk_model.score(X_risk, y_risk)
            print(f"   é£é™©é¢„æµ‹æ¨¡å‹ RÂ² å¾—åˆ†: {risk_score:.4f}")
            
            # ä¿å­˜æ¨¡å‹
            joblib.dump(self.risk_model, '/tmp/adaptive_risk_model.pkl')
            print("   âœ… è‡ªé€‚åº”é£é™©æ¨¡å‹è®­ç»ƒå®Œæˆ")
        else:
            print("   âš ï¸  æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤é£é™©å‚æ•°")
    
    def predict_adaptive_risk(self, current_features):
        """é¢„æµ‹å½“å‰çš„é£é™©æ°´å¹³å¹¶è°ƒæ•´å‚æ•°"""
        if self.risk_model is None:
            return self.params['stop_loss'], self.params['take_profit']
        
        try:
            # é¢„æµ‹é£é™©
            risk_features = current_features[self.key_features].values.reshape(1, -1)
            predicted_volatility = self.risk_model.predict(risk_features)[0]
            
            # æ ¹æ®é¢„æµ‹é£é™©è°ƒæ•´å‚æ•°
            risk_multiplier = min(max(predicted_volatility / 0.02, 0.5), 2.0)  # é™åˆ¶åœ¨0.5-2.0å€
            
            adaptive_stop_loss = self.params['stop_loss'] * risk_multiplier
            adaptive_take_profit = self.params['take_profit'] * risk_multiplier
            
            return adaptive_stop_loss, adaptive_take_profit
            
        except Exception as e:
            print(f"   âš ï¸  é£é™©é¢„æµ‹å¤±è´¥: {e}")
            return self.params['stop_loss'], self.params['take_profit']
    
    def generate_ml_enhanced_signals(self, data):
        """ç”ŸæˆMLå¢å¼ºçš„äº¤æ˜“ä¿¡å·"""
        features_data = self.extract_features(data)
        
        if len(features_data) < 50:
            print("âš ï¸  æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå¯é ä¿¡å·")
            return pd.Series(0, index=data.index)
        
        # ä½¿ç”¨å…³é”®ç‰¹å¾ç”Ÿæˆä¿¡å·
        X = features_data[self.key_features]
        
        # è®¡ç®—åŠ æƒä¿¡å·
        signals = pd.Series(0.0, index=X.index)
        
        # åŸºäºç‰¹å¾é‡è¦æ€§çš„åŠ æƒä¿¡å·
        for feature in self.key_features[:5]:  # ä½¿ç”¨å‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            if feature in X.columns:
                feature_weight = self.feature_importance.get(feature, 0.1)
                feature_signal = X[feature] * feature_weight
                signals += feature_signal
        
        # æ ‡å‡†åŒ–ä¿¡å·
        signals = (signals - signals.mean()) / (signals.std() + 1e-8)
        
        # åº”ç”¨ä¿¡å·é˜ˆå€¼
        buy_signals = signals > self.params['signal_threshold']
        sell_signals = signals < -self.params['signal_threshold']
        
        # è½¬æ¢ä¸ºäº¤æ˜“ä¿¡å·
        trade_signals = pd.Series(0, index=signals.index)
        trade_signals[buy_signals] = 1
        trade_signals[sell_signals] = -1
        
        return trade_signals.reindex(data.index, fill_value=0)
    
    def backtest_ml_strategy(self, symbol, period="1y"):
        """MLå¢å¼ºç­–ç•¥å›æµ‹"""
        print(f"ğŸš€ å¼€å§‹MLå¢å¼ºçš„ {symbol} ç­–ç•¥å›æµ‹...")
        
        # è·å–æ•°æ®
        data = self.fetch_data(symbol, period)
        if data is None:
            return None
        
        # æå–ç‰¹å¾å¹¶è¿›è¡Œåˆ†æ
        features_data = self.extract_features(data)
        
        # æ‰§è¡ŒMLåˆ†æ
        self.perform_feature_analysis(features_data)
        
        # å‚æ•°ä¼˜åŒ–
        self.bayesian_parameter_optimization(features_data)
        
        # æ„å»ºè‡ªé€‚åº”é£é™©æ¨¡å‹
        self.build_adaptive_risk_model(features_data)
        
        # ç”Ÿæˆäº¤æ˜“ä¿¡å·
        signals = self.generate_ml_enhanced_signals(data)
        
        # æ‰§è¡Œå›æµ‹
        self.capital = self.initial_capital
        self.positions = {}
        self.trades = []
        self.portfolio_value = []
        self.dates = []
        
        for i, (date, row) in enumerate(data.iterrows()):
            current_price = row['Close']
            signal = signals.loc[date] if date in signals.index else 0
            
            # è·å–å½“å‰ç‰¹å¾ç”¨äºè‡ªé€‚åº”é£é™©ç®¡ç†
            if i >= len(self.key_features) and len(features_data) > i:
                current_features = features_data.iloc[i-len(self.key_features):i].mean()
                adaptive_stop_loss, adaptive_take_profit = self.predict_adaptive_risk(current_features)
            else:
                adaptive_stop_loss = self.params['stop_loss']
                adaptive_take_profit = self.params['take_profit']
            
            # æ‰§è¡Œäº¤æ˜“é€»è¾‘
            self.execute_trade(symbol, current_price, signal, date, 
                             adaptive_stop_loss, adaptive_take_profit)
            
            # è®°å½•ç»„åˆä»·å€¼
            portfolio_val = self.calculate_portfolio_value({symbol: current_price})
            self.portfolio_value.append(portfolio_val)
            self.dates.append(date)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        results = self.calculate_performance_metrics()
        
        print(f"\nğŸ“Š MLå¢å¼ºç­–ç•¥å›æµ‹å®Œæˆ!")
        self.print_performance_summary(results)
        
        return results
    
    def execute_trade(self, symbol, price, signal, date, stop_loss, take_profit):
        """æ‰§è¡Œäº¤æ˜“"""
        current_position = self.positions.get(symbol, 0)
        
        if signal == 1 and current_position == 0:  # ä¹°å…¥ä¿¡å·
            position_size = min(self.params['max_position_size'], 
                              self.capital / price * self.params['max_position_size'])
            cost = position_size * price
            
            if cost <= self.capital:
                self.positions[symbol] = position_size
                self.capital -= cost
                self.trades.append({
                    'Date': date,
                    'Symbol': symbol,
                    'Action': 'BUY',
                    'Quantity': position_size,
                    'Price': price,
                    'Value': cost,
                    'Stop_Loss': stop_loss,
                    'Take_Profit': take_profit
                })
        
        elif signal == -1 and current_position > 0:  # å–å‡ºä¿¡å·
            revenue = current_position * price
            self.capital += revenue
            self.trades.append({
                'Date': date,
                'Symbol': symbol,
                'Action': 'SELL',
                'Quantity': current_position,
                'Price': price,
                'Value': revenue,
                'Stop_Loss': stop_loss,
                'Take_Profit': take_profit
            })
            self.positions[symbol] = 0
    
    def calculate_portfolio_value(self, current_prices):
        """è®¡ç®—ç»„åˆä»·å€¼"""
        portfolio_value = self.capital
        for symbol, quantity in self.positions.items():
            if symbol in current_prices:
                portfolio_value += quantity * current_prices[symbol]
        return portfolio_value
    
    def calculate_performance_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        if not self.portfolio_value:
            return {}
        
        portfolio_series = pd.Series(self.portfolio_value, index=self.dates)
        returns = portfolio_series.pct_change().dropna()
        
        total_return = (portfolio_series.iloc[-1] / self.initial_capital - 1) * 100
        volatility = returns.std() * np.sqrt(252) * 100
        sharpe_ratio = (returns.mean() * 252) / (returns.std() * np.sqrt(252)) if returns.std() > 0 else 0
        
        # æœ€å¤§å›æ’¤
        cumulative = (1 + returns).cumprod()
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max
        max_drawdown = drawdown.min() * 100
        
        return {
            'Total_Return': total_return,
            'Volatility': volatility,
            'Sharpe_Ratio': sharpe_ratio,
            'Max_Drawdown': max_drawdown,
            'Total_Trades': len(self.trades),
            'Final_Capital': portfolio_series.iloc[-1],
            'Win_Rate': self.calculate_win_rate()
        }
    
    def calculate_win_rate(self):
        """è®¡ç®—èƒœç‡"""
        if len(self.trades) < 2:
            return 0
        
        profits = []
        buy_price = None
        
        for trade in self.trades:
            if trade['Action'] == 'BUY':
                buy_price = trade['Price']
            elif trade['Action'] == 'SELL' and buy_price:
                profit = (trade['Price'] - buy_price) / buy_price
                profits.append(profit)
                buy_price = None
        
        if not profits:
            return 0
        
        winning_trades = sum(1 for p in profits if p > 0)
        return (winning_trades / len(profits)) * 100
    
    def print_performance_summary(self, results):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“ˆ MLå¢å¼ºç­–ç•¥æ€§èƒ½æ‘˜è¦")
        print("="*60)
        print(f"ğŸ’° æ€»æ”¶ç›Šç‡:     {results['Total_Return']:.2f}%")
        print(f"ğŸ“Š å¹´åŒ–æ³¢åŠ¨ç‡:   {results['Volatility']:.2f}%")
        print(f"âš¡ å¤æ™®æ¯”ç‡:     {results['Sharpe_Ratio']:.2f}")
        print(f"ğŸ“‰ æœ€å¤§å›æ’¤:     {results['Max_Drawdown']:.2f}%")
        print(f"ğŸ”„ äº¤æ˜“æ¬¡æ•°:     {results['Total_Trades']}")
        print(f"ğŸ¯ èƒœç‡:         {results['Win_Rate']:.2f}%")
        print(f"ğŸ’µ æœ€ç»ˆèµ„äº§:     ${results['Final_Capital']:,.2f}")
        print("="*60)
    
    def visualize_results(self, symbol):
        """å¯è§†åŒ–ç»“æœ"""
        if not self.portfolio_value:
            print("âš ï¸  æ²¡æœ‰å›æµ‹æ•°æ®å¯ä¾›å¯è§†åŒ–")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'MLå¢å¼ºçš„{symbol}ç­–ç•¥åˆ†æç»“æœ', fontsize=16, fontweight='bold')
        
        # 1. èµ„äº§æ›²çº¿
        portfolio_series = pd.Series(self.portfolio_value, index=self.dates)
        axes[0, 0].plot(portfolio_series.index, portfolio_series.values, 'b-', linewidth=2)
        axes[0, 0].axhline(y=self.initial_capital, color='r', linestyle='--', alpha=0.7)
        axes[0, 0].set_title('èµ„äº§å¢é•¿æ›²çº¿')
        axes[0, 0].set_ylabel('èµ„äº§ä»·å€¼ ($)')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ç‰¹å¾é‡è¦æ€§
        if self.feature_importance:
            top_features = dict(list(self.feature_importance.items())[:10])
            axes[0, 1].barh(range(len(top_features)), list(top_features.values()))
            axes[0, 1].set_yticks(range(len(top_features)))
            axes[0, 1].set_yticklabels(list(top_features.keys()), fontsize=8)
            axes[0, 1].set_title('Top 10 ç‰¹å¾é‡è¦æ€§')
            axes[0, 1].set_xlabel('é‡è¦æ€§å¾—åˆ†')
        
        # 3. æ”¶ç›Šåˆ†å¸ƒ
        returns = portfolio_series.pct_change().dropna()
        axes[1, 0].hist(returns, bins=30, alpha=0.7, color='green')
        axes[1, 0].axvline(x=returns.mean(), color='red', linestyle='--', label=f'å‡å€¼: {returns.mean():.4f}')
        axes[1, 0].set_title('æ”¶ç›Šç‡åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('æ—¥æ”¶ç›Šç‡')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].legend()
        
        # 4. å›æ’¤åˆ†æ
        cumulative = (1 + returns).cumprod()
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max * 100
        axes[1, 1].fill_between(drawdown.index, drawdown.values, 0, alpha=0.3, color='red')
        axes[1, 1].plot(drawdown.index, drawdown.values, 'r-', linewidth=1)
        axes[1, 1].set_title('å›æ’¤åˆ†æ')
        axes[1, 1].set_ylabel('å›æ’¤ (%)')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'/tmp/ml_enhanced_{symbol}_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: /tmp/ml_enhanced_{symbol}_analysis.png")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– MLå¢å¼ºçš„Citadelé«˜é¢‘äº¤æ˜“ç­–ç•¥")
    print("=" * 60)
    
    # åˆ›å»ºç­–ç•¥å®ä¾‹
    strategy = MLEnhancedCitadelStrategy(initial_capital=1000000)
    
    # æµ‹è¯•è‚¡ç¥¨
    test_symbols = ['AAPL', 'MSFT', 'GOOGL']
    
    for symbol in test_symbols:
        print(f"\nğŸ¯ æµ‹è¯•è‚¡ç¥¨: {symbol}")
        print("-" * 40)
        
        # æ‰§è¡ŒMLå¢å¼ºå›æµ‹
        results = strategy.backtest_ml_strategy(symbol, period="1y")
        
        if results:
            # å¯è§†åŒ–ç»“æœ
            strategy.visualize_results(symbol)
            
            print(f"\nâœ… {symbol} MLå¢å¼ºç­–ç•¥æµ‹è¯•å®Œæˆ")
        else:
            print(f"âŒ {symbol} ç­–ç•¥æµ‹è¯•å¤±è´¥")
        
        print("\n" + "="*60)
    
    print("ğŸš€ MLå¢å¼ºç­–ç•¥åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    main()