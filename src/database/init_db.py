"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

ç”¨äºåˆ›å»ºæ•°æ®åº“è¡¨ã€åˆå§‹åŒ–æ•°æ®å’Œæµ‹è¯•è¿æ¥
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.database.connection import DatabaseManager
from src.database.models import Base
from sqlalchemy import text

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_env_file(env_file: str = '.env'):
    """
    åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶
    
    Args:
        env_file: ç¯å¢ƒå˜é‡æ–‡ä»¶è·¯å¾„
    """
    env_path = project_root / env_file
    
    if not env_path.exists():
        logger.warning(f"ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")
        logger.info("è¯·å¤åˆ¶ .env.database æ–‡ä»¶ä¸º .env å¹¶é…ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯")
        return
    
    try:
        from dotenv import load_dotenv
        load_dotenv(env_path)
        logger.info(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
    except ImportError:
        logger.warning("python-dotenv æœªå®‰è£…ï¼Œè¯·æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡")


def test_database_connections(db_manager: DatabaseManager) -> Dict[str, bool]:
    """
    æµ‹è¯•æ•°æ®åº“è¿æ¥
    
    Args:
        db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
        
    Returns:
        dict: è¿æ¥æµ‹è¯•ç»“æœ
    """
    logger.info("å¼€å§‹æµ‹è¯•æ•°æ®åº“è¿æ¥...")
    
    results = db_manager.test_connections()
    
    for db_type, success in results.items():
        if success:
            logger.info(f"âœ… {db_type.upper()} è¿æ¥æˆåŠŸ")
        else:
            logger.error(f"âŒ {db_type.upper()} è¿æ¥å¤±è´¥")
    
    return results


def create_database_tables(db_manager: DatabaseManager):
    """
    åˆ›å»ºæ•°æ®åº“è¡¨
    
    Args:
        db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
    """
    logger.info("å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
    
    try:
        db_manager.create_tables()
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        
        # éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        engine = db_manager.get_postgresql_engine()
        with engine.connect() as conn:
            # æ ¹æ®æ•°æ®åº“ç±»å‹é€‰æ‹©ä¸åŒçš„æŸ¥è¯¢è¯­å¥
            if 'sqlite' in str(engine.url):
                # SQLiteæŸ¥è¯¢è¯­å¥
                result = conn.execute(text("""
                    SELECT name as table_name 
                    FROM sqlite_master 
                    WHERE type='table' AND name NOT LIKE 'sqlite_%'
                    ORDER BY name
                """))
            else:
                # PostgreSQLæŸ¥è¯¢è¯­å¥
                result = conn.execute(text("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    ORDER BY table_name
                """))
            
            tables = [row[0] for row in result]
            logger.info(f"å·²åˆ›å»ºçš„è¡¨: {', '.join(tables)}")
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥: {e}")
        raise


def initialize_sample_data(db_manager: DatabaseManager):
    """
    åˆå§‹åŒ–ç¤ºä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰
    
    Args:
        db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
    """
    logger.info("åˆå§‹åŒ–ç¤ºä¾‹æ•°æ®...")
    
    try:
        from datetime import datetime, timedelta
        from src.database.dao import stock_data_dao
        
        # åˆ›å»ºä¸€äº›ç¤ºä¾‹è‚¡ç¥¨æ•°æ®
        sample_data = [
            {
                'symbol': 'AAPL',
                'date': datetime.now() - timedelta(days=2),
                'open': 150.0,
                'high': 155.0,
                'low': 148.0,
                'close': 152.0,
                'volume': 1000000
            },
            {
                'symbol': 'AAPL',
                'date': datetime.now() - timedelta(days=1),
                'open': 152.0,
                'high': 158.0,
                'low': 151.0,
                'close': 156.0,
                'volume': 1200000
            }
        ]
        
        stock_data_dao.batch_create(sample_data)
        logger.info("âœ… ç¤ºä¾‹æ•°æ®åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        logger.warning(f"ç¤ºä¾‹æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")


def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ•°æ®åº“åˆå§‹åŒ–æµç¨‹
    """
    logger.info("ğŸš€ å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
    
    # 1. åŠ è½½ç¯å¢ƒå˜é‡
    load_env_file()
    
    # 2. åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
    db_manager = DatabaseManager()
    
    try:
        # 3. æµ‹è¯•æ•°æ®åº“è¿æ¥
        connection_results = test_database_connections(db_manager)
        
        # 4. å¦‚æœPostgreSQLè¿æ¥æˆåŠŸï¼Œåˆ›å»ºè¡¨
        if connection_results.get('postgresql', False):
            create_database_tables(db_manager)
            
            # 5. å¯é€‰ï¼šåˆå§‹åŒ–ç¤ºä¾‹æ•°æ®
            if '--sample-data' in sys.argv:
                initialize_sample_data(db_manager)
        else:
            logger.error("PostgreSQLè¿æ¥å¤±è´¥ï¼Œæ— æ³•åˆ›å»ºè¡¨")
            return False
        
        # 6. æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        logger.info("ğŸ“Š æ•°æ®åº“é…ç½®ä¿¡æ¯:")
        logger.info(f"  PostgreSQL: {os.getenv('POSTGRES_HOST', 'localhost')}:{os.getenv('POSTGRES_PORT', 5432)}")
        logger.info(f"  æ•°æ®åº“å: {os.getenv('POSTGRES_DB', 'quant_trading')}")
        logger.info(f"  Redis: {os.getenv('REDIS_HOST', 'localhost')}:{os.getenv('REDIS_PORT', 6379)}")
        
        logger.info("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    finally:
        # 7. å…³é—­è¿æ¥
        db_manager.close_connections()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)