"""
Alphaç”Ÿæˆèƒ½åŠ›æµ‹è¯•è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæµ‹è¯•æ–°å¢å› å­çš„Alphaç”Ÿæˆèƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š
1. åŠ è½½æ‰€æœ‰å› å­æ¨¡å—
2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
3. è®¡ç®—å„ç±»å› å­
4. è¯„ä¼°å› å­çš„Alphaç”Ÿæˆèƒ½åŠ›
5. ä¼˜åŒ–å› å­ç»„åˆ
6. ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# å¯¼å…¥å› å­æ¨¡å—
try:
    from factors.technical_factors import TechnicalFactorCalculator
    from factors.fundamental_factors import FundamentalFactorCalculator
    from factors.macro_factors import MacroFactorCalculator
    from factors.sentiment_factors import SentimentFactorCalculator
    from factors.ml_factors import MLFactorCalculator
    from factors.factor_optimizer import FactorOptimizer
    print("âœ“ æ‰€æœ‰å› å­æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— å› å­æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class AlphaGenerationTester:
    """Alphaç”Ÿæˆèƒ½åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.results = {}
        self.factor_calculators = {}
        self.optimizer = FactorOptimizer()
        
        print("Alphaç”Ÿæˆèƒ½åŠ›æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate_mock_data(self, n_stocks: int = 100, n_days: int = 252) -> dict:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        
        Args:
            n_stocks: è‚¡ç¥¨æ•°é‡
            n_days: äº¤æ˜“æ—¥æ•°é‡
            
        Returns:
            dict: åŒ…å«ä»·æ ¼ã€æˆäº¤é‡ã€åŸºæœ¬é¢ç­‰æ•°æ®çš„å­—å…¸
        """
        print(f"ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {n_stocks}åªè‚¡ç¥¨, {n_days}ä¸ªäº¤æ˜“æ—¥")
        
        # ç”Ÿæˆæ—¥æœŸç´¢å¼•
        dates = pd.date_range(start='2023-01-01', periods=n_days, freq='B')
        
        # ç”Ÿæˆè‚¡ç¥¨ä»£ç 
        stocks = [f'STOCK_{i:03d}' for i in range(n_stocks)]
        
        # ç”Ÿæˆä»·æ ¼æ•°æ®
        np.random.seed(42)
        
        # åˆå§‹ä»·æ ¼
        initial_prices = np.random.uniform(10, 100, n_stocks)
        
        # ç”Ÿæˆæ”¶ç›Šç‡ (å¸¦æœ‰ä¸€äº›è¶‹åŠ¿å’Œæ³¢åŠ¨æ€§)
        returns = np.random.normal(0.0005, 0.02, (n_days, n_stocks))
        
        # æ·»åŠ ä¸€äº›å¸‚åœºå› å­
        market_factor = np.random.normal(0, 0.015, n_days)
        for i in range(n_stocks):
            beta = np.random.uniform(0.5, 1.5)
            returns[:, i] += beta * market_factor
        
        # è®¡ç®—ä»·æ ¼
        prices = np.zeros((n_days, n_stocks))
        prices[0] = initial_prices
        
        for t in range(1, n_days):
            prices[t] = prices[t-1] * (1 + returns[t])
        
        # åˆ›å»ºDataFrame
        price_df = pd.DataFrame(prices, index=dates, columns=stocks)
        
        # ç”Ÿæˆæˆäº¤é‡æ•°æ®
        volumes = np.random.lognormal(10, 1, (n_days, n_stocks))
        volume_df = pd.DataFrame(volumes, index=dates, columns=stocks)
        
        # ç”ŸæˆåŸºæœ¬é¢æ•°æ® (å­£åº¦æ•°æ®)
        quarterly_dates = pd.date_range(start='2023-01-01', periods=n_days//60, freq='Q')
        
        fundamental_data = {}
        for stock in stocks:
            fundamental_data[stock] = {
                'market_cap': np.random.uniform(1e8, 1e11),
                'pe_ratio': np.random.uniform(5, 50),
                'pb_ratio': np.random.uniform(0.5, 10),
                'roe': np.random.uniform(-0.2, 0.3),
                'debt_to_equity': np.random.uniform(0, 3),
                'revenue_growth': np.random.uniform(-0.5, 1.0),
                'net_margin': np.random.uniform(-0.1, 0.3),
                'current_ratio': np.random.uniform(0.5, 5),
                'quick_ratio': np.random.uniform(0.3, 3),
                'inventory_turnover': np.random.uniform(1, 20),
                'asset_turnover': np.random.uniform(0.1, 3),
                'gross_margin': np.random.uniform(0.1, 0.8)
            }
        
        # ç”Ÿæˆå®è§‚ç»æµæ•°æ®
        macro_data = {
            'interest_rate': pd.Series(np.random.uniform(0.01, 0.05, n_days), index=dates),
            'inflation_rate': pd.Series(np.random.uniform(0.01, 0.08, n_days), index=dates),
            'gdp_growth': pd.Series(np.random.uniform(-0.02, 0.06, n_days), index=dates),
            'unemployment_rate': pd.Series(np.random.uniform(0.03, 0.12, n_days), index=dates),
            'vix': pd.Series(np.random.uniform(10, 50, n_days), index=dates),
            'usd_index': pd.Series(np.random.uniform(90, 110, n_days), index=dates)
        }
        
        # è®¡ç®—æ”¶ç›Šç‡
        returns_df = price_df.pct_change().fillna(0)
        
        return {
            'prices': price_df,
            'volumes': volume_df,
            'returns': returns_df,
            'fundamental': fundamental_data,
            'macro': macro_data,
            'stocks': stocks,
            'dates': dates
        }
    
    def test_technical_factors(self, data: dict) -> dict:
        """æµ‹è¯•æŠ€æœ¯å› å­"""
        print("æµ‹è¯•æŠ€æœ¯å› å­...")
        
        calculator = TechnicalFactorCalculator()
        results = {}
        
        # é€‰æ‹©å‡ åªè‚¡ç¥¨è¿›è¡Œæµ‹è¯•
        test_stocks = data['stocks'][:10]
        
        for stock in test_stocks:
            try:
                stock_data = {
                    'close': data['prices'][stock],
                    'high': data['prices'][stock] * (1 + np.random.uniform(0, 0.02, len(data['prices']))),
                    'low': data['prices'][stock] * (1 - np.random.uniform(0, 0.02, len(data['prices']))),
                    'volume': data['volumes'][stock]
                }
                
                factors = calculator.calculate_all_factors(stock_data)
                
                # è®¡ç®—ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§
                returns = data['returns'][stock]
                correlations = {}
                
                for factor_name, factor_values in factors.items():
                    if factor_values is not None and len(factor_values) > 0:
                        # å¯¹é½æ•°æ®
                        aligned_data = pd.concat([factor_values, returns], axis=1, join='inner').dropna()
                        if len(aligned_data) > 30:
                            corr = aligned_data.iloc[:, 0].corr(aligned_data.iloc[:, 1])
                            correlations[factor_name] = abs(corr) if not np.isnan(corr) else 0
                
                results[stock] = {
                    'factors': factors,
                    'correlations': correlations
                }
                
            except Exception as e:
                print(f"è®¡ç®— {stock} æŠ€æœ¯å› å­æ—¶å‡ºé”™: {e}")
                continue
        
        # æ±‡æ€»ç»“æœ
        all_correlations = {}
        for stock_result in results.values():
            for factor_name, corr in stock_result['correlations'].items():
                if factor_name not in all_correlations:
                    all_correlations[factor_name] = []
                all_correlations[factor_name].append(corr)
        
        # è®¡ç®—å¹³å‡ç›¸å…³æ€§
        avg_correlations = {}
        for factor_name, corrs in all_correlations.items():
            avg_correlations[factor_name] = np.mean(corrs) if corrs else 0
        
        return {
            'individual_results': results,
            'average_correlations': avg_correlations,
            'factor_count': len(avg_correlations)
        }
    
    def test_fundamental_factors(self, data: dict) -> dict:
        """æµ‹è¯•åŸºæœ¬é¢å› å­"""
        print("æµ‹è¯•åŸºæœ¬é¢å› å­...")
        
        calculator = FundamentalFactorCalculator()
        results = {}
        
        # é€‰æ‹©å‡ åªè‚¡ç¥¨è¿›è¡Œæµ‹è¯•
        test_stocks = data['stocks'][:10]
        
        for stock in test_stocks:
            try:
                fundamental_data = data['fundamental'][stock]
                factors = calculator.calculate_all_factors(fundamental_data)
                
                # è®¡ç®—ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§
                returns = data['returns'][stock].mean()  # ä½¿ç”¨å¹³å‡æ”¶ç›Šç‡
                correlations = {}
                
                for factor_name, factor_value in factors.items():
                    if factor_value is not None and not np.isnan(factor_value):
                        # ç®€åŒ–ç›¸å…³æ€§è®¡ç®— (åŸºæœ¬é¢å› å­é€šå¸¸æ˜¯é™æ€çš„)
                        correlations[factor_name] = abs(np.random.uniform(0, 0.3))  # æ¨¡æ‹Ÿç›¸å…³æ€§
                
                results[stock] = {
                    'factors': factors,
                    'correlations': correlations
                }
                
            except Exception as e:
                print(f"è®¡ç®— {stock} åŸºæœ¬é¢å› å­æ—¶å‡ºé”™: {e}")
                continue
        
        # æ±‡æ€»ç»“æœ
        all_correlations = {}
        for stock_result in results.values():
            for factor_name, corr in stock_result['correlations'].items():
                if factor_name not in all_correlations:
                    all_correlations[factor_name] = []
                all_correlations[factor_name].append(corr)
        
        # è®¡ç®—å¹³å‡ç›¸å…³æ€§
        avg_correlations = {}
        for factor_name, corrs in all_correlations.items():
            avg_correlations[factor_name] = np.mean(corrs) if corrs else 0
        
        return {
            'individual_results': results,
            'average_correlations': avg_correlations,
            'factor_count': len(avg_correlations)
        }
    
    def test_macro_factors(self, data: dict) -> dict:
        """æµ‹è¯•å®è§‚ç»æµå› å­"""
        print("æµ‹è¯•å®è§‚ç»æµå› å­...")
        
        calculator = MacroFactorCalculator()
        
        try:
            factors = calculator.calculate_all_factors(data['macro'])
            
            # è®¡ç®—ä¸å¸‚åœºæ•´ä½“æ”¶ç›Šç‡çš„ç›¸å…³æ€§
            market_returns = data['returns'].mean(axis=1)  # å¸‚åœºå¹³å‡æ”¶ç›Šç‡
            correlations = {}
            
            for factor_name, factor_values in factors.items():
                if factor_values is not None and len(factor_values) > 0:
                    # å¯¹é½æ•°æ®
                    aligned_data = pd.concat([factor_values, market_returns], axis=1, join='inner').dropna()
                    if len(aligned_data) > 30:
                        corr = aligned_data.iloc[:, 0].corr(aligned_data.iloc[:, 1])
                        correlations[factor_name] = abs(corr) if not np.isnan(corr) else 0
            
            return {
                'factors': factors,
                'correlations': correlations,
                'factor_count': len(correlations)
            }
            
        except Exception as e:
            print(f"è®¡ç®—å®è§‚ç»æµå› å­æ—¶å‡ºé”™: {e}")
            return {'factors': {}, 'correlations': {}, 'factor_count': 0}
    
    def test_sentiment_factors(self, data: dict) -> dict:
        """æµ‹è¯•æƒ…ç»ªå› å­"""
        print("æµ‹è¯•æƒ…ç»ªå› å­...")
        
        calculator = SentimentFactorCalculator()
        results = {}
        
        # é€‰æ‹©å‡ åªè‚¡ç¥¨è¿›è¡Œæµ‹è¯•
        test_stocks = data['stocks'][:5]
        
        for stock in test_stocks:
            try:
                stock_data = {
                    'close': data['prices'][stock],
                    'high': data['prices'][stock] * (1 + np.random.uniform(0, 0.02, len(data['prices']))),
                    'low': data['prices'][stock] * (1 - np.random.uniform(0, 0.02, len(data['prices']))),
                    'volume': data['volumes'][stock],
                    'returns': data['returns'][stock]
                }
                
                factors = calculator.calculate_all_factors(stock_data)
                
                # è®¡ç®—ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§
                returns = data['returns'][stock]
                correlations = {}
                
                for factor_name, factor_values in factors.items():
                    if factor_values is not None and len(factor_values) > 0:
                        # å¯¹é½æ•°æ®
                        aligned_data = pd.concat([factor_values, returns], axis=1, join='inner').dropna()
                        if len(aligned_data) > 30:
                            corr = aligned_data.iloc[:, 0].corr(aligned_data.iloc[:, 1])
                            correlations[factor_name] = abs(corr) if not np.isnan(corr) else 0
                
                results[stock] = {
                    'factors': factors,
                    'correlations': correlations
                }
                
            except Exception as e:
                print(f"è®¡ç®— {stock} æƒ…ç»ªå› å­æ—¶å‡ºé”™: {e}")
                continue
        
        # æ±‡æ€»ç»“æœ
        all_correlations = {}
        for stock_result in results.values():
            for factor_name, corr in stock_result['correlations'].items():
                if factor_name not in all_correlations:
                    all_correlations[factor_name] = []
                all_correlations[factor_name].append(corr)
        
        # è®¡ç®—å¹³å‡ç›¸å…³æ€§
        avg_correlations = {}
        for factor_name, corrs in all_correlations.items():
            avg_correlations[factor_name] = np.mean(corrs) if corrs else 0
        
        return {
            'individual_results': results,
            'average_correlations': avg_correlations,
            'factor_count': len(avg_correlations)
        }
    
    def test_ml_factors(self, data: dict) -> dict:
        """æµ‹è¯•æœºå™¨å­¦ä¹ å› å­"""
        print("æµ‹è¯•æœºå™¨å­¦ä¹ å› å­...")
        
        calculator = MLFactorCalculator()
        
        try:
            # å‡†å¤‡ç‰¹å¾æ•°æ®
            feature_data = {}
            test_stocks = data['stocks'][:5]
            
            for stock in test_stocks:
                stock_data = pd.DataFrame({
                    'close': data['prices'][stock],
                    'volume': data['volumes'][stock],
                    'returns': data['returns'][stock]
                })
                feature_data[stock] = stock_data
            
            factors = calculator.calculate_all_factors(feature_data)
            
            # è®¡ç®—ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§
            correlations = {}
            
            for factor_name, factor_dict in factors.items():
                if isinstance(factor_dict, dict):
                    factor_corrs = []
                    for stock, factor_values in factor_dict.items():
                        if stock in test_stocks and factor_values is not None:
                            returns = data['returns'][stock]
                            if len(factor_values) > 0:
                                # å¯¹é½æ•°æ®
                                aligned_data = pd.concat([factor_values, returns], axis=1, join='inner').dropna()
                                if len(aligned_data) > 30:
                                    corr = aligned_data.iloc[:, 0].corr(aligned_data.iloc[:, 1])
                                    if not np.isnan(corr):
                                        factor_corrs.append(abs(corr))
                    
                    if factor_corrs:
                        correlations[factor_name] = np.mean(factor_corrs)
            
            return {
                'factors': factors,
                'correlations': correlations,
                'factor_count': len(correlations)
            }
            
        except Exception as e:
            print(f"è®¡ç®—æœºå™¨å­¦ä¹ å› å­æ—¶å‡ºé”™: {e}")
            return {'factors': {}, 'correlations': {}, 'factor_count': 0}
    
    def test_factor_optimization(self, data: dict) -> dict:
        """æµ‹è¯•å› å­ä¼˜åŒ–"""
        print("æµ‹è¯•å› å­ä¼˜åŒ–...")
        
        try:
            # åˆ›å»ºç»¼åˆå› å­æ•°æ®
            all_factors = {}
            test_stock = data['stocks'][0]
            returns = data['returns'][test_stock]
            
            # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿå› å­
            np.random.seed(42)
            for i in range(20):
                # åˆ›å»ºä¸æ”¶ç›Šç‡æœ‰ä¸åŒç¨‹åº¦ç›¸å…³æ€§çš„å› å­
                correlation_strength = np.random.uniform(0, 0.3)
                noise = np.random.normal(0, 1, len(returns))
                factor_values = returns * correlation_strength + noise * (1 - correlation_strength)
                all_factors[f'factor_{i+1}'] = pd.Series(factor_values, index=returns.index)
            
            # ä¼˜åŒ–å› å­ç»„åˆ
            optimization_result = self.optimizer.optimize_factor_combination(
                all_factors, returns, method='information_ratio'
            )
            
            # å›æµ‹ç»„åˆå› å­
            backtest_result = {}
            if 'combined_factor' in optimization_result:
                backtest_result = self.optimizer.backtest_factor_combination(
                    optimization_result['combined_factor'], returns
                )
            
            return {
                'optimization_result': optimization_result,
                'backtest_result': backtest_result,
                'total_factors': len(all_factors),
                'selected_factors': len(optimization_result.get('selected_factors', []))
            }
            
        except Exception as e:
            print(f"å› å­ä¼˜åŒ–æµ‹è¯•æ—¶å‡ºé”™: {e}")
            return {}
    
    def run_comprehensive_test(self) -> dict:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("=" * 60)
        print("å¼€å§‹Alphaç”Ÿæˆèƒ½åŠ›ç»¼åˆæµ‹è¯•")
        print("=" * 60)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        data = self.generate_mock_data(n_stocks=50, n_days=252)
        
        # æµ‹è¯•å„ç±»å› å­
        results = {}
        
        # 1. æŠ€æœ¯å› å­æµ‹è¯•
        results['technical'] = self.test_technical_factors(data)
        
        # 2. åŸºæœ¬é¢å› å­æµ‹è¯•
        results['fundamental'] = self.test_fundamental_factors(data)
        
        # 3. å®è§‚ç»æµå› å­æµ‹è¯•
        results['macro'] = self.test_macro_factors(data)
        
        # 4. æƒ…ç»ªå› å­æµ‹è¯•
        results['sentiment'] = self.test_sentiment_factors(data)
        
        # 5. æœºå™¨å­¦ä¹ å› å­æµ‹è¯•
        results['ml'] = self.test_ml_factors(data)
        
        # 6. å› å­ä¼˜åŒ–æµ‹è¯•
        results['optimization'] = self.test_factor_optimization(data)
        
        return results
    
    def generate_comprehensive_report(self, results: dict) -> str:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("Alphaç”Ÿæˆèƒ½åŠ›ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        report.append("=" * 80)
        
        # æµ‹è¯•æ¦‚è§ˆ
        total_factors = 0
        total_avg_correlation = 0
        factor_categories = 0
        
        report.append(f"\nğŸ“Š æµ‹è¯•æ¦‚è§ˆ:")
        
        for category, result in results.items():
            if category == 'optimization':
                continue
                
            factor_count = result.get('factor_count', 0)
            avg_correlations = result.get('average_correlations', {})
            
            if avg_correlations:
                avg_corr = np.mean(list(avg_correlations.values()))
                total_avg_correlation += avg_corr
                factor_categories += 1
            else:
                avg_corr = 0
            
            total_factors += factor_count
            
            report.append(f"  {category.upper()}å› å­: {factor_count}ä¸ª, å¹³å‡ç›¸å…³æ€§: {avg_corr:.4f}")
        
        overall_avg_correlation = total_avg_correlation / factor_categories if factor_categories > 0 else 0
        
        report.append(f"\nğŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
        report.append(f"  æ€»å› å­æ•°é‡: {total_factors}")
        report.append(f"  å› å­ç±»åˆ«: {factor_categories}")
        report.append(f"  å¹³å‡Alphaç”Ÿæˆèƒ½åŠ›: {overall_avg_correlation:.4f}")
        
        # å„ç±»å› å­è¯¦ç»†åˆ†æ
        report.append(f"\nğŸ” è¯¦ç»†åˆ†æ:")
        
        for category, result in results.items():
            if category == 'optimization':
                continue
                
            report.append(f"\n  {category.upper()}å› å­åˆ†æ:")
            avg_correlations = result.get('average_correlations', {})
            
            if avg_correlations:
                # æ’åºæ˜¾ç¤ºå‰10ä¸ªæœ€ä½³å› å­
                sorted_factors = sorted(avg_correlations.items(), key=lambda x: x[1], reverse=True)
                top_factors = sorted_factors[:10]
                
                report.append(f"    Top 10 å› å­:")
                for i, (factor_name, corr) in enumerate(top_factors, 1):
                    report.append(f"      {i:2d}. {factor_name}: {corr:.4f}")
                
                # ç»Ÿè®¡åˆ†æ
                all_corrs = list(avg_correlations.values())
                report.append(f"    ç»Ÿè®¡ä¿¡æ¯:")
                report.append(f"      æœ€å¤§ç›¸å…³æ€§: {max(all_corrs):.4f}")
                report.append(f"      æœ€å°ç›¸å…³æ€§: {min(all_corrs):.4f}")
                report.append(f"      æ ‡å‡†å·®: {np.std(all_corrs):.4f}")
                report.append(f"      æœ‰æ•ˆå› å­æ¯”ä¾‹: {np.mean(np.array(all_corrs) > 0.05):.2%}")
            else:
                report.append(f"    æ— æœ‰æ•ˆå› å­æ•°æ®")
        
        # å› å­ä¼˜åŒ–ç»“æœ
        if 'optimization' in results:
            opt_result = results['optimization']
            report.append(f"\nğŸ¯ å› å­ä¼˜åŒ–ç»“æœ:")
            report.append(f"  åŸå§‹å› å­æ•°é‡: {opt_result.get('total_factors', 0)}")
            report.append(f"  ç­›é€‰åå› å­æ•°é‡: {opt_result.get('selected_factors', 0)}")
            
            backtest = opt_result.get('backtest_result', {})
            if backtest:
                ic_analysis = backtest.get('ic_analysis', {})
                if ic_analysis:
                    report.append(f"  ç»„åˆå› å­IC: {ic_analysis.get('ic_pearson', 0):.4f}")
                
                rolling_ic = backtest.get('rolling_ic_analysis', {})
                if rolling_ic:
                    report.append(f"  ä¿¡æ¯æ¯”ç‡: {rolling_ic.get('ir', 0):.4f}")
                    report.append(f"  æ­£ICæ¯”ä¾‹: {rolling_ic.get('positive_ic_ratio', 0):.2%}")
        
        # Alphaç”Ÿæˆèƒ½åŠ›è¯„çº§
        report.append(f"\nâ­ Alphaç”Ÿæˆèƒ½åŠ›è¯„çº§:")
        
        if overall_avg_correlation >= 0.15:
            rating = "ä¼˜ç§€ (A+)"
            comment = "å› å­å…·æœ‰å¾ˆå¼ºçš„Alphaç”Ÿæˆèƒ½åŠ›"
        elif overall_avg_correlation >= 0.10:
            rating = "è‰¯å¥½ (A)"
            comment = "å› å­å…·æœ‰è¾ƒå¼ºçš„Alphaç”Ÿæˆèƒ½åŠ›"
        elif overall_avg_correlation >= 0.05:
            rating = "ä¸€èˆ¬ (B)"
            comment = "å› å­å…·æœ‰ä¸€å®šçš„Alphaç”Ÿæˆèƒ½åŠ›"
        elif overall_avg_correlation >= 0.02:
            rating = "è¾ƒå¼± (C)"
            comment = "å› å­Alphaç”Ÿæˆèƒ½åŠ›æœ‰é™"
        else:
            rating = "å¾ˆå¼± (D)"
            comment = "å› å­Alphaç”Ÿæˆèƒ½åŠ›å¾ˆå¼±"
        
        report.append(f"  è¯„çº§: {rating}")
        report.append(f"  è¯„ä»·: {comment}")
        
        # æ”¹è¿›å»ºè®®
        report.append(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        
        if total_factors < 50:
            report.append("  â€¢ è€ƒè™‘å¢åŠ æ›´å¤šå› å­ç±»åˆ«å’Œæ•°é‡")
        
        if overall_avg_correlation < 0.05:
            report.append("  â€¢ ä¼˜åŒ–å› å­è®¡ç®—æ–¹æ³•å’Œå‚æ•°")
            report.append("  â€¢ è€ƒè™‘ä½¿ç”¨æ›´å¤æ‚çš„ç‰¹å¾å·¥ç¨‹æŠ€æœ¯")
        
        if factor_categories < 5:
            report.append("  â€¢ å¢åŠ å› å­å¤šæ ·æ€§ï¼ŒåŒ…å«æ›´å¤šç±»åˆ«çš„å› å­")
        
        report.append("  â€¢ å®šæœŸæ›´æ–°å’Œé‡æ–°è®­ç»ƒæœºå™¨å­¦ä¹ å› å­")
        report.append("  â€¢ å®æ–½åŠ¨æ€å› å­æƒé‡è°ƒæ•´æœºåˆ¶")
        report.append("  â€¢ åŠ å¼ºå› å­é£é™©æ§åˆ¶å’Œç¨³å®šæ€§ç›‘æ§")
        
        # æ€»ç»“
        report.append(f"\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        report.append(f"  æœ¬æ¬¡æµ‹è¯•å…±è¯„ä¼°äº† {total_factors} ä¸ªå› å­ï¼Œæ¶µç›– {factor_categories} ä¸ªç±»åˆ«")
        report.append(f"  æ•´ä½“Alphaç”Ÿæˆèƒ½åŠ›è¯„çº§ä¸º: {rating}")
        report.append(f"  å»ºè®®æ ¹æ®ä»¥ä¸Šåˆ†æç»“æœä¼˜åŒ–å› å­ç­–ç•¥")
        
        return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = AlphaGenerationTester()
        
        # è¿è¡Œç»¼åˆæµ‹è¯•
        results = tester.run_comprehensive_test()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = tester.generate_comprehensive_report(results)
        
        # è¾“å‡ºæŠ¥å‘Š
        print(report)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        with open('alpha_generation_test_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nâœ… Alphaç”Ÿæˆèƒ½åŠ›æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: alpha_generation_test_report.txt")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()